{
  "best_metric": 1.61072159,
  "best_model_checkpoint": "/root/autodl-tmp/DeepSeek-VL2/deepseek/fine-tuned-model/v3-20250307-103814/checkpoint-6000",
  "epoch": 0.75,
  "eval_steps": 2000,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000125,
      "grad_norm": 1.4962161779403687,
      "learning_rate": 7.999999691574867e-05,
      "loss": 2.3562440872192383,
      "memory(GiB)": 11.89,
      "step": 1,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.079233
    },
    {
      "epoch": 0.000625,
      "grad_norm": 23.37042808532715,
      "learning_rate": 7.999992289374038e-05,
      "loss": 4.115095138549805,
      "memory(GiB)": 17.97,
      "step": 5,
      "token_acc": 0.35514018691588783,
      "train_speed(iter/s)": 0.213169
    },
    {
      "epoch": 0.00125,
      "grad_norm": 1.4970625638961792,
      "learning_rate": 7.999969157525883e-05,
      "loss": 4.485531997680664,
      "memory(GiB)": 17.97,
      "step": 10,
      "token_acc": 0.3467741935483871,
      "train_speed(iter/s)": 0.261769
    },
    {
      "epoch": 0.001875,
      "grad_norm": 1.724088430404663,
      "learning_rate": 7.999930604544711e-05,
      "loss": 4.290039443969727,
      "memory(GiB)": 17.97,
      "step": 15,
      "token_acc": 0.33613445378151263,
      "train_speed(iter/s)": 0.280829
    },
    {
      "epoch": 0.0025,
      "grad_norm": 1.5707802772521973,
      "learning_rate": 7.99987663057916e-05,
      "loss": 3.2774421691894533,
      "memory(GiB)": 17.97,
      "step": 20,
      "token_acc": 0.34108527131782945,
      "train_speed(iter/s)": 0.296092
    },
    {
      "epoch": 0.003125,
      "grad_norm": 0.7923545837402344,
      "learning_rate": 7.999807235837312e-05,
      "loss": 2.824492835998535,
      "memory(GiB)": 17.97,
      "step": 25,
      "token_acc": 0.48175182481751827,
      "train_speed(iter/s)": 0.307975
    },
    {
      "epoch": 0.00375,
      "grad_norm": 9.810070037841797,
      "learning_rate": 7.999722420586709e-05,
      "loss": 3.9532039642333983,
      "memory(GiB)": 17.97,
      "step": 30,
      "token_acc": 0.3865546218487395,
      "train_speed(iter/s)": 0.324403
    },
    {
      "epoch": 0.004375,
      "grad_norm": 7.302082061767578,
      "learning_rate": 7.999622185154341e-05,
      "loss": 2.918758773803711,
      "memory(GiB)": 18.99,
      "step": 35,
      "token_acc": 0.49242424242424243,
      "train_speed(iter/s)": 0.331246
    },
    {
      "epoch": 0.005,
      "grad_norm": 1.742152452468872,
      "learning_rate": 7.999506529926642e-05,
      "loss": 1.889266014099121,
      "memory(GiB)": 18.99,
      "step": 40,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.337187
    },
    {
      "epoch": 0.005625,
      "grad_norm": 1.3054096698760986,
      "learning_rate": 7.999375455349505e-05,
      "loss": 2.2669757843017577,
      "memory(GiB)": 18.99,
      "step": 45,
      "token_acc": 0.5147058823529411,
      "train_speed(iter/s)": 0.341034
    },
    {
      "epoch": 0.00625,
      "grad_norm": 16.858882904052734,
      "learning_rate": 7.999228961928259e-05,
      "loss": 3.5433155059814454,
      "memory(GiB)": 18.99,
      "step": 50,
      "token_acc": 0.4855072463768116,
      "train_speed(iter/s)": 0.344649
    },
    {
      "epoch": 0.006875,
      "grad_norm": 7.5881524085998535,
      "learning_rate": 7.999067050227685e-05,
      "loss": 3.5390071868896484,
      "memory(GiB)": 18.99,
      "step": 55,
      "token_acc": 0.5037037037037037,
      "train_speed(iter/s)": 0.346153
    },
    {
      "epoch": 0.0075,
      "grad_norm": 2.347489595413208,
      "learning_rate": 7.998889720872003e-05,
      "loss": 2.448847007751465,
      "memory(GiB)": 22.05,
      "step": 60,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.348743
    },
    {
      "epoch": 0.008125,
      "grad_norm": 6.129647731781006,
      "learning_rate": 7.998696974544871e-05,
      "loss": 2.1715768814086913,
      "memory(GiB)": 22.05,
      "step": 65,
      "token_acc": 0.5793650793650794,
      "train_speed(iter/s)": 0.350619
    },
    {
      "epoch": 0.00875,
      "grad_norm": 1.3735499382019043,
      "learning_rate": 7.998488811989388e-05,
      "loss": 3.110190200805664,
      "memory(GiB)": 22.05,
      "step": 70,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.352301
    },
    {
      "epoch": 0.009375,
      "grad_norm": 1.6452621221542358,
      "learning_rate": 7.998265234008086e-05,
      "loss": 2.3591949462890627,
      "memory(GiB)": 22.05,
      "step": 75,
      "token_acc": 0.5068493150684932,
      "train_speed(iter/s)": 0.354155
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0429755449295044,
      "learning_rate": 7.998026241462927e-05,
      "loss": 3.1762725830078127,
      "memory(GiB)": 22.05,
      "step": 80,
      "token_acc": 0.3798449612403101,
      "train_speed(iter/s)": 0.355394
    },
    {
      "epoch": 0.010625,
      "grad_norm": 8.116653442382812,
      "learning_rate": 7.997771835275302e-05,
      "loss": 2.296131134033203,
      "memory(GiB)": 22.05,
      "step": 85,
      "token_acc": 0.5426356589147286,
      "train_speed(iter/s)": 0.356426
    },
    {
      "epoch": 0.01125,
      "grad_norm": 1.1605650186538696,
      "learning_rate": 7.997502016426028e-05,
      "loss": 1.8887693405151367,
      "memory(GiB)": 22.05,
      "step": 90,
      "token_acc": 0.5655737704918032,
      "train_speed(iter/s)": 0.356612
    },
    {
      "epoch": 0.011875,
      "grad_norm": 1.4518030881881714,
      "learning_rate": 7.99721678595534e-05,
      "loss": 3.4304786682128907,
      "memory(GiB)": 22.05,
      "step": 95,
      "token_acc": 0.46715328467153283,
      "train_speed(iter/s)": 0.35702
    },
    {
      "epoch": 0.0125,
      "grad_norm": 5.891845703125,
      "learning_rate": 7.996916144962893e-05,
      "loss": 2.778383255004883,
      "memory(GiB)": 22.05,
      "step": 100,
      "token_acc": 0.4927536231884058,
      "train_speed(iter/s)": 0.35823
    },
    {
      "epoch": 0.013125,
      "grad_norm": 1.2081389427185059,
      "learning_rate": 7.996600094607749e-05,
      "loss": 2.9243459701538086,
      "memory(GiB)": 22.05,
      "step": 105,
      "token_acc": 0.4628099173553719,
      "train_speed(iter/s)": 0.359393
    },
    {
      "epoch": 0.01375,
      "grad_norm": 8.270181655883789,
      "learning_rate": 7.99626863610838e-05,
      "loss": 2.770221138000488,
      "memory(GiB)": 22.05,
      "step": 110,
      "token_acc": 0.4409448818897638,
      "train_speed(iter/s)": 0.359763
    },
    {
      "epoch": 0.014375,
      "grad_norm": 10.413384437561035,
      "learning_rate": 7.995921770742666e-05,
      "loss": 3.408167266845703,
      "memory(GiB)": 22.05,
      "step": 115,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.360281
    },
    {
      "epoch": 0.015,
      "grad_norm": 9.607588768005371,
      "learning_rate": 7.995559499847881e-05,
      "loss": 2.7572635650634765,
      "memory(GiB)": 22.05,
      "step": 120,
      "token_acc": 0.4961832061068702,
      "train_speed(iter/s)": 0.360389
    },
    {
      "epoch": 0.015625,
      "grad_norm": 1.08954918384552,
      "learning_rate": 7.99518182482069e-05,
      "loss": 2.494379997253418,
      "memory(GiB)": 22.05,
      "step": 125,
      "token_acc": 0.5037593984962406,
      "train_speed(iter/s)": 0.360586
    },
    {
      "epoch": 0.01625,
      "grad_norm": 1.5921378135681152,
      "learning_rate": 7.994788747117151e-05,
      "loss": 1.5052242279052734,
      "memory(GiB)": 22.05,
      "step": 130,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.361312
    },
    {
      "epoch": 0.016875,
      "grad_norm": 1.5943681001663208,
      "learning_rate": 7.9943802682527e-05,
      "loss": 1.9188323974609376,
      "memory(GiB)": 22.05,
      "step": 135,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.361809
    },
    {
      "epoch": 0.0175,
      "grad_norm": 8.738972663879395,
      "learning_rate": 7.993956389802153e-05,
      "loss": 3.0082208633422853,
      "memory(GiB)": 22.05,
      "step": 140,
      "token_acc": 0.4246575342465753,
      "train_speed(iter/s)": 0.362139
    },
    {
      "epoch": 0.018125,
      "grad_norm": 1.1272974014282227,
      "learning_rate": 7.99351711339969e-05,
      "loss": 2.411260795593262,
      "memory(GiB)": 22.05,
      "step": 145,
      "token_acc": 0.49606299212598426,
      "train_speed(iter/s)": 0.362603
    },
    {
      "epoch": 0.01875,
      "grad_norm": 5.915585517883301,
      "learning_rate": 7.993062440738864e-05,
      "loss": 2.722926712036133,
      "memory(GiB)": 22.05,
      "step": 150,
      "token_acc": 0.4830508474576271,
      "train_speed(iter/s)": 0.362788
    },
    {
      "epoch": 0.019375,
      "grad_norm": 11.311067581176758,
      "learning_rate": 7.992592373572579e-05,
      "loss": 2.7384735107421876,
      "memory(GiB)": 22.05,
      "step": 155,
      "token_acc": 0.4108527131782946,
      "train_speed(iter/s)": 0.362569
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3686164617538452,
      "learning_rate": 7.992106913713087e-05,
      "loss": 1.6250644683837892,
      "memory(GiB)": 22.05,
      "step": 160,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.362432
    },
    {
      "epoch": 0.020625,
      "grad_norm": 1.4984554052352905,
      "learning_rate": 7.991606063031992e-05,
      "loss": 2.6253801345825196,
      "memory(GiB)": 22.05,
      "step": 165,
      "token_acc": 0.40869565217391307,
      "train_speed(iter/s)": 0.362645
    },
    {
      "epoch": 0.02125,
      "grad_norm": 2.270359516143799,
      "learning_rate": 7.99108982346023e-05,
      "loss": 1.6939838409423829,
      "memory(GiB)": 22.05,
      "step": 170,
      "token_acc": 0.5912408759124088,
      "train_speed(iter/s)": 0.363226
    },
    {
      "epoch": 0.021875,
      "grad_norm": 1.4322271347045898,
      "learning_rate": 7.990558196988064e-05,
      "loss": 2.7430326461791994,
      "memory(GiB)": 22.05,
      "step": 175,
      "token_acc": 0.43283582089552236,
      "train_speed(iter/s)": 0.363345
    },
    {
      "epoch": 0.0225,
      "grad_norm": 1.5652906894683838,
      "learning_rate": 7.990011185665082e-05,
      "loss": 2.001554489135742,
      "memory(GiB)": 22.05,
      "step": 180,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.363779
    },
    {
      "epoch": 0.023125,
      "grad_norm": 2.149388551712036,
      "learning_rate": 7.989448791600182e-05,
      "loss": 1.5657968521118164,
      "memory(GiB)": 22.05,
      "step": 185,
      "token_acc": 0.6821705426356589,
      "train_speed(iter/s)": 0.363762
    },
    {
      "epoch": 0.02375,
      "grad_norm": 7.368746757507324,
      "learning_rate": 7.988871016961572e-05,
      "loss": 2.3619945526123045,
      "memory(GiB)": 22.05,
      "step": 190,
      "token_acc": 0.4330708661417323,
      "train_speed(iter/s)": 0.363829
    },
    {
      "epoch": 0.024375,
      "grad_norm": 8.641366958618164,
      "learning_rate": 7.988277863976752e-05,
      "loss": 3.00323486328125,
      "memory(GiB)": 22.05,
      "step": 195,
      "token_acc": 0.4316546762589928,
      "train_speed(iter/s)": 0.364064
    },
    {
      "epoch": 0.025,
      "grad_norm": 1.3411959409713745,
      "learning_rate": 7.987669334932513e-05,
      "loss": 2.4134859085083007,
      "memory(GiB)": 22.05,
      "step": 200,
      "token_acc": 0.44285714285714284,
      "train_speed(iter/s)": 0.364409
    },
    {
      "epoch": 0.025625,
      "grad_norm": 1.6866869926452637,
      "learning_rate": 7.987045432174924e-05,
      "loss": 2.5926187515258787,
      "memory(GiB)": 22.05,
      "step": 205,
      "token_acc": 0.5327868852459017,
      "train_speed(iter/s)": 0.364468
    },
    {
      "epoch": 0.02625,
      "grad_norm": 1.4134234189987183,
      "learning_rate": 7.986406158109327e-05,
      "loss": 1.4175107955932618,
      "memory(GiB)": 22.05,
      "step": 210,
      "token_acc": 0.6302521008403361,
      "train_speed(iter/s)": 0.365007
    },
    {
      "epoch": 0.026875,
      "grad_norm": 1.7693010568618774,
      "learning_rate": 7.985751515200324e-05,
      "loss": 2.641947937011719,
      "memory(GiB)": 22.05,
      "step": 215,
      "token_acc": 0.5081967213114754,
      "train_speed(iter/s)": 0.365011
    },
    {
      "epoch": 0.0275,
      "grad_norm": 6.073214054107666,
      "learning_rate": 7.985081505971765e-05,
      "loss": 1.9705904006958008,
      "memory(GiB)": 22.05,
      "step": 220,
      "token_acc": 0.5470085470085471,
      "train_speed(iter/s)": 0.364827
    },
    {
      "epoch": 0.028125,
      "grad_norm": 1.6012895107269287,
      "learning_rate": 7.98439613300675e-05,
      "loss": 2.4490671157836914,
      "memory(GiB)": 22.05,
      "step": 225,
      "token_acc": 0.408,
      "train_speed(iter/s)": 0.364896
    },
    {
      "epoch": 0.02875,
      "grad_norm": 6.885223388671875,
      "learning_rate": 7.983695398947602e-05,
      "loss": 2.293138122558594,
      "memory(GiB)": 22.05,
      "step": 230,
      "token_acc": 0.5190839694656488,
      "train_speed(iter/s)": 0.364921
    },
    {
      "epoch": 0.029375,
      "grad_norm": 6.420029163360596,
      "learning_rate": 7.982979306495873e-05,
      "loss": 2.855607604980469,
      "memory(GiB)": 22.05,
      "step": 235,
      "token_acc": 0.452991452991453,
      "train_speed(iter/s)": 0.365006
    },
    {
      "epoch": 0.03,
      "grad_norm": 6.492240905761719,
      "learning_rate": 7.98224785841232e-05,
      "loss": 2.2941484451293945,
      "memory(GiB)": 22.05,
      "step": 240,
      "token_acc": 0.49586776859504134,
      "train_speed(iter/s)": 0.365182
    },
    {
      "epoch": 0.030625,
      "grad_norm": 1.4737049341201782,
      "learning_rate": 7.981501057516908e-05,
      "loss": 2.1779531478881835,
      "memory(GiB)": 22.05,
      "step": 245,
      "token_acc": 0.4830508474576271,
      "train_speed(iter/s)": 0.365101
    },
    {
      "epoch": 0.03125,
      "grad_norm": 1.6664820909500122,
      "learning_rate": 7.980738906688788e-05,
      "loss": 2.599526023864746,
      "memory(GiB)": 22.05,
      "step": 250,
      "token_acc": 0.453125,
      "train_speed(iter/s)": 0.364829
    },
    {
      "epoch": 0.031875,
      "grad_norm": 1.5110535621643066,
      "learning_rate": 7.979961408866288e-05,
      "loss": 1.7498579025268555,
      "memory(GiB)": 22.05,
      "step": 255,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.36491
    },
    {
      "epoch": 0.0325,
      "grad_norm": 2.6753990650177,
      "learning_rate": 7.979168567046906e-05,
      "loss": 2.2233903884887694,
      "memory(GiB)": 22.05,
      "step": 260,
      "token_acc": 0.5590551181102362,
      "train_speed(iter/s)": 0.365075
    },
    {
      "epoch": 0.033125,
      "grad_norm": 2.4827487468719482,
      "learning_rate": 7.978360384287297e-05,
      "loss": 1.8326671600341797,
      "memory(GiB)": 22.05,
      "step": 265,
      "token_acc": 0.5864661654135338,
      "train_speed(iter/s)": 0.365077
    },
    {
      "epoch": 0.03375,
      "grad_norm": 2.1573307514190674,
      "learning_rate": 7.977536863703256e-05,
      "loss": 2.3695945739746094,
      "memory(GiB)": 22.05,
      "step": 270,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.365141
    },
    {
      "epoch": 0.034375,
      "grad_norm": 6.674324035644531,
      "learning_rate": 7.976698008469714e-05,
      "loss": 2.515140724182129,
      "memory(GiB)": 22.05,
      "step": 275,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.364936
    },
    {
      "epoch": 0.035,
      "grad_norm": 1.8524092435836792,
      "learning_rate": 7.97584382182072e-05,
      "loss": 2.1463890075683594,
      "memory(GiB)": 22.05,
      "step": 280,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.365216
    },
    {
      "epoch": 0.035625,
      "grad_norm": 1.715530514717102,
      "learning_rate": 7.974974307049431e-05,
      "loss": 2.5390581130981444,
      "memory(GiB)": 22.05,
      "step": 285,
      "token_acc": 0.48872180451127817,
      "train_speed(iter/s)": 0.365092
    },
    {
      "epoch": 0.03625,
      "grad_norm": 6.237386226654053,
      "learning_rate": 7.974089467508097e-05,
      "loss": 2.352019500732422,
      "memory(GiB)": 22.05,
      "step": 290,
      "token_acc": 0.48091603053435117,
      "train_speed(iter/s)": 0.365301
    },
    {
      "epoch": 0.036875,
      "grad_norm": 1.8695337772369385,
      "learning_rate": 7.973189306608056e-05,
      "loss": 2.9301883697509767,
      "memory(GiB)": 22.05,
      "step": 295,
      "token_acc": 0.4375,
      "train_speed(iter/s)": 0.36605
    },
    {
      "epoch": 0.0375,
      "grad_norm": 2.0637500286102295,
      "learning_rate": 7.972273827819706e-05,
      "loss": 2.1763776779174804,
      "memory(GiB)": 22.05,
      "step": 300,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.366061
    },
    {
      "epoch": 0.038125,
      "grad_norm": 1.5646940469741821,
      "learning_rate": 7.971343034672505e-05,
      "loss": 1.7244224548339844,
      "memory(GiB)": 22.05,
      "step": 305,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.36611
    },
    {
      "epoch": 0.03875,
      "grad_norm": 1.5400278568267822,
      "learning_rate": 7.970396930754951e-05,
      "loss": 2.2957054138183595,
      "memory(GiB)": 22.05,
      "step": 310,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.366133
    },
    {
      "epoch": 0.039375,
      "grad_norm": 1.8590233325958252,
      "learning_rate": 7.969435519714574e-05,
      "loss": 1.9082595825195312,
      "memory(GiB)": 22.05,
      "step": 315,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.366198
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.937962532043457,
      "learning_rate": 7.968458805257913e-05,
      "loss": 2.5720146179199217,
      "memory(GiB)": 22.05,
      "step": 320,
      "token_acc": 0.456,
      "train_speed(iter/s)": 0.366376
    },
    {
      "epoch": 0.040625,
      "grad_norm": 1.699748158454895,
      "learning_rate": 7.967466791150504e-05,
      "loss": 2.341603469848633,
      "memory(GiB)": 22.05,
      "step": 325,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.366619
    },
    {
      "epoch": 0.04125,
      "grad_norm": 1.2509762048721313,
      "learning_rate": 7.966459481216877e-05,
      "loss": 1.7036666870117188,
      "memory(GiB)": 22.05,
      "step": 330,
      "token_acc": 0.609375,
      "train_speed(iter/s)": 0.367271
    },
    {
      "epoch": 0.041875,
      "grad_norm": 1.5701292753219604,
      "learning_rate": 7.965436879340526e-05,
      "loss": 2.0706737518310545,
      "memory(GiB)": 22.05,
      "step": 335,
      "token_acc": 0.5492957746478874,
      "train_speed(iter/s)": 0.367547
    },
    {
      "epoch": 0.0425,
      "grad_norm": 1.644730806350708,
      "learning_rate": 7.9643989894639e-05,
      "loss": 2.229527473449707,
      "memory(GiB)": 22.05,
      "step": 340,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.367427
    },
    {
      "epoch": 0.043125,
      "grad_norm": 1.5717246532440186,
      "learning_rate": 7.963345815588389e-05,
      "loss": 2.594368553161621,
      "memory(GiB)": 22.05,
      "step": 345,
      "token_acc": 0.47183098591549294,
      "train_speed(iter/s)": 0.367511
    },
    {
      "epoch": 0.04375,
      "grad_norm": 1.7136132717132568,
      "learning_rate": 7.962277361774309e-05,
      "loss": 1.9358293533325195,
      "memory(GiB)": 22.05,
      "step": 350,
      "token_acc": 0.5766423357664233,
      "train_speed(iter/s)": 0.36751
    },
    {
      "epoch": 0.044375,
      "grad_norm": 1.2970750331878662,
      "learning_rate": 7.961193632140884e-05,
      "loss": 2.281744384765625,
      "memory(GiB)": 22.05,
      "step": 355,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.367193
    },
    {
      "epoch": 0.045,
      "grad_norm": 1.6824291944503784,
      "learning_rate": 7.960094630866231e-05,
      "loss": 2.3732534408569337,
      "memory(GiB)": 22.05,
      "step": 360,
      "token_acc": 0.49635036496350365,
      "train_speed(iter/s)": 0.366991
    },
    {
      "epoch": 0.045625,
      "grad_norm": 7.778469085693359,
      "learning_rate": 7.958980362187342e-05,
      "loss": 2.868796157836914,
      "memory(GiB)": 22.05,
      "step": 365,
      "token_acc": 0.39097744360902253,
      "train_speed(iter/s)": 0.367014
    },
    {
      "epoch": 0.04625,
      "grad_norm": 1.603101372718811,
      "learning_rate": 7.957850830400074e-05,
      "loss": 2.4728158950805663,
      "memory(GiB)": 22.05,
      "step": 370,
      "token_acc": 0.4263565891472868,
      "train_speed(iter/s)": 0.36639
    },
    {
      "epoch": 0.046875,
      "grad_norm": 12.197469711303711,
      "learning_rate": 7.956706039859124e-05,
      "loss": 2.7399059295654298,
      "memory(GiB)": 22.05,
      "step": 375,
      "token_acc": 0.4380165289256198,
      "train_speed(iter/s)": 0.365794
    },
    {
      "epoch": 0.0475,
      "grad_norm": 2.1636760234832764,
      "learning_rate": 7.95554599497802e-05,
      "loss": 2.94527530670166,
      "memory(GiB)": 22.05,
      "step": 380,
      "token_acc": 0.4126984126984127,
      "train_speed(iter/s)": 0.365212
    },
    {
      "epoch": 0.048125,
      "grad_norm": 1.2904582023620605,
      "learning_rate": 7.954370700229093e-05,
      "loss": 1.9102937698364257,
      "memory(GiB)": 22.05,
      "step": 385,
      "token_acc": 0.5954198473282443,
      "train_speed(iter/s)": 0.364504
    },
    {
      "epoch": 0.04875,
      "grad_norm": 4.832700252532959,
      "learning_rate": 7.953180160143477e-05,
      "loss": 2.206654930114746,
      "memory(GiB)": 22.05,
      "step": 390,
      "token_acc": 0.5170068027210885,
      "train_speed(iter/s)": 0.364095
    },
    {
      "epoch": 0.049375,
      "grad_norm": 1.300783395767212,
      "learning_rate": 7.951974379311077e-05,
      "loss": 1.859089469909668,
      "memory(GiB)": 22.05,
      "step": 395,
      "token_acc": 0.5658914728682171,
      "train_speed(iter/s)": 0.363884
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5327872037887573,
      "learning_rate": 7.950753362380551e-05,
      "loss": 2.5616968154907225,
      "memory(GiB)": 22.05,
      "step": 400,
      "token_acc": 0.5205479452054794,
      "train_speed(iter/s)": 0.364001
    },
    {
      "epoch": 0.050625,
      "grad_norm": 1.898066520690918,
      "learning_rate": 7.949517114059305e-05,
      "loss": 2.6441070556640627,
      "memory(GiB)": 22.05,
      "step": 405,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.364136
    },
    {
      "epoch": 0.05125,
      "grad_norm": 1.1977771520614624,
      "learning_rate": 7.948265639113462e-05,
      "loss": 1.7644433975219727,
      "memory(GiB)": 22.05,
      "step": 410,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.364201
    },
    {
      "epoch": 0.051875,
      "grad_norm": 8.999896049499512,
      "learning_rate": 7.946998942367851e-05,
      "loss": 2.534511375427246,
      "memory(GiB)": 22.05,
      "step": 415,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.364132
    },
    {
      "epoch": 0.0525,
      "grad_norm": 4.256814479827881,
      "learning_rate": 7.945717028705983e-05,
      "loss": 2.839717674255371,
      "memory(GiB)": 22.05,
      "step": 420,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.364179
    },
    {
      "epoch": 0.053125,
      "grad_norm": 1.9143290519714355,
      "learning_rate": 7.944419903070035e-05,
      "loss": 2.297677421569824,
      "memory(GiB)": 22.05,
      "step": 425,
      "token_acc": 0.4915254237288136,
      "train_speed(iter/s)": 0.364326
    },
    {
      "epoch": 0.05375,
      "grad_norm": 1.3415749073028564,
      "learning_rate": 7.943107570460836e-05,
      "loss": 2.995492172241211,
      "memory(GiB)": 22.05,
      "step": 430,
      "token_acc": 0.4195804195804196,
      "train_speed(iter/s)": 0.364378
    },
    {
      "epoch": 0.054375,
      "grad_norm": 5.374773979187012,
      "learning_rate": 7.941780035937836e-05,
      "loss": 2.0939008712768556,
      "memory(GiB)": 22.05,
      "step": 435,
      "token_acc": 0.5671641791044776,
      "train_speed(iter/s)": 0.364367
    },
    {
      "epoch": 0.055,
      "grad_norm": 1.3460168838500977,
      "learning_rate": 7.940437304619096e-05,
      "loss": 2.396258735656738,
      "memory(GiB)": 22.05,
      "step": 440,
      "token_acc": 0.4825174825174825,
      "train_speed(iter/s)": 0.364315
    },
    {
      "epoch": 0.055625,
      "grad_norm": 1.540993094444275,
      "learning_rate": 7.939079381681268e-05,
      "loss": 2.5619829177856444,
      "memory(GiB)": 22.05,
      "step": 445,
      "token_acc": 0.4881889763779528,
      "train_speed(iter/s)": 0.364272
    },
    {
      "epoch": 0.05625,
      "grad_norm": 6.002119541168213,
      "learning_rate": 7.937706272359567e-05,
      "loss": 2.740810012817383,
      "memory(GiB)": 22.05,
      "step": 450,
      "token_acc": 0.3984375,
      "train_speed(iter/s)": 0.364139
    },
    {
      "epoch": 0.056875,
      "grad_norm": 1.6001759767532349,
      "learning_rate": 7.936317981947762e-05,
      "loss": 1.914686393737793,
      "memory(GiB)": 22.05,
      "step": 455,
      "token_acc": 0.5390625,
      "train_speed(iter/s)": 0.364217
    },
    {
      "epoch": 0.0575,
      "grad_norm": 1.7131500244140625,
      "learning_rate": 7.934914515798145e-05,
      "loss": 1.8682416915893554,
      "memory(GiB)": 22.05,
      "step": 460,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.364211
    },
    {
      "epoch": 0.058125,
      "grad_norm": 5.168917179107666,
      "learning_rate": 7.933495879321516e-05,
      "loss": 2.335883903503418,
      "memory(GiB)": 22.05,
      "step": 465,
      "token_acc": 0.5182481751824818,
      "train_speed(iter/s)": 0.364269
    },
    {
      "epoch": 0.05875,
      "grad_norm": 1.5365345478057861,
      "learning_rate": 7.932062077987167e-05,
      "loss": 1.7277503967285157,
      "memory(GiB)": 22.05,
      "step": 470,
      "token_acc": 0.6535433070866141,
      "train_speed(iter/s)": 0.364346
    },
    {
      "epoch": 0.059375,
      "grad_norm": 4.19841194152832,
      "learning_rate": 7.930613117322848e-05,
      "loss": 1.708944320678711,
      "memory(GiB)": 22.05,
      "step": 475,
      "token_acc": 0.5609756097560976,
      "train_speed(iter/s)": 0.364479
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9564707279205322,
      "learning_rate": 7.929149002914756e-05,
      "loss": 2.3916481018066404,
      "memory(GiB)": 22.05,
      "step": 480,
      "token_acc": 0.4672131147540984,
      "train_speed(iter/s)": 0.364416
    },
    {
      "epoch": 0.060625,
      "grad_norm": 1.3255120515823364,
      "learning_rate": 7.92766974040751e-05,
      "loss": 2.108688163757324,
      "memory(GiB)": 22.05,
      "step": 485,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.364331
    },
    {
      "epoch": 0.06125,
      "grad_norm": 4.163254261016846,
      "learning_rate": 7.926175335504131e-05,
      "loss": 1.723259735107422,
      "memory(GiB)": 22.05,
      "step": 490,
      "token_acc": 0.5338345864661654,
      "train_speed(iter/s)": 0.364098
    },
    {
      "epoch": 0.061875,
      "grad_norm": 1.6886259317398071,
      "learning_rate": 7.924665793966016e-05,
      "loss": 1.7078754425048828,
      "memory(GiB)": 22.05,
      "step": 495,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.364216
    },
    {
      "epoch": 0.0625,
      "grad_norm": 2.3270840644836426,
      "learning_rate": 7.923141121612922e-05,
      "loss": 2.1777980804443358,
      "memory(GiB)": 22.05,
      "step": 500,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.364156
    },
    {
      "epoch": 0.063125,
      "grad_norm": 2.0083119869232178,
      "learning_rate": 7.921601324322938e-05,
      "loss": 3.097306823730469,
      "memory(GiB)": 22.05,
      "step": 505,
      "token_acc": 0.3983050847457627,
      "train_speed(iter/s)": 0.364069
    },
    {
      "epoch": 0.06375,
      "grad_norm": 5.464849472045898,
      "learning_rate": 7.920046408032463e-05,
      "loss": 2.4497091293334963,
      "memory(GiB)": 22.05,
      "step": 510,
      "token_acc": 0.4180327868852459,
      "train_speed(iter/s)": 0.364216
    },
    {
      "epoch": 0.064375,
      "grad_norm": 2.17147159576416,
      "learning_rate": 7.918476378736187e-05,
      "loss": 2.5551532745361327,
      "memory(GiB)": 22.05,
      "step": 515,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.364114
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.4799808263778687,
      "learning_rate": 7.916891242487064e-05,
      "loss": 2.7765523910522463,
      "memory(GiB)": 22.05,
      "step": 520,
      "token_acc": 0.4701492537313433,
      "train_speed(iter/s)": 0.364129
    },
    {
      "epoch": 0.065625,
      "grad_norm": 1.7904807329177856,
      "learning_rate": 7.91529100539629e-05,
      "loss": 2.4956069946289063,
      "memory(GiB)": 22.05,
      "step": 525,
      "token_acc": 0.512987012987013,
      "train_speed(iter/s)": 0.364217
    },
    {
      "epoch": 0.06625,
      "grad_norm": 3.9744346141815186,
      "learning_rate": 7.913675673633281e-05,
      "loss": 2.581785202026367,
      "memory(GiB)": 22.05,
      "step": 530,
      "token_acc": 0.42142857142857143,
      "train_speed(iter/s)": 0.364147
    },
    {
      "epoch": 0.066875,
      "grad_norm": 1.7519989013671875,
      "learning_rate": 7.912045253425645e-05,
      "loss": 2.124197006225586,
      "memory(GiB)": 22.05,
      "step": 535,
      "token_acc": 0.582089552238806,
      "train_speed(iter/s)": 0.364109
    },
    {
      "epoch": 0.0675,
      "grad_norm": 1.8105684518814087,
      "learning_rate": 7.910399751059164e-05,
      "loss": 1.3107890129089355,
      "memory(GiB)": 22.05,
      "step": 540,
      "token_acc": 0.664,
      "train_speed(iter/s)": 0.364246
    },
    {
      "epoch": 0.068125,
      "grad_norm": 1.5313360691070557,
      "learning_rate": 7.908739172877763e-05,
      "loss": 2.2529109954833983,
      "memory(GiB)": 22.05,
      "step": 545,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.364183
    },
    {
      "epoch": 0.06875,
      "grad_norm": 1.636850118637085,
      "learning_rate": 7.90706352528349e-05,
      "loss": 2.3218711853027343,
      "memory(GiB)": 22.05,
      "step": 550,
      "token_acc": 0.518796992481203,
      "train_speed(iter/s)": 0.364153
    },
    {
      "epoch": 0.069375,
      "grad_norm": 4.139140605926514,
      "learning_rate": 7.905372814736494e-05,
      "loss": 2.5430891036987306,
      "memory(GiB)": 22.05,
      "step": 555,
      "token_acc": 0.4122137404580153,
      "train_speed(iter/s)": 0.363891
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3618216514587402,
      "learning_rate": 7.90366704775499e-05,
      "loss": 2.0908817291259765,
      "memory(GiB)": 22.05,
      "step": 560,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.363991
    },
    {
      "epoch": 0.070625,
      "grad_norm": 1.2833837270736694,
      "learning_rate": 7.901946230915245e-05,
      "loss": 2.2498512268066406,
      "memory(GiB)": 22.05,
      "step": 565,
      "token_acc": 0.5032679738562091,
      "train_speed(iter/s)": 0.364001
    },
    {
      "epoch": 0.07125,
      "grad_norm": 1.3759454488754272,
      "learning_rate": 7.900210370851549e-05,
      "loss": 1.8371726989746093,
      "memory(GiB)": 22.05,
      "step": 570,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.363717
    },
    {
      "epoch": 0.071875,
      "grad_norm": 1.027458906173706,
      "learning_rate": 7.89845947425618e-05,
      "loss": 1.7857465744018555,
      "memory(GiB)": 22.05,
      "step": 575,
      "token_acc": 0.6124031007751938,
      "train_speed(iter/s)": 0.363361
    },
    {
      "epoch": 0.0725,
      "grad_norm": 2.0250842571258545,
      "learning_rate": 7.896693547879399e-05,
      "loss": 2.3583843231201174,
      "memory(GiB)": 22.05,
      "step": 580,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.362862
    },
    {
      "epoch": 0.073125,
      "grad_norm": 2.2081944942474365,
      "learning_rate": 7.8949125985294e-05,
      "loss": 2.7648622512817385,
      "memory(GiB)": 22.05,
      "step": 585,
      "token_acc": 0.48026315789473684,
      "train_speed(iter/s)": 0.36245
    },
    {
      "epoch": 0.07375,
      "grad_norm": 1.7812790870666504,
      "learning_rate": 7.8931166330723e-05,
      "loss": 1.5312828063964843,
      "memory(GiB)": 22.05,
      "step": 590,
      "token_acc": 0.592,
      "train_speed(iter/s)": 0.362179
    },
    {
      "epoch": 0.074375,
      "grad_norm": 1.9591772556304932,
      "learning_rate": 7.891305658432113e-05,
      "loss": 2.0603610992431642,
      "memory(GiB)": 22.05,
      "step": 595,
      "token_acc": 0.5378787878787878,
      "train_speed(iter/s)": 0.361791
    },
    {
      "epoch": 0.075,
      "grad_norm": 1.2067970037460327,
      "learning_rate": 7.889479681590707e-05,
      "loss": 2.328938674926758,
      "memory(GiB)": 22.05,
      "step": 600,
      "token_acc": 0.5289256198347108,
      "train_speed(iter/s)": 0.361616
    },
    {
      "epoch": 0.075625,
      "grad_norm": 0.9518520832061768,
      "learning_rate": 7.887638709587798e-05,
      "loss": 2.0411504745483398,
      "memory(GiB)": 22.05,
      "step": 605,
      "token_acc": 0.5734265734265734,
      "train_speed(iter/s)": 0.361645
    },
    {
      "epoch": 0.07625,
      "grad_norm": 1.7018077373504639,
      "learning_rate": 7.88578274952091e-05,
      "loss": 1.5423151969909668,
      "memory(GiB)": 22.05,
      "step": 610,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.361677
    },
    {
      "epoch": 0.076875,
      "grad_norm": 1.4242631196975708,
      "learning_rate": 7.883911808545345e-05,
      "loss": 2.745341682434082,
      "memory(GiB)": 22.05,
      "step": 615,
      "token_acc": 0.4049586776859504,
      "train_speed(iter/s)": 0.361656
    },
    {
      "epoch": 0.0775,
      "grad_norm": 1.2377263307571411,
      "learning_rate": 7.88202589387417e-05,
      "loss": 2.4251787185668947,
      "memory(GiB)": 22.05,
      "step": 620,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.361633
    },
    {
      "epoch": 0.078125,
      "grad_norm": 5.651135444641113,
      "learning_rate": 7.880125012778177e-05,
      "loss": 3.096056365966797,
      "memory(GiB)": 22.05,
      "step": 625,
      "token_acc": 0.41025641025641024,
      "train_speed(iter/s)": 0.36168
    },
    {
      "epoch": 0.07875,
      "grad_norm": 1.8862788677215576,
      "learning_rate": 7.878209172585855e-05,
      "loss": 2.2661453247070313,
      "memory(GiB)": 22.05,
      "step": 630,
      "token_acc": 0.5398230088495575,
      "train_speed(iter/s)": 0.361731
    },
    {
      "epoch": 0.079375,
      "grad_norm": 1.3651154041290283,
      "learning_rate": 7.876278380683369e-05,
      "loss": 2.751251983642578,
      "memory(GiB)": 22.05,
      "step": 635,
      "token_acc": 0.39655172413793105,
      "train_speed(iter/s)": 0.361707
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.813506007194519,
      "learning_rate": 7.874332644514525e-05,
      "loss": 2.815757942199707,
      "memory(GiB)": 22.05,
      "step": 640,
      "token_acc": 0.46923076923076923,
      "train_speed(iter/s)": 0.361768
    },
    {
      "epoch": 0.080625,
      "grad_norm": 1.674534797668457,
      "learning_rate": 7.872371971580747e-05,
      "loss": 2.605231285095215,
      "memory(GiB)": 22.05,
      "step": 645,
      "token_acc": 0.41935483870967744,
      "train_speed(iter/s)": 0.361701
    },
    {
      "epoch": 0.08125,
      "grad_norm": 1.4533342123031616,
      "learning_rate": 7.87039636944104e-05,
      "loss": 1.546284294128418,
      "memory(GiB)": 22.05,
      "step": 650,
      "token_acc": 0.6102941176470589,
      "train_speed(iter/s)": 0.361745
    },
    {
      "epoch": 0.081875,
      "grad_norm": 1.3962903022766113,
      "learning_rate": 7.86840584571197e-05,
      "loss": 1.8517095565795898,
      "memory(GiB)": 22.05,
      "step": 655,
      "token_acc": 0.5597014925373134,
      "train_speed(iter/s)": 0.361794
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.9753164052963257,
      "learning_rate": 7.86640040806763e-05,
      "loss": 1.8383638381958007,
      "memory(GiB)": 22.05,
      "step": 660,
      "token_acc": 0.5163934426229508,
      "train_speed(iter/s)": 0.361823
    },
    {
      "epoch": 0.083125,
      "grad_norm": 1.3184839487075806,
      "learning_rate": 7.864380064239609e-05,
      "loss": 1.9177995681762696,
      "memory(GiB)": 22.05,
      "step": 665,
      "token_acc": 0.5878378378378378,
      "train_speed(iter/s)": 0.361964
    },
    {
      "epoch": 0.08375,
      "grad_norm": 1.2848726511001587,
      "learning_rate": 7.862344822016963e-05,
      "loss": 2.287553405761719,
      "memory(GiB)": 22.05,
      "step": 670,
      "token_acc": 0.5401459854014599,
      "train_speed(iter/s)": 0.362022
    },
    {
      "epoch": 0.084375,
      "grad_norm": 4.529956340789795,
      "learning_rate": 7.86029468924619e-05,
      "loss": 2.368867874145508,
      "memory(GiB)": 22.05,
      "step": 675,
      "token_acc": 0.5347222222222222,
      "train_speed(iter/s)": 0.361935
    },
    {
      "epoch": 0.085,
      "grad_norm": 1.2674548625946045,
      "learning_rate": 7.858229673831193e-05,
      "loss": 2.033020782470703,
      "memory(GiB)": 22.05,
      "step": 680,
      "token_acc": 0.5538461538461539,
      "train_speed(iter/s)": 0.362167
    },
    {
      "epoch": 0.085625,
      "grad_norm": 2.194671869277954,
      "learning_rate": 7.856149783733252e-05,
      "loss": 2.14208927154541,
      "memory(GiB)": 22.05,
      "step": 685,
      "token_acc": 0.5079365079365079,
      "train_speed(iter/s)": 0.362449
    },
    {
      "epoch": 0.08625,
      "grad_norm": 6.463589668273926,
      "learning_rate": 7.854055026970996e-05,
      "loss": 2.348231887817383,
      "memory(GiB)": 22.05,
      "step": 690,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.362499
    },
    {
      "epoch": 0.086875,
      "grad_norm": 4.068617820739746,
      "learning_rate": 7.851945411620365e-05,
      "loss": 2.354098892211914,
      "memory(GiB)": 22.05,
      "step": 695,
      "token_acc": 0.5210084033613446,
      "train_speed(iter/s)": 0.362513
    },
    {
      "epoch": 0.0875,
      "grad_norm": 3.7354047298431396,
      "learning_rate": 7.849820945814589e-05,
      "loss": 2.077698516845703,
      "memory(GiB)": 22.05,
      "step": 700,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.361227
    },
    {
      "epoch": 0.088125,
      "grad_norm": 1.4959793090820312,
      "learning_rate": 7.847681637744149e-05,
      "loss": 1.7449003219604493,
      "memory(GiB)": 22.05,
      "step": 705,
      "token_acc": 0.5572519083969466,
      "train_speed(iter/s)": 0.358249
    },
    {
      "epoch": 0.08875,
      "grad_norm": 1.374652624130249,
      "learning_rate": 7.845527495656745e-05,
      "loss": 2.260055923461914,
      "memory(GiB)": 22.05,
      "step": 710,
      "token_acc": 0.5214285714285715,
      "train_speed(iter/s)": 0.3575
    },
    {
      "epoch": 0.089375,
      "grad_norm": 6.425623416900635,
      "learning_rate": 7.84335852785727e-05,
      "loss": 2.0448436737060547,
      "memory(GiB)": 22.05,
      "step": 715,
      "token_acc": 0.5271317829457365,
      "train_speed(iter/s)": 0.357138
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8413691520690918,
      "learning_rate": 7.841174742707773e-05,
      "loss": 2.083683967590332,
      "memory(GiB)": 22.05,
      "step": 720,
      "token_acc": 0.49193548387096775,
      "train_speed(iter/s)": 0.355939
    },
    {
      "epoch": 0.090625,
      "grad_norm": 1.7286382913589478,
      "learning_rate": 7.83897614862743e-05,
      "loss": 2.151285934448242,
      "memory(GiB)": 22.05,
      "step": 725,
      "token_acc": 0.576,
      "train_speed(iter/s)": 0.355571
    },
    {
      "epoch": 0.09125,
      "grad_norm": 1.2081462144851685,
      "learning_rate": 7.83676275409251e-05,
      "loss": 2.6315855026245116,
      "memory(GiB)": 22.05,
      "step": 730,
      "token_acc": 0.4921875,
      "train_speed(iter/s)": 0.355245
    },
    {
      "epoch": 0.091875,
      "grad_norm": 1.8225678205490112,
      "learning_rate": 7.83453456763634e-05,
      "loss": 1.7734298706054688,
      "memory(GiB)": 22.05,
      "step": 735,
      "token_acc": 0.5299145299145299,
      "train_speed(iter/s)": 0.35497
    },
    {
      "epoch": 0.0925,
      "grad_norm": 1.2370537519454956,
      "learning_rate": 7.832291597849278e-05,
      "loss": 2.190023994445801,
      "memory(GiB)": 22.05,
      "step": 740,
      "token_acc": 0.49606299212598426,
      "train_speed(iter/s)": 0.354929
    },
    {
      "epoch": 0.093125,
      "grad_norm": 1.1876499652862549,
      "learning_rate": 7.830033853378672e-05,
      "loss": 1.8505165100097656,
      "memory(GiB)": 22.05,
      "step": 745,
      "token_acc": 0.5426356589147286,
      "train_speed(iter/s)": 0.354944
    },
    {
      "epoch": 0.09375,
      "grad_norm": 2.1905887126922607,
      "learning_rate": 7.827761342928836e-05,
      "loss": 2.006153106689453,
      "memory(GiB)": 22.05,
      "step": 750,
      "token_acc": 0.5461538461538461,
      "train_speed(iter/s)": 0.355
    },
    {
      "epoch": 0.094375,
      "grad_norm": 1.823926568031311,
      "learning_rate": 7.825474075261009e-05,
      "loss": 3.1371833801269533,
      "memory(GiB)": 22.05,
      "step": 755,
      "token_acc": 0.38333333333333336,
      "train_speed(iter/s)": 0.355017
    },
    {
      "epoch": 0.095,
      "grad_norm": 5.161891460418701,
      "learning_rate": 7.823172059193321e-05,
      "loss": 2.933157539367676,
      "memory(GiB)": 22.05,
      "step": 760,
      "token_acc": 0.3937007874015748,
      "train_speed(iter/s)": 0.355084
    },
    {
      "epoch": 0.095625,
      "grad_norm": 2.2124054431915283,
      "learning_rate": 7.820855303600768e-05,
      "loss": 2.1835296630859373,
      "memory(GiB)": 22.05,
      "step": 765,
      "token_acc": 0.5038759689922481,
      "train_speed(iter/s)": 0.355184
    },
    {
      "epoch": 0.09625,
      "grad_norm": 1.9930853843688965,
      "learning_rate": 7.818523817415165e-05,
      "loss": 1.8742399215698242,
      "memory(GiB)": 22.05,
      "step": 770,
      "token_acc": 0.5944055944055944,
      "train_speed(iter/s)": 0.35536
    },
    {
      "epoch": 0.096875,
      "grad_norm": 1.3541256189346313,
      "learning_rate": 7.816177609625123e-05,
      "loss": 1.77149658203125,
      "memory(GiB)": 22.05,
      "step": 775,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.355478
    },
    {
      "epoch": 0.0975,
      "grad_norm": 3.9646613597869873,
      "learning_rate": 7.813816689276005e-05,
      "loss": 2.0066383361816404,
      "memory(GiB)": 22.05,
      "step": 780,
      "token_acc": 0.5362318840579711,
      "train_speed(iter/s)": 0.355572
    },
    {
      "epoch": 0.098125,
      "grad_norm": 7.136993885040283,
      "learning_rate": 7.811441065469901e-05,
      "loss": 3.477935791015625,
      "memory(GiB)": 22.05,
      "step": 785,
      "token_acc": 0.36065573770491804,
      "train_speed(iter/s)": 0.355556
    },
    {
      "epoch": 0.09875,
      "grad_norm": 1.3357646465301514,
      "learning_rate": 7.809050747365582e-05,
      "loss": 2.1696283340454103,
      "memory(GiB)": 22.05,
      "step": 790,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.355573
    },
    {
      "epoch": 0.099375,
      "grad_norm": 1.342698335647583,
      "learning_rate": 7.806645744178474e-05,
      "loss": 1.75050048828125,
      "memory(GiB)": 22.05,
      "step": 795,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.355691
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.734743356704712,
      "learning_rate": 7.804226065180615e-05,
      "loss": 1.3919909477233887,
      "memory(GiB)": 22.05,
      "step": 800,
      "token_acc": 0.6370370370370371,
      "train_speed(iter/s)": 0.355829
    },
    {
      "epoch": 0.100625,
      "grad_norm": 2.3969297409057617,
      "learning_rate": 7.801791719700626e-05,
      "loss": 3.2963546752929687,
      "memory(GiB)": 22.05,
      "step": 805,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.355755
    },
    {
      "epoch": 0.10125,
      "grad_norm": 5.182115077972412,
      "learning_rate": 7.799342717123671e-05,
      "loss": 2.9980842590332033,
      "memory(GiB)": 22.05,
      "step": 810,
      "token_acc": 0.3893129770992366,
      "train_speed(iter/s)": 0.355467
    },
    {
      "epoch": 0.101875,
      "grad_norm": 1.7904378175735474,
      "learning_rate": 7.796879066891422e-05,
      "loss": 2.2591785430908202,
      "memory(GiB)": 22.05,
      "step": 815,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.35572
    },
    {
      "epoch": 0.1025,
      "grad_norm": 1.8024218082427979,
      "learning_rate": 7.794400778502018e-05,
      "loss": 1.8385417938232422,
      "memory(GiB)": 22.05,
      "step": 820,
      "token_acc": 0.6031746031746031,
      "train_speed(iter/s)": 0.355956
    },
    {
      "epoch": 0.103125,
      "grad_norm": 1.6982988119125366,
      "learning_rate": 7.791907861510043e-05,
      "loss": 2.5578435897827148,
      "memory(GiB)": 22.05,
      "step": 825,
      "token_acc": 0.4380165289256198,
      "train_speed(iter/s)": 0.356029
    },
    {
      "epoch": 0.10375,
      "grad_norm": 1.9223971366882324,
      "learning_rate": 7.789400325526465e-05,
      "loss": 1.7149173736572265,
      "memory(GiB)": 22.05,
      "step": 830,
      "token_acc": 0.5639097744360902,
      "train_speed(iter/s)": 0.356112
    },
    {
      "epoch": 0.104375,
      "grad_norm": 2.2506332397460938,
      "learning_rate": 7.786878180218626e-05,
      "loss": 2.4131113052368165,
      "memory(GiB)": 22.05,
      "step": 835,
      "token_acc": 0.5121951219512195,
      "train_speed(iter/s)": 0.356167
    },
    {
      "epoch": 0.105,
      "grad_norm": 4.844207286834717,
      "learning_rate": 7.784341435310182e-05,
      "loss": 1.967202377319336,
      "memory(GiB)": 22.05,
      "step": 840,
      "token_acc": 0.5766423357664233,
      "train_speed(iter/s)": 0.356204
    },
    {
      "epoch": 0.105625,
      "grad_norm": 4.328721046447754,
      "learning_rate": 7.781790100581079e-05,
      "loss": 1.7086259841918945,
      "memory(GiB)": 22.05,
      "step": 845,
      "token_acc": 0.628099173553719,
      "train_speed(iter/s)": 0.356307
    },
    {
      "epoch": 0.10625,
      "grad_norm": 1.720809817314148,
      "learning_rate": 7.779224185867513e-05,
      "loss": 2.1177156448364256,
      "memory(GiB)": 22.05,
      "step": 850,
      "token_acc": 0.4957983193277311,
      "train_speed(iter/s)": 0.356408
    },
    {
      "epoch": 0.106875,
      "grad_norm": 1.398409128189087,
      "learning_rate": 7.776643701061885e-05,
      "loss": 1.4510110855102538,
      "memory(GiB)": 22.05,
      "step": 855,
      "token_acc": 0.5859375,
      "train_speed(iter/s)": 0.356543
    },
    {
      "epoch": 0.1075,
      "grad_norm": 1.1765918731689453,
      "learning_rate": 7.774048656112774e-05,
      "loss": 2.4478946685791017,
      "memory(GiB)": 22.05,
      "step": 860,
      "token_acc": 0.488,
      "train_speed(iter/s)": 0.356602
    },
    {
      "epoch": 0.108125,
      "grad_norm": 1.7895324230194092,
      "learning_rate": 7.771439061024892e-05,
      "loss": 2.3606109619140625,
      "memory(GiB)": 22.05,
      "step": 865,
      "token_acc": 0.5193798449612403,
      "train_speed(iter/s)": 0.356623
    },
    {
      "epoch": 0.10875,
      "grad_norm": 1.5877437591552734,
      "learning_rate": 7.76881492585904e-05,
      "loss": 2.337001609802246,
      "memory(GiB)": 22.05,
      "step": 870,
      "token_acc": 0.423728813559322,
      "train_speed(iter/s)": 0.356736
    },
    {
      "epoch": 0.109375,
      "grad_norm": 6.915220260620117,
      "learning_rate": 7.766176260732084e-05,
      "loss": 3.443142318725586,
      "memory(GiB)": 22.05,
      "step": 875,
      "token_acc": 0.35570469798657717,
      "train_speed(iter/s)": 0.355947
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8175631761550903,
      "learning_rate": 7.763523075816903e-05,
      "loss": 1.5360898971557617,
      "memory(GiB)": 22.05,
      "step": 880,
      "token_acc": 0.6134453781512605,
      "train_speed(iter/s)": 0.355874
    },
    {
      "epoch": 0.110625,
      "grad_norm": 1.6071606874465942,
      "learning_rate": 7.760855381342355e-05,
      "loss": 1.6893260955810547,
      "memory(GiB)": 22.05,
      "step": 885,
      "token_acc": 0.6230769230769231,
      "train_speed(iter/s)": 0.355875
    },
    {
      "epoch": 0.11125,
      "grad_norm": 1.3108738660812378,
      "learning_rate": 7.758173187593236e-05,
      "loss": 2.0007455825805662,
      "memory(GiB)": 22.05,
      "step": 890,
      "token_acc": 0.575,
      "train_speed(iter/s)": 0.355872
    },
    {
      "epoch": 0.111875,
      "grad_norm": 1.7772564888000488,
      "learning_rate": 7.755476504910246e-05,
      "loss": 2.17187385559082,
      "memory(GiB)": 22.05,
      "step": 895,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.355938
    },
    {
      "epoch": 0.1125,
      "grad_norm": 1.6440151929855347,
      "learning_rate": 7.752765343689938e-05,
      "loss": 1.9649280548095702,
      "memory(GiB)": 22.05,
      "step": 900,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.356032
    },
    {
      "epoch": 0.113125,
      "grad_norm": 5.059119701385498,
      "learning_rate": 7.750039714384686e-05,
      "loss": 2.588139533996582,
      "memory(GiB)": 22.05,
      "step": 905,
      "token_acc": 0.4076923076923077,
      "train_speed(iter/s)": 0.355917
    },
    {
      "epoch": 0.11375,
      "grad_norm": 1.7217943668365479,
      "learning_rate": 7.747299627502646e-05,
      "loss": 2.3057003021240234,
      "memory(GiB)": 22.05,
      "step": 910,
      "token_acc": 0.5461538461538461,
      "train_speed(iter/s)": 0.355745
    },
    {
      "epoch": 0.114375,
      "grad_norm": 1.6864597797393799,
      "learning_rate": 7.744545093607711e-05,
      "loss": 2.44748592376709,
      "memory(GiB)": 22.05,
      "step": 915,
      "token_acc": 0.5074626865671642,
      "train_speed(iter/s)": 0.355523
    },
    {
      "epoch": 0.115,
      "grad_norm": 2.647778272628784,
      "learning_rate": 7.74177612331947e-05,
      "loss": 2.035471534729004,
      "memory(GiB)": 22.05,
      "step": 920,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.355326
    },
    {
      "epoch": 0.115625,
      "grad_norm": 1.588834285736084,
      "learning_rate": 7.73899272731317e-05,
      "loss": 2.0592918395996094,
      "memory(GiB)": 22.05,
      "step": 925,
      "token_acc": 0.6183206106870229,
      "train_speed(iter/s)": 0.35517
    },
    {
      "epoch": 0.11625,
      "grad_norm": 1.832348346710205,
      "learning_rate": 7.736194916319675e-05,
      "loss": 2.610113525390625,
      "memory(GiB)": 22.05,
      "step": 930,
      "token_acc": 0.527027027027027,
      "train_speed(iter/s)": 0.355027
    },
    {
      "epoch": 0.116875,
      "grad_norm": 4.193082332611084,
      "learning_rate": 7.73338270112542e-05,
      "loss": 2.0078752517700194,
      "memory(GiB)": 22.05,
      "step": 935,
      "token_acc": 0.5746268656716418,
      "train_speed(iter/s)": 0.35487
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.478049874305725,
      "learning_rate": 7.730556092572378e-05,
      "loss": 2.074324035644531,
      "memory(GiB)": 22.05,
      "step": 940,
      "token_acc": 0.5158730158730159,
      "train_speed(iter/s)": 0.35461
    },
    {
      "epoch": 0.118125,
      "grad_norm": 1.3808472156524658,
      "learning_rate": 7.727715101558006e-05,
      "loss": 2.163776969909668,
      "memory(GiB)": 22.05,
      "step": 945,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.354384
    },
    {
      "epoch": 0.11875,
      "grad_norm": 1.4734551906585693,
      "learning_rate": 7.724859739035214e-05,
      "loss": 1.952537727355957,
      "memory(GiB)": 22.05,
      "step": 950,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.354258
    },
    {
      "epoch": 0.119375,
      "grad_norm": 1.4807006120681763,
      "learning_rate": 7.721990016012322e-05,
      "loss": 1.9616443634033203,
      "memory(GiB)": 22.05,
      "step": 955,
      "token_acc": 0.5413533834586466,
      "train_speed(iter/s)": 0.354131
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.7353932857513428,
      "learning_rate": 7.719105943553007e-05,
      "loss": 1.9603939056396484,
      "memory(GiB)": 22.05,
      "step": 960,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.353968
    },
    {
      "epoch": 0.120625,
      "grad_norm": 1.1824371814727783,
      "learning_rate": 7.716207532776271e-05,
      "loss": 2.4679351806640626,
      "memory(GiB)": 22.05,
      "step": 965,
      "token_acc": 0.4868421052631579,
      "train_speed(iter/s)": 0.353767
    },
    {
      "epoch": 0.12125,
      "grad_norm": 5.040292263031006,
      "learning_rate": 7.713294794856396e-05,
      "loss": 1.8630308151245116,
      "memory(GiB)": 22.05,
      "step": 970,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.353617
    },
    {
      "epoch": 0.121875,
      "grad_norm": 4.946776390075684,
      "learning_rate": 7.710367741022897e-05,
      "loss": 2.9492061614990233,
      "memory(GiB)": 22.05,
      "step": 975,
      "token_acc": 0.452991452991453,
      "train_speed(iter/s)": 0.353653
    },
    {
      "epoch": 0.1225,
      "grad_norm": 4.921274185180664,
      "learning_rate": 7.707426382560484e-05,
      "loss": 2.9132997512817385,
      "memory(GiB)": 22.05,
      "step": 980,
      "token_acc": 0.38345864661654133,
      "train_speed(iter/s)": 0.353687
    },
    {
      "epoch": 0.123125,
      "grad_norm": 2.0001280307769775,
      "learning_rate": 7.704470730809014e-05,
      "loss": 3.581581878662109,
      "memory(GiB)": 22.05,
      "step": 985,
      "token_acc": 0.4251968503937008,
      "train_speed(iter/s)": 0.353679
    },
    {
      "epoch": 0.12375,
      "grad_norm": 1.2614476680755615,
      "learning_rate": 7.70150079716345e-05,
      "loss": 2.44311580657959,
      "memory(GiB)": 22.05,
      "step": 990,
      "token_acc": 0.49137931034482757,
      "train_speed(iter/s)": 0.353718
    },
    {
      "epoch": 0.124375,
      "grad_norm": 1.7064470052719116,
      "learning_rate": 7.698516593073814e-05,
      "loss": 2.360190582275391,
      "memory(GiB)": 22.05,
      "step": 995,
      "token_acc": 0.5118110236220472,
      "train_speed(iter/s)": 0.353762
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.458720088005066,
      "learning_rate": 7.695518130045147e-05,
      "loss": 1.4799788475036622,
      "memory(GiB)": 22.05,
      "step": 1000,
      "token_acc": 0.6384615384615384,
      "train_speed(iter/s)": 0.35382
    },
    {
      "epoch": 0.125625,
      "grad_norm": 1.6713567972183228,
      "learning_rate": 7.692505419637466e-05,
      "loss": 2.8815292358398437,
      "memory(GiB)": 22.05,
      "step": 1005,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.353879
    },
    {
      "epoch": 0.12625,
      "grad_norm": 1.5104411840438843,
      "learning_rate": 7.689478473465707e-05,
      "loss": 2.0943729400634767,
      "memory(GiB)": 22.05,
      "step": 1010,
      "token_acc": 0.5851851851851851,
      "train_speed(iter/s)": 0.353914
    },
    {
      "epoch": 0.126875,
      "grad_norm": 3.6796627044677734,
      "learning_rate": 7.6864373031997e-05,
      "loss": 3.110824775695801,
      "memory(GiB)": 22.05,
      "step": 1015,
      "token_acc": 0.421875,
      "train_speed(iter/s)": 0.353964
    },
    {
      "epoch": 0.1275,
      "grad_norm": 1.5436640977859497,
      "learning_rate": 7.683381920564107e-05,
      "loss": 2.517339324951172,
      "memory(GiB)": 22.05,
      "step": 1020,
      "token_acc": 0.5038167938931297,
      "train_speed(iter/s)": 0.35403
    },
    {
      "epoch": 0.128125,
      "grad_norm": 1.8095581531524658,
      "learning_rate": 7.68031233733838e-05,
      "loss": 1.4350282669067382,
      "memory(GiB)": 22.05,
      "step": 1025,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.354132
    },
    {
      "epoch": 0.12875,
      "grad_norm": 1.7264028787612915,
      "learning_rate": 7.677228565356729e-05,
      "loss": 1.6814964294433594,
      "memory(GiB)": 22.05,
      "step": 1030,
      "token_acc": 0.5691056910569106,
      "train_speed(iter/s)": 0.35422
    },
    {
      "epoch": 0.129375,
      "grad_norm": 5.867192268371582,
      "learning_rate": 7.674130616508055e-05,
      "loss": 2.6125980377197267,
      "memory(GiB)": 22.05,
      "step": 1035,
      "token_acc": 0.49586776859504134,
      "train_speed(iter/s)": 0.354279
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8900115489959717,
      "learning_rate": 7.671018502735925e-05,
      "loss": 2.366688919067383,
      "memory(GiB)": 22.05,
      "step": 1040,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.354263
    },
    {
      "epoch": 0.130625,
      "grad_norm": 1.3394099473953247,
      "learning_rate": 7.667892236038509e-05,
      "loss": 2.1226127624511717,
      "memory(GiB)": 22.05,
      "step": 1045,
      "token_acc": 0.5153846153846153,
      "train_speed(iter/s)": 0.3543
    },
    {
      "epoch": 0.13125,
      "grad_norm": 1.8936907052993774,
      "learning_rate": 7.664751828468545e-05,
      "loss": 1.7543462753295898,
      "memory(GiB)": 22.05,
      "step": 1050,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.354384
    },
    {
      "epoch": 0.131875,
      "grad_norm": 3.4524736404418945,
      "learning_rate": 7.661597292133284e-05,
      "loss": 2.367625617980957,
      "memory(GiB)": 22.05,
      "step": 1055,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.354459
    },
    {
      "epoch": 0.1325,
      "grad_norm": 2.1148929595947266,
      "learning_rate": 7.658428639194455e-05,
      "loss": 2.333822822570801,
      "memory(GiB)": 22.05,
      "step": 1060,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.35456
    },
    {
      "epoch": 0.133125,
      "grad_norm": 4.022482395172119,
      "learning_rate": 7.655245881868204e-05,
      "loss": 1.9122301101684571,
      "memory(GiB)": 22.05,
      "step": 1065,
      "token_acc": 0.5254237288135594,
      "train_speed(iter/s)": 0.354612
    },
    {
      "epoch": 0.13375,
      "grad_norm": 1.8670644760131836,
      "learning_rate": 7.652049032425058e-05,
      "loss": 1.7864755630493163,
      "memory(GiB)": 22.05,
      "step": 1070,
      "token_acc": 0.5401459854014599,
      "train_speed(iter/s)": 0.354621
    },
    {
      "epoch": 0.134375,
      "grad_norm": 7.511542320251465,
      "learning_rate": 7.64883810318987e-05,
      "loss": 2.703466796875,
      "memory(GiB)": 22.05,
      "step": 1075,
      "token_acc": 0.464,
      "train_speed(iter/s)": 0.354657
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.5580096244812012,
      "learning_rate": 7.645613106541781e-05,
      "loss": 1.9293279647827148,
      "memory(GiB)": 22.05,
      "step": 1080,
      "token_acc": 0.6148148148148148,
      "train_speed(iter/s)": 0.354716
    },
    {
      "epoch": 0.135625,
      "grad_norm": 1.4108108282089233,
      "learning_rate": 7.64237405491416e-05,
      "loss": 1.6279251098632812,
      "memory(GiB)": 22.05,
      "step": 1085,
      "token_acc": 0.6532258064516129,
      "train_speed(iter/s)": 0.354792
    },
    {
      "epoch": 0.13625,
      "grad_norm": 4.809190273284912,
      "learning_rate": 7.639120960794565e-05,
      "loss": 2.135287857055664,
      "memory(GiB)": 22.05,
      "step": 1090,
      "token_acc": 0.49193548387096775,
      "train_speed(iter/s)": 0.354836
    },
    {
      "epoch": 0.136875,
      "grad_norm": 5.311635971069336,
      "learning_rate": 7.63585383672469e-05,
      "loss": 2.235919189453125,
      "memory(GiB)": 22.05,
      "step": 1095,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.354713
    },
    {
      "epoch": 0.1375,
      "grad_norm": 1.3257637023925781,
      "learning_rate": 7.632572695300326e-05,
      "loss": 1.9365604400634766,
      "memory(GiB)": 22.05,
      "step": 1100,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.354803
    },
    {
      "epoch": 0.138125,
      "grad_norm": 1.4671543836593628,
      "learning_rate": 7.629277549171295e-05,
      "loss": 2.536027526855469,
      "memory(GiB)": 22.05,
      "step": 1105,
      "token_acc": 0.4580152671755725,
      "train_speed(iter/s)": 0.354564
    },
    {
      "epoch": 0.13875,
      "grad_norm": 3.09541392326355,
      "learning_rate": 7.62596841104142e-05,
      "loss": 2.6709209442138673,
      "memory(GiB)": 22.05,
      "step": 1110,
      "token_acc": 0.4740740740740741,
      "train_speed(iter/s)": 0.354405
    },
    {
      "epoch": 0.139375,
      "grad_norm": 2.5388991832733154,
      "learning_rate": 7.622645293668462e-05,
      "loss": 1.9843305587768554,
      "memory(GiB)": 22.05,
      "step": 1115,
      "token_acc": 0.5540540540540541,
      "train_speed(iter/s)": 0.354265
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.8938076496124268,
      "learning_rate": 7.619308209864079e-05,
      "loss": 1.9046234130859374,
      "memory(GiB)": 22.05,
      "step": 1120,
      "token_acc": 0.5602836879432624,
      "train_speed(iter/s)": 0.354311
    },
    {
      "epoch": 0.140625,
      "grad_norm": 4.662811756134033,
      "learning_rate": 7.615957172493774e-05,
      "loss": 2.176839256286621,
      "memory(GiB)": 22.05,
      "step": 1125,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.354347
    },
    {
      "epoch": 0.14125,
      "grad_norm": 1.2271974086761475,
      "learning_rate": 7.612592194476845e-05,
      "loss": 1.7601556777954102,
      "memory(GiB)": 22.05,
      "step": 1130,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.354396
    },
    {
      "epoch": 0.141875,
      "grad_norm": 1.3490327596664429,
      "learning_rate": 7.609213288786334e-05,
      "loss": 1.911835289001465,
      "memory(GiB)": 22.05,
      "step": 1135,
      "token_acc": 0.5507246376811594,
      "train_speed(iter/s)": 0.354442
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.5452584028244019,
      "learning_rate": 7.605820468448983e-05,
      "loss": 1.8371622085571289,
      "memory(GiB)": 22.05,
      "step": 1140,
      "token_acc": 0.5481481481481482,
      "train_speed(iter/s)": 0.354519
    },
    {
      "epoch": 0.143125,
      "grad_norm": 8.503945350646973,
      "learning_rate": 7.602413746545174e-05,
      "loss": 2.046339225769043,
      "memory(GiB)": 22.05,
      "step": 1145,
      "token_acc": 0.5590551181102362,
      "train_speed(iter/s)": 0.354552
    },
    {
      "epoch": 0.14375,
      "grad_norm": 5.3970561027526855,
      "learning_rate": 7.598993136208887e-05,
      "loss": 3.031105804443359,
      "memory(GiB)": 22.05,
      "step": 1150,
      "token_acc": 0.4015151515151515,
      "train_speed(iter/s)": 0.354606
    },
    {
      "epoch": 0.144375,
      "grad_norm": 4.078405380249023,
      "learning_rate": 7.595558650627643e-05,
      "loss": 2.208159828186035,
      "memory(GiB)": 22.05,
      "step": 1155,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.35464
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.7156379222869873,
      "learning_rate": 7.592110303042463e-05,
      "loss": 2.596577835083008,
      "memory(GiB)": 22.05,
      "step": 1160,
      "token_acc": 0.4796747967479675,
      "train_speed(iter/s)": 0.35476
    },
    {
      "epoch": 0.145625,
      "grad_norm": 8.00075912475586,
      "learning_rate": 7.588648106747803e-05,
      "loss": 3.0085784912109377,
      "memory(GiB)": 22.05,
      "step": 1165,
      "token_acc": 0.4263565891472868,
      "train_speed(iter/s)": 0.354796
    },
    {
      "epoch": 0.14625,
      "grad_norm": 1.5662599802017212,
      "learning_rate": 7.585172075091516e-05,
      "loss": 1.8774105072021485,
      "memory(GiB)": 22.05,
      "step": 1170,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.354768
    },
    {
      "epoch": 0.146875,
      "grad_norm": 1.518415093421936,
      "learning_rate": 7.581682221474789e-05,
      "loss": 1.7027999877929687,
      "memory(GiB)": 22.05,
      "step": 1175,
      "token_acc": 0.6356589147286822,
      "train_speed(iter/s)": 0.354781
    },
    {
      "epoch": 0.1475,
      "grad_norm": 3.279376268386841,
      "learning_rate": 7.5781785593521e-05,
      "loss": 2.3868034362792967,
      "memory(GiB)": 22.05,
      "step": 1180,
      "token_acc": 0.5583333333333333,
      "train_speed(iter/s)": 0.354888
    },
    {
      "epoch": 0.148125,
      "grad_norm": 1.6859444379806519,
      "learning_rate": 7.574661102231168e-05,
      "loss": 2.058688735961914,
      "memory(GiB)": 22.05,
      "step": 1185,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.354975
    },
    {
      "epoch": 0.14875,
      "grad_norm": 1.219653606414795,
      "learning_rate": 7.571129863672884e-05,
      "loss": 1.8983903884887696,
      "memory(GiB)": 22.05,
      "step": 1190,
      "token_acc": 0.6015625,
      "train_speed(iter/s)": 0.355043
    },
    {
      "epoch": 0.149375,
      "grad_norm": 1.491075873374939,
      "learning_rate": 7.567584857291283e-05,
      "loss": 2.0561748504638673,
      "memory(GiB)": 22.05,
      "step": 1195,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.355112
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.544041395187378,
      "learning_rate": 7.564026096753472e-05,
      "loss": 2.4766023635864256,
      "memory(GiB)": 22.05,
      "step": 1200,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.355156
    },
    {
      "epoch": 0.150625,
      "grad_norm": 1.3580695390701294,
      "learning_rate": 7.560453595779587e-05,
      "loss": 2.087586212158203,
      "memory(GiB)": 22.05,
      "step": 1205,
      "token_acc": 0.5273972602739726,
      "train_speed(iter/s)": 0.355132
    },
    {
      "epoch": 0.15125,
      "grad_norm": 1.4659048318862915,
      "learning_rate": 7.556867368142738e-05,
      "loss": 2.2413188934326174,
      "memory(GiB)": 22.05,
      "step": 1210,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.354986
    },
    {
      "epoch": 0.151875,
      "grad_norm": 1.4285852909088135,
      "learning_rate": 7.553267427668954e-05,
      "loss": 2.0504955291748046,
      "memory(GiB)": 22.05,
      "step": 1215,
      "token_acc": 0.5785714285714286,
      "train_speed(iter/s)": 0.354913
    },
    {
      "epoch": 0.1525,
      "grad_norm": 4.101473331451416,
      "learning_rate": 7.549653788237134e-05,
      "loss": 2.6767803192138673,
      "memory(GiB)": 22.05,
      "step": 1220,
      "token_acc": 0.4296875,
      "train_speed(iter/s)": 0.355107
    },
    {
      "epoch": 0.153125,
      "grad_norm": 3.876192331314087,
      "learning_rate": 7.546026463778987e-05,
      "loss": 2.340767669677734,
      "memory(GiB)": 22.05,
      "step": 1225,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.355289
    },
    {
      "epoch": 0.15375,
      "grad_norm": 1.3625297546386719,
      "learning_rate": 7.542385468278983e-05,
      "loss": 2.3307029724121096,
      "memory(GiB)": 22.05,
      "step": 1230,
      "token_acc": 0.5220588235294118,
      "train_speed(iter/s)": 0.355544
    },
    {
      "epoch": 0.154375,
      "grad_norm": 1.293561339378357,
      "learning_rate": 7.538730815774303e-05,
      "loss": 1.942378044128418,
      "memory(GiB)": 22.05,
      "step": 1235,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.355518
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.4255070686340332,
      "learning_rate": 7.535062520354775e-05,
      "loss": 2.1255077362060546,
      "memory(GiB)": 22.05,
      "step": 1240,
      "token_acc": 0.4925373134328358,
      "train_speed(iter/s)": 0.355682
    },
    {
      "epoch": 0.155625,
      "grad_norm": 1.9002217054367065,
      "learning_rate": 7.531380596162824e-05,
      "loss": 2.2522201538085938,
      "memory(GiB)": 22.05,
      "step": 1245,
      "token_acc": 0.46616541353383456,
      "train_speed(iter/s)": 0.355665
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.3426238298416138,
      "learning_rate": 7.52768505739342e-05,
      "loss": 2.5176523208618162,
      "memory(GiB)": 22.05,
      "step": 1250,
      "token_acc": 0.44537815126050423,
      "train_speed(iter/s)": 0.355628
    },
    {
      "epoch": 0.156875,
      "grad_norm": 1.412093997001648,
      "learning_rate": 7.523975918294024e-05,
      "loss": 1.905466079711914,
      "memory(GiB)": 22.05,
      "step": 1255,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.355472
    },
    {
      "epoch": 0.1575,
      "grad_norm": 3.483238697052002,
      "learning_rate": 7.520253193164529e-05,
      "loss": 1.9363216400146483,
      "memory(GiB)": 22.05,
      "step": 1260,
      "token_acc": 0.5037037037037037,
      "train_speed(iter/s)": 0.355327
    },
    {
      "epoch": 0.158125,
      "grad_norm": 1.875778079032898,
      "learning_rate": 7.516516896357202e-05,
      "loss": 2.2596084594726564,
      "memory(GiB)": 22.05,
      "step": 1265,
      "token_acc": 0.5234375,
      "train_speed(iter/s)": 0.35536
    },
    {
      "epoch": 0.15875,
      "grad_norm": 4.896336555480957,
      "learning_rate": 7.512767042276638e-05,
      "loss": 3.143903350830078,
      "memory(GiB)": 22.05,
      "step": 1270,
      "token_acc": 0.35714285714285715,
      "train_speed(iter/s)": 0.355409
    },
    {
      "epoch": 0.159375,
      "grad_norm": 4.710414886474609,
      "learning_rate": 7.509003645379697e-05,
      "loss": 2.4263607025146485,
      "memory(GiB)": 22.05,
      "step": 1275,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.355387
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4600249528884888,
      "learning_rate": 7.505226720175455e-05,
      "loss": 2.4466915130615234,
      "memory(GiB)": 22.05,
      "step": 1280,
      "token_acc": 0.4435483870967742,
      "train_speed(iter/s)": 0.355387
    },
    {
      "epoch": 0.160625,
      "grad_norm": 2.2036752700805664,
      "learning_rate": 7.501436281225138e-05,
      "loss": 2.387215232849121,
      "memory(GiB)": 22.05,
      "step": 1285,
      "token_acc": 0.4461538461538462,
      "train_speed(iter/s)": 0.355432
    },
    {
      "epoch": 0.16125,
      "grad_norm": 1.6154958009719849,
      "learning_rate": 7.497632343142076e-05,
      "loss": 2.2333980560302735,
      "memory(GiB)": 22.05,
      "step": 1290,
      "token_acc": 0.46774193548387094,
      "train_speed(iter/s)": 0.355613
    },
    {
      "epoch": 0.161875,
      "grad_norm": 1.3811124563217163,
      "learning_rate": 7.49381492059164e-05,
      "loss": 2.1518882751464843,
      "memory(GiB)": 22.05,
      "step": 1295,
      "token_acc": 0.43089430894308944,
      "train_speed(iter/s)": 0.355838
    },
    {
      "epoch": 0.1625,
      "grad_norm": 3.7145957946777344,
      "learning_rate": 7.48998402829119e-05,
      "loss": 2.3933181762695312,
      "memory(GiB)": 22.05,
      "step": 1300,
      "token_acc": 0.45864661654135336,
      "train_speed(iter/s)": 0.355888
    },
    {
      "epoch": 0.163125,
      "grad_norm": 1.49378502368927,
      "learning_rate": 7.486139681010012e-05,
      "loss": 2.4250244140625,
      "memory(GiB)": 22.05,
      "step": 1305,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.355787
    },
    {
      "epoch": 0.16375,
      "grad_norm": 3.6651451587677,
      "learning_rate": 7.48228189356927e-05,
      "loss": 2.9251726150512694,
      "memory(GiB)": 22.05,
      "step": 1310,
      "token_acc": 0.3969465648854962,
      "train_speed(iter/s)": 0.355691
    },
    {
      "epoch": 0.164375,
      "grad_norm": 1.4351978302001953,
      "learning_rate": 7.478410680841943e-05,
      "loss": 1.2913969039916993,
      "memory(GiB)": 22.05,
      "step": 1315,
      "token_acc": 0.6714285714285714,
      "train_speed(iter/s)": 0.355885
    },
    {
      "epoch": 0.165,
      "grad_norm": 3.3389804363250732,
      "learning_rate": 7.474526057752766e-05,
      "loss": 2.479926872253418,
      "memory(GiB)": 22.05,
      "step": 1320,
      "token_acc": 0.488,
      "train_speed(iter/s)": 0.355895
    },
    {
      "epoch": 0.165625,
      "grad_norm": 1.6469707489013672,
      "learning_rate": 7.470628039278177e-05,
      "loss": 1.6777715682983398,
      "memory(GiB)": 22.05,
      "step": 1325,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.355898
    },
    {
      "epoch": 0.16625,
      "grad_norm": 1.564797282218933,
      "learning_rate": 7.466716640446256e-05,
      "loss": 2.2546628952026366,
      "memory(GiB)": 22.05,
      "step": 1330,
      "token_acc": 0.4728682170542636,
      "train_speed(iter/s)": 0.355833
    },
    {
      "epoch": 0.166875,
      "grad_norm": 2.0351414680480957,
      "learning_rate": 7.462791876336674e-05,
      "loss": 1.737381362915039,
      "memory(GiB)": 22.05,
      "step": 1335,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.355876
    },
    {
      "epoch": 0.1675,
      "grad_norm": 4.604657173156738,
      "learning_rate": 7.458853762080622e-05,
      "loss": 3.1669290542602537,
      "memory(GiB)": 22.05,
      "step": 1340,
      "token_acc": 0.36065573770491804,
      "train_speed(iter/s)": 0.355882
    },
    {
      "epoch": 0.168125,
      "grad_norm": 1.622400164604187,
      "learning_rate": 7.454902312860761e-05,
      "loss": 2.325551986694336,
      "memory(GiB)": 22.05,
      "step": 1345,
      "token_acc": 0.4744525547445255,
      "train_speed(iter/s)": 0.355984
    },
    {
      "epoch": 0.16875,
      "grad_norm": 1.663526177406311,
      "learning_rate": 7.450937543911169e-05,
      "loss": 1.7940687179565429,
      "memory(GiB)": 22.05,
      "step": 1350,
      "token_acc": 0.5488721804511278,
      "train_speed(iter/s)": 0.356171
    },
    {
      "epoch": 0.169375,
      "grad_norm": 2.2135894298553467,
      "learning_rate": 7.446959470517266e-05,
      "loss": 1.6458057403564452,
      "memory(GiB)": 22.05,
      "step": 1355,
      "token_acc": 0.6062992125984252,
      "train_speed(iter/s)": 0.356227
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6596611738204956,
      "learning_rate": 7.442968108015775e-05,
      "loss": 2.1678319931030274,
      "memory(GiB)": 22.05,
      "step": 1360,
      "token_acc": 0.49137931034482757,
      "train_speed(iter/s)": 0.35621
    },
    {
      "epoch": 0.170625,
      "grad_norm": 4.786085605621338,
      "learning_rate": 7.438963471794646e-05,
      "loss": 1.559609603881836,
      "memory(GiB)": 22.05,
      "step": 1365,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.356153
    },
    {
      "epoch": 0.17125,
      "grad_norm": 1.8335988521575928,
      "learning_rate": 7.434945577293002e-05,
      "loss": 2.3647790908813477,
      "memory(GiB)": 22.05,
      "step": 1370,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.356074
    },
    {
      "epoch": 0.171875,
      "grad_norm": 4.130224704742432,
      "learning_rate": 7.430914440001089e-05,
      "loss": 2.180631637573242,
      "memory(GiB)": 22.05,
      "step": 1375,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.356063
    },
    {
      "epoch": 0.1725,
      "grad_norm": 4.0061798095703125,
      "learning_rate": 7.4268700754602e-05,
      "loss": 1.7258005142211914,
      "memory(GiB)": 22.05,
      "step": 1380,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.35604
    },
    {
      "epoch": 0.173125,
      "grad_norm": 1.3867642879486084,
      "learning_rate": 7.422812499262626e-05,
      "loss": 2.0612918853759767,
      "memory(GiB)": 22.05,
      "step": 1385,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.355953
    },
    {
      "epoch": 0.17375,
      "grad_norm": 2.3518662452697754,
      "learning_rate": 7.418741727051592e-05,
      "loss": 1.786214256286621,
      "memory(GiB)": 22.05,
      "step": 1390,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.355894
    },
    {
      "epoch": 0.174375,
      "grad_norm": 1.579498529434204,
      "learning_rate": 7.414657774521201e-05,
      "loss": 1.9812067031860352,
      "memory(GiB)": 22.05,
      "step": 1395,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.355882
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.7555171251296997,
      "learning_rate": 7.41056065741637e-05,
      "loss": 2.8226638793945313,
      "memory(GiB)": 22.05,
      "step": 1400,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.355841
    },
    {
      "epoch": 0.175625,
      "grad_norm": 1.8294812440872192,
      "learning_rate": 7.406450391532764e-05,
      "loss": 1.9316072463989258,
      "memory(GiB)": 22.05,
      "step": 1405,
      "token_acc": 0.576,
      "train_speed(iter/s)": 0.355827
    },
    {
      "epoch": 0.17625,
      "grad_norm": 1.4230892658233643,
      "learning_rate": 7.402326992716746e-05,
      "loss": 1.9879693984985352,
      "memory(GiB)": 22.05,
      "step": 1410,
      "token_acc": 0.5126050420168067,
      "train_speed(iter/s)": 0.355793
    },
    {
      "epoch": 0.176875,
      "grad_norm": 1.4698067903518677,
      "learning_rate": 7.398190476865309e-05,
      "loss": 1.4815160751342773,
      "memory(GiB)": 22.05,
      "step": 1415,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.355761
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.3114378452301025,
      "learning_rate": 7.394040859926015e-05,
      "loss": 1.989111328125,
      "memory(GiB)": 22.05,
      "step": 1420,
      "token_acc": 0.5774647887323944,
      "train_speed(iter/s)": 0.355702
    },
    {
      "epoch": 0.178125,
      "grad_norm": 1.3441863059997559,
      "learning_rate": 7.389878157896938e-05,
      "loss": 1.7570112228393555,
      "memory(GiB)": 22.05,
      "step": 1425,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.355577
    },
    {
      "epoch": 0.17875,
      "grad_norm": 1.578366756439209,
      "learning_rate": 7.385702386826597e-05,
      "loss": 2.068583869934082,
      "memory(GiB)": 22.05,
      "step": 1430,
      "token_acc": 0.528,
      "train_speed(iter/s)": 0.355521
    },
    {
      "epoch": 0.179375,
      "grad_norm": 5.097947597503662,
      "learning_rate": 7.381513562813895e-05,
      "loss": 2.698533630371094,
      "memory(GiB)": 22.05,
      "step": 1435,
      "token_acc": 0.45528455284552843,
      "train_speed(iter/s)": 0.355401
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7356523275375366,
      "learning_rate": 7.377311702008061e-05,
      "loss": 1.8035099029541015,
      "memory(GiB)": 22.05,
      "step": 1440,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.35549
    },
    {
      "epoch": 0.180625,
      "grad_norm": 3.8797895908355713,
      "learning_rate": 7.373096820608584e-05,
      "loss": 2.1456106185913084,
      "memory(GiB)": 22.05,
      "step": 1445,
      "token_acc": 0.5655737704918032,
      "train_speed(iter/s)": 0.355581
    },
    {
      "epoch": 0.18125,
      "grad_norm": 4.091367244720459,
      "learning_rate": 7.368868934865146e-05,
      "loss": 2.6164710998535154,
      "memory(GiB)": 22.05,
      "step": 1450,
      "token_acc": 0.36220472440944884,
      "train_speed(iter/s)": 0.355616
    },
    {
      "epoch": 0.181875,
      "grad_norm": 6.077880382537842,
      "learning_rate": 7.364628061077576e-05,
      "loss": 3.017837715148926,
      "memory(GiB)": 22.05,
      "step": 1455,
      "token_acc": 0.4028776978417266,
      "train_speed(iter/s)": 0.355703
    },
    {
      "epoch": 0.1825,
      "grad_norm": 2.070949077606201,
      "learning_rate": 7.360374215595768e-05,
      "loss": 1.611121368408203,
      "memory(GiB)": 22.05,
      "step": 1460,
      "token_acc": 0.5948275862068966,
      "train_speed(iter/s)": 0.355733
    },
    {
      "epoch": 0.183125,
      "grad_norm": 4.853907585144043,
      "learning_rate": 7.356107414819626e-05,
      "loss": 2.237546920776367,
      "memory(GiB)": 22.05,
      "step": 1465,
      "token_acc": 0.4830508474576271,
      "train_speed(iter/s)": 0.35565
    },
    {
      "epoch": 0.18375,
      "grad_norm": 5.1895575523376465,
      "learning_rate": 7.351827675199005e-05,
      "loss": 2.6369050979614257,
      "memory(GiB)": 22.05,
      "step": 1470,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.355618
    },
    {
      "epoch": 0.184375,
      "grad_norm": 1.3884005546569824,
      "learning_rate": 7.347535013233637e-05,
      "loss": 2.1839147567749024,
      "memory(GiB)": 22.05,
      "step": 1475,
      "token_acc": 0.5761589403973509,
      "train_speed(iter/s)": 0.355602
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.3621747493743896,
      "learning_rate": 7.343229445473082e-05,
      "loss": 1.643155860900879,
      "memory(GiB)": 22.05,
      "step": 1480,
      "token_acc": 0.5895522388059702,
      "train_speed(iter/s)": 0.355608
    },
    {
      "epoch": 0.185625,
      "grad_norm": 1.3102519512176514,
      "learning_rate": 7.338910988516648e-05,
      "loss": 1.593876838684082,
      "memory(GiB)": 22.05,
      "step": 1485,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.355651
    },
    {
      "epoch": 0.18625,
      "grad_norm": 1.855931282043457,
      "learning_rate": 7.334579659013338e-05,
      "loss": 2.4660696029663085,
      "memory(GiB)": 22.05,
      "step": 1490,
      "token_acc": 0.4523809523809524,
      "train_speed(iter/s)": 0.355625
    },
    {
      "epoch": 0.186875,
      "grad_norm": 1.7424300909042358,
      "learning_rate": 7.330235473661784e-05,
      "loss": 2.8167278289794924,
      "memory(GiB)": 22.05,
      "step": 1495,
      "token_acc": 0.4453125,
      "train_speed(iter/s)": 0.355567
    },
    {
      "epoch": 0.1875,
      "grad_norm": 6.3034586906433105,
      "learning_rate": 7.325878449210182e-05,
      "loss": 2.9368900299072265,
      "memory(GiB)": 22.05,
      "step": 1500,
      "token_acc": 0.4461538461538462,
      "train_speed(iter/s)": 0.355529
    },
    {
      "epoch": 0.188125,
      "grad_norm": 1.6889384984970093,
      "learning_rate": 7.321508602456221e-05,
      "loss": 2.138971710205078,
      "memory(GiB)": 22.05,
      "step": 1505,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.355481
    },
    {
      "epoch": 0.18875,
      "grad_norm": 1.514643669128418,
      "learning_rate": 7.317125950247032e-05,
      "loss": 1.7364171981811523,
      "memory(GiB)": 22.05,
      "step": 1510,
      "token_acc": 0.5533333333333333,
      "train_speed(iter/s)": 0.355499
    },
    {
      "epoch": 0.189375,
      "grad_norm": 2.4403882026672363,
      "learning_rate": 7.312730509479107e-05,
      "loss": 2.276047134399414,
      "memory(GiB)": 22.05,
      "step": 1515,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.355608
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4925146102905273,
      "learning_rate": 7.308322297098248e-05,
      "loss": 2.2843557357788087,
      "memory(GiB)": 22.05,
      "step": 1520,
      "token_acc": 0.49624060150375937,
      "train_speed(iter/s)": 0.355689
    },
    {
      "epoch": 0.190625,
      "grad_norm": 9.140519142150879,
      "learning_rate": 7.303901330099493e-05,
      "loss": 2.572518539428711,
      "memory(GiB)": 22.05,
      "step": 1525,
      "token_acc": 0.4928571428571429,
      "train_speed(iter/s)": 0.355858
    },
    {
      "epoch": 0.19125,
      "grad_norm": 2.4918768405914307,
      "learning_rate": 7.299467625527054e-05,
      "loss": 2.2208635330200197,
      "memory(GiB)": 22.05,
      "step": 1530,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.355928
    },
    {
      "epoch": 0.191875,
      "grad_norm": 5.128340721130371,
      "learning_rate": 7.29502120047425e-05,
      "loss": 2.6029731750488283,
      "memory(GiB)": 22.05,
      "step": 1535,
      "token_acc": 0.4375,
      "train_speed(iter/s)": 0.355871
    },
    {
      "epoch": 0.1925,
      "grad_norm": 4.071610450744629,
      "learning_rate": 7.29056207208344e-05,
      "loss": 2.138294982910156,
      "memory(GiB)": 22.05,
      "step": 1540,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.355759
    },
    {
      "epoch": 0.193125,
      "grad_norm": 1.425747036933899,
      "learning_rate": 7.28609025754596e-05,
      "loss": 1.5317718505859375,
      "memory(GiB)": 22.05,
      "step": 1545,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.355746
    },
    {
      "epoch": 0.19375,
      "grad_norm": 5.2487993240356445,
      "learning_rate": 7.281605774102054e-05,
      "loss": 2.334124755859375,
      "memory(GiB)": 22.05,
      "step": 1550,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.355795
    },
    {
      "epoch": 0.194375,
      "grad_norm": 1.7490296363830566,
      "learning_rate": 7.277108639040812e-05,
      "loss": 2.642459487915039,
      "memory(GiB)": 22.05,
      "step": 1555,
      "token_acc": 0.4405594405594406,
      "train_speed(iter/s)": 0.355674
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.329263687133789,
      "learning_rate": 7.272598869700094e-05,
      "loss": 1.8675220489501954,
      "memory(GiB)": 22.05,
      "step": 1560,
      "token_acc": 0.5528455284552846,
      "train_speed(iter/s)": 0.355601
    },
    {
      "epoch": 0.195625,
      "grad_norm": 1.4767310619354248,
      "learning_rate": 7.268076483466475e-05,
      "loss": 1.7508838653564454,
      "memory(GiB)": 22.05,
      "step": 1565,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.355585
    },
    {
      "epoch": 0.19625,
      "grad_norm": 1.590723991394043,
      "learning_rate": 7.263541497775166e-05,
      "loss": 1.680251693725586,
      "memory(GiB)": 22.05,
      "step": 1570,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.35557
    },
    {
      "epoch": 0.196875,
      "grad_norm": 3.1152024269104004,
      "learning_rate": 7.258993930109958e-05,
      "loss": 2.3581396102905274,
      "memory(GiB)": 22.05,
      "step": 1575,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.355464
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.5412771701812744,
      "learning_rate": 7.25443379800315e-05,
      "loss": 1.8353401184082032,
      "memory(GiB)": 22.05,
      "step": 1580,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.35534
    },
    {
      "epoch": 0.198125,
      "grad_norm": 2.234893321990967,
      "learning_rate": 7.249861119035472e-05,
      "loss": 1.4737600326538085,
      "memory(GiB)": 22.05,
      "step": 1585,
      "token_acc": 0.6410256410256411,
      "train_speed(iter/s)": 0.355254
    },
    {
      "epoch": 0.19875,
      "grad_norm": 3.5173730850219727,
      "learning_rate": 7.24527591083604e-05,
      "loss": 2.1132129669189452,
      "memory(GiB)": 22.05,
      "step": 1590,
      "token_acc": 0.512,
      "train_speed(iter/s)": 0.355153
    },
    {
      "epoch": 0.199375,
      "grad_norm": 1.9179620742797852,
      "learning_rate": 7.240678191082264e-05,
      "loss": 1.7639026641845703,
      "memory(GiB)": 22.05,
      "step": 1595,
      "token_acc": 0.5590551181102362,
      "train_speed(iter/s)": 0.35513
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1986632347106934,
      "learning_rate": 7.236067977499791e-05,
      "loss": 2.539267158508301,
      "memory(GiB)": 22.05,
      "step": 1600,
      "token_acc": 0.5241935483870968,
      "train_speed(iter/s)": 0.355064
    },
    {
      "epoch": 0.200625,
      "grad_norm": 1.3764147758483887,
      "learning_rate": 7.231445287862437e-05,
      "loss": 1.6409212112426759,
      "memory(GiB)": 22.05,
      "step": 1605,
      "token_acc": 0.6267605633802817,
      "train_speed(iter/s)": 0.354991
    },
    {
      "epoch": 0.20125,
      "grad_norm": 1.6267225742340088,
      "learning_rate": 7.226810139992121e-05,
      "loss": 2.830088806152344,
      "memory(GiB)": 22.05,
      "step": 1610,
      "token_acc": 0.5241935483870968,
      "train_speed(iter/s)": 0.354986
    },
    {
      "epoch": 0.201875,
      "grad_norm": 1.7798389196395874,
      "learning_rate": 7.222162551758785e-05,
      "loss": 2.3054155349731444,
      "memory(GiB)": 22.05,
      "step": 1615,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.35504
    },
    {
      "epoch": 0.2025,
      "grad_norm": 2.4416744709014893,
      "learning_rate": 7.217502541080338e-05,
      "loss": 2.988551902770996,
      "memory(GiB)": 22.05,
      "step": 1620,
      "token_acc": 0.35664335664335667,
      "train_speed(iter/s)": 0.355019
    },
    {
      "epoch": 0.203125,
      "grad_norm": 1.5458744764328003,
      "learning_rate": 7.21283012592258e-05,
      "loss": 2.264415168762207,
      "memory(GiB)": 22.05,
      "step": 1625,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.354933
    },
    {
      "epoch": 0.20375,
      "grad_norm": 1.4030908346176147,
      "learning_rate": 7.208145324299135e-05,
      "loss": 1.407921314239502,
      "memory(GiB)": 22.05,
      "step": 1630,
      "token_acc": 0.6585365853658537,
      "train_speed(iter/s)": 0.354977
    },
    {
      "epoch": 0.204375,
      "grad_norm": 1.039529800415039,
      "learning_rate": 7.203448154271374e-05,
      "loss": 2.189361000061035,
      "memory(GiB)": 22.05,
      "step": 1635,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.354957
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.6985130310058594,
      "learning_rate": 7.198738633948364e-05,
      "loss": 2.41549129486084,
      "memory(GiB)": 22.05,
      "step": 1640,
      "token_acc": 0.48905109489051096,
      "train_speed(iter/s)": 0.354956
    },
    {
      "epoch": 0.205625,
      "grad_norm": 1.225817084312439,
      "learning_rate": 7.194016781486775e-05,
      "loss": 2.23782958984375,
      "memory(GiB)": 22.05,
      "step": 1645,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.354953
    },
    {
      "epoch": 0.20625,
      "grad_norm": 1.4006069898605347,
      "learning_rate": 7.189282615090829e-05,
      "loss": 2.1577880859375,
      "memory(GiB)": 22.05,
      "step": 1650,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.355022
    },
    {
      "epoch": 0.206875,
      "grad_norm": 0.9286966323852539,
      "learning_rate": 7.184536153012219e-05,
      "loss": 1.7792068481445313,
      "memory(GiB)": 22.05,
      "step": 1655,
      "token_acc": 0.5950413223140496,
      "train_speed(iter/s)": 0.355211
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.2873599529266357,
      "learning_rate": 7.17977741355004e-05,
      "loss": 1.9920110702514648,
      "memory(GiB)": 22.05,
      "step": 1660,
      "token_acc": 0.59375,
      "train_speed(iter/s)": 0.355337
    },
    {
      "epoch": 0.208125,
      "grad_norm": 2.013664484024048,
      "learning_rate": 7.175006415050725e-05,
      "loss": 1.6092262268066406,
      "memory(GiB)": 22.05,
      "step": 1665,
      "token_acc": 0.6434108527131783,
      "train_speed(iter/s)": 0.355539
    },
    {
      "epoch": 0.20875,
      "grad_norm": 3.723010778427124,
      "learning_rate": 7.170223175907965e-05,
      "loss": 2.9467926025390625,
      "memory(GiB)": 22.05,
      "step": 1670,
      "token_acc": 0.4126984126984127,
      "train_speed(iter/s)": 0.355701
    },
    {
      "epoch": 0.209375,
      "grad_norm": 1.4421855211257935,
      "learning_rate": 7.165427714562642e-05,
      "loss": 2.50455265045166,
      "memory(GiB)": 22.05,
      "step": 1675,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.355746
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2649768590927124,
      "learning_rate": 7.160620049502762e-05,
      "loss": 2.924453926086426,
      "memory(GiB)": 22.05,
      "step": 1680,
      "token_acc": 0.4015151515151515,
      "train_speed(iter/s)": 0.355763
    },
    {
      "epoch": 0.210625,
      "grad_norm": 1.3525017499923706,
      "learning_rate": 7.15580019926338e-05,
      "loss": 2.366709899902344,
      "memory(GiB)": 22.05,
      "step": 1685,
      "token_acc": 0.5461538461538461,
      "train_speed(iter/s)": 0.355744
    },
    {
      "epoch": 0.21125,
      "grad_norm": 3.247218132019043,
      "learning_rate": 7.150968182426524e-05,
      "loss": 2.073220062255859,
      "memory(GiB)": 22.05,
      "step": 1690,
      "token_acc": 0.5581395348837209,
      "train_speed(iter/s)": 0.35572
    },
    {
      "epoch": 0.211875,
      "grad_norm": 1.0774726867675781,
      "learning_rate": 7.146124017621134e-05,
      "loss": 2.3762977600097654,
      "memory(GiB)": 22.05,
      "step": 1695,
      "token_acc": 0.5040650406504065,
      "train_speed(iter/s)": 0.355725
    },
    {
      "epoch": 0.2125,
      "grad_norm": 4.165371417999268,
      "learning_rate": 7.14126772352298e-05,
      "loss": 2.418412780761719,
      "memory(GiB)": 22.05,
      "step": 1700,
      "token_acc": 0.4957983193277311,
      "train_speed(iter/s)": 0.355729
    },
    {
      "epoch": 0.213125,
      "grad_norm": 1.5826605558395386,
      "learning_rate": 7.136399318854596e-05,
      "loss": 2.100800895690918,
      "memory(GiB)": 22.05,
      "step": 1705,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.355745
    },
    {
      "epoch": 0.21375,
      "grad_norm": 0.815940260887146,
      "learning_rate": 7.131518822385208e-05,
      "loss": 1.4159578323364257,
      "memory(GiB)": 22.05,
      "step": 1710,
      "token_acc": 0.6870229007633588,
      "train_speed(iter/s)": 0.355789
    },
    {
      "epoch": 0.214375,
      "grad_norm": 1.303062081336975,
      "learning_rate": 7.126626252930653e-05,
      "loss": 2.0379411697387697,
      "memory(GiB)": 22.05,
      "step": 1715,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.355911
    },
    {
      "epoch": 0.215,
      "grad_norm": 4.3105788230896,
      "learning_rate": 7.121721629353319e-05,
      "loss": 2.436116027832031,
      "memory(GiB)": 22.05,
      "step": 1720,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.355867
    },
    {
      "epoch": 0.215625,
      "grad_norm": 3.3763768672943115,
      "learning_rate": 7.116804970562068e-05,
      "loss": 2.299012565612793,
      "memory(GiB)": 22.05,
      "step": 1725,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.355721
    },
    {
      "epoch": 0.21625,
      "grad_norm": 3.5209014415740967,
      "learning_rate": 7.111876295512154e-05,
      "loss": 2.2439138412475588,
      "memory(GiB)": 22.05,
      "step": 1730,
      "token_acc": 0.4878048780487805,
      "train_speed(iter/s)": 0.355749
    },
    {
      "epoch": 0.216875,
      "grad_norm": 2.9394896030426025,
      "learning_rate": 7.106935623205165e-05,
      "loss": 2.554486083984375,
      "memory(GiB)": 22.05,
      "step": 1735,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.355799
    },
    {
      "epoch": 0.2175,
      "grad_norm": 6.082408905029297,
      "learning_rate": 7.101982972688939e-05,
      "loss": 2.9327693939208985,
      "memory(GiB)": 22.05,
      "step": 1740,
      "token_acc": 0.4672131147540984,
      "train_speed(iter/s)": 0.355861
    },
    {
      "epoch": 0.218125,
      "grad_norm": 1.3082011938095093,
      "learning_rate": 7.097018363057492e-05,
      "loss": 2.094737434387207,
      "memory(GiB)": 22.05,
      "step": 1745,
      "token_acc": 0.5343511450381679,
      "train_speed(iter/s)": 0.355879
    },
    {
      "epoch": 0.21875,
      "grad_norm": 3.1863250732421875,
      "learning_rate": 7.092041813450948e-05,
      "loss": 2.9933792114257813,
      "memory(GiB)": 22.05,
      "step": 1750,
      "token_acc": 0.4496124031007752,
      "train_speed(iter/s)": 0.355897
    },
    {
      "epoch": 0.219375,
      "grad_norm": 6.748083114624023,
      "learning_rate": 7.087053343055466e-05,
      "loss": 2.44582576751709,
      "memory(GiB)": 22.05,
      "step": 1755,
      "token_acc": 0.4351145038167939,
      "train_speed(iter/s)": 0.355944
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.559144139289856,
      "learning_rate": 7.082052971103158e-05,
      "loss": 1.799227523803711,
      "memory(GiB)": 22.05,
      "step": 1760,
      "token_acc": 0.5414012738853503,
      "train_speed(iter/s)": 0.35603
    },
    {
      "epoch": 0.220625,
      "grad_norm": 1.5583007335662842,
      "learning_rate": 7.077040716872024e-05,
      "loss": 1.3865958213806153,
      "memory(GiB)": 22.05,
      "step": 1765,
      "token_acc": 0.6692913385826772,
      "train_speed(iter/s)": 0.356019
    },
    {
      "epoch": 0.22125,
      "grad_norm": 1.3364800214767456,
      "learning_rate": 7.072016599685872e-05,
      "loss": 2.4930667877197266,
      "memory(GiB)": 22.05,
      "step": 1770,
      "token_acc": 0.4523809523809524,
      "train_speed(iter/s)": 0.355953
    },
    {
      "epoch": 0.221875,
      "grad_norm": 4.540929317474365,
      "learning_rate": 7.066980638914247e-05,
      "loss": 2.6575349807739257,
      "memory(GiB)": 22.05,
      "step": 1775,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.355954
    },
    {
      "epoch": 0.2225,
      "grad_norm": 2.5194687843322754,
      "learning_rate": 7.061932853972354e-05,
      "loss": 2.948868179321289,
      "memory(GiB)": 22.05,
      "step": 1780,
      "token_acc": 0.43410852713178294,
      "train_speed(iter/s)": 0.355965
    },
    {
      "epoch": 0.223125,
      "grad_norm": 1.390292763710022,
      "learning_rate": 7.056873264320983e-05,
      "loss": 1.7453208923339845,
      "memory(GiB)": 22.05,
      "step": 1785,
      "token_acc": 0.6137931034482759,
      "train_speed(iter/s)": 0.35585
    },
    {
      "epoch": 0.22375,
      "grad_norm": 2.392693519592285,
      "learning_rate": 7.051801889466436e-05,
      "loss": 1.8490951538085938,
      "memory(GiB)": 22.05,
      "step": 1790,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.355794
    },
    {
      "epoch": 0.224375,
      "grad_norm": 4.1963276863098145,
      "learning_rate": 7.04671874896045e-05,
      "loss": 2.517627716064453,
      "memory(GiB)": 22.05,
      "step": 1795,
      "token_acc": 0.45864661654135336,
      "train_speed(iter/s)": 0.355776
    },
    {
      "epoch": 0.225,
      "grad_norm": 3.6887969970703125,
      "learning_rate": 7.041623862400125e-05,
      "loss": 2.16314811706543,
      "memory(GiB)": 22.05,
      "step": 1800,
      "token_acc": 0.5045045045045045,
      "train_speed(iter/s)": 0.355899
    },
    {
      "epoch": 0.225625,
      "grad_norm": 1.777966022491455,
      "learning_rate": 7.03651724942784e-05,
      "loss": 2.2373468399047853,
      "memory(GiB)": 22.05,
      "step": 1805,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.356019
    },
    {
      "epoch": 0.22625,
      "grad_norm": 1.5107450485229492,
      "learning_rate": 7.031398929731188e-05,
      "loss": 2.0004295349121093,
      "memory(GiB)": 22.05,
      "step": 1810,
      "token_acc": 0.5971223021582733,
      "train_speed(iter/s)": 0.356057
    },
    {
      "epoch": 0.226875,
      "grad_norm": 1.5182595252990723,
      "learning_rate": 7.026268923042893e-05,
      "loss": 1.3549575805664062,
      "memory(GiB)": 22.05,
      "step": 1815,
      "token_acc": 0.6466165413533834,
      "train_speed(iter/s)": 0.356068
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.7778778076171875,
      "learning_rate": 7.021127249140735e-05,
      "loss": 2.6531774520874025,
      "memory(GiB)": 22.05,
      "step": 1820,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.356096
    },
    {
      "epoch": 0.228125,
      "grad_norm": 2.189098358154297,
      "learning_rate": 7.015973927847479e-05,
      "loss": 2.394926834106445,
      "memory(GiB)": 22.05,
      "step": 1825,
      "token_acc": 0.4672131147540984,
      "train_speed(iter/s)": 0.356033
    },
    {
      "epoch": 0.22875,
      "grad_norm": 3.984109878540039,
      "learning_rate": 7.010808979030788e-05,
      "loss": 2.32718448638916,
      "memory(GiB)": 22.05,
      "step": 1830,
      "token_acc": 0.4523809523809524,
      "train_speed(iter/s)": 0.356101
    },
    {
      "epoch": 0.229375,
      "grad_norm": 1.1923826932907104,
      "learning_rate": 7.005632422603161e-05,
      "loss": 2.3833711624145506,
      "memory(GiB)": 22.05,
      "step": 1835,
      "token_acc": 0.48214285714285715,
      "train_speed(iter/s)": 0.356243
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3569241762161255,
      "learning_rate": 7.000444278521839e-05,
      "loss": 2.299965667724609,
      "memory(GiB)": 22.05,
      "step": 1840,
      "token_acc": 0.48026315789473684,
      "train_speed(iter/s)": 0.356344
    },
    {
      "epoch": 0.230625,
      "grad_norm": 3.2978270053863525,
      "learning_rate": 6.995244566788742e-05,
      "loss": 1.8569801330566407,
      "memory(GiB)": 22.05,
      "step": 1845,
      "token_acc": 0.5491803278688525,
      "train_speed(iter/s)": 0.356443
    },
    {
      "epoch": 0.23125,
      "grad_norm": 1.277692437171936,
      "learning_rate": 6.990033307450388e-05,
      "loss": 1.9774850845336913,
      "memory(GiB)": 22.05,
      "step": 1850,
      "token_acc": 0.5620437956204379,
      "train_speed(iter/s)": 0.356378
    },
    {
      "epoch": 0.231875,
      "grad_norm": 1.6522198915481567,
      "learning_rate": 6.98481052059781e-05,
      "loss": 1.9956676483154296,
      "memory(GiB)": 22.05,
      "step": 1855,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.356321
    },
    {
      "epoch": 0.2325,
      "grad_norm": 1.2536354064941406,
      "learning_rate": 6.979576226366489e-05,
      "loss": 2.1378299713134767,
      "memory(GiB)": 22.05,
      "step": 1860,
      "token_acc": 0.5546875,
      "train_speed(iter/s)": 0.356155
    },
    {
      "epoch": 0.233125,
      "grad_norm": 1.1884899139404297,
      "learning_rate": 6.974330444936265e-05,
      "loss": 2.144409942626953,
      "memory(GiB)": 22.05,
      "step": 1865,
      "token_acc": 0.46774193548387094,
      "train_speed(iter/s)": 0.356163
    },
    {
      "epoch": 0.23375,
      "grad_norm": 3.8620545864105225,
      "learning_rate": 6.969073196531268e-05,
      "loss": 2.5521781921386717,
      "memory(GiB)": 22.05,
      "step": 1870,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.356278
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.4313746690750122,
      "learning_rate": 6.963804501419837e-05,
      "loss": 1.6910598754882813,
      "memory(GiB)": 22.05,
      "step": 1875,
      "token_acc": 0.5862068965517241,
      "train_speed(iter/s)": 0.356249
    },
    {
      "epoch": 0.235,
      "grad_norm": 2.4015982151031494,
      "learning_rate": 6.95852437991444e-05,
      "loss": 2.4782697677612306,
      "memory(GiB)": 22.05,
      "step": 1880,
      "token_acc": 0.48905109489051096,
      "train_speed(iter/s)": 0.356243
    },
    {
      "epoch": 0.235625,
      "grad_norm": 1.4667612314224243,
      "learning_rate": 6.953232852371596e-05,
      "loss": 1.5413541793823242,
      "memory(GiB)": 22.05,
      "step": 1885,
      "token_acc": 0.6323529411764706,
      "train_speed(iter/s)": 0.35626
    },
    {
      "epoch": 0.23625,
      "grad_norm": 1.5593127012252808,
      "learning_rate": 6.947929939191804e-05,
      "loss": 1.6805759429931642,
      "memory(GiB)": 22.05,
      "step": 1890,
      "token_acc": 0.5546875,
      "train_speed(iter/s)": 0.356303
    },
    {
      "epoch": 0.236875,
      "grad_norm": 1.1642462015151978,
      "learning_rate": 6.94261566081945e-05,
      "loss": 1.8279291152954102,
      "memory(GiB)": 22.05,
      "step": 1895,
      "token_acc": 0.5474452554744526,
      "train_speed(iter/s)": 0.356467
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.413071632385254,
      "learning_rate": 6.937290037742743e-05,
      "loss": 1.891244888305664,
      "memory(GiB)": 22.05,
      "step": 1900,
      "token_acc": 0.5597014925373134,
      "train_speed(iter/s)": 0.356593
    },
    {
      "epoch": 0.238125,
      "grad_norm": 1.1678898334503174,
      "learning_rate": 6.931953090493626e-05,
      "loss": 1.9864051818847657,
      "memory(GiB)": 22.05,
      "step": 1905,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.356549
    },
    {
      "epoch": 0.23875,
      "grad_norm": 3.4099762439727783,
      "learning_rate": 6.9266048396477e-05,
      "loss": 2.056623649597168,
      "memory(GiB)": 22.05,
      "step": 1910,
      "token_acc": 0.5683453237410072,
      "train_speed(iter/s)": 0.356449
    },
    {
      "epoch": 0.239375,
      "grad_norm": 1.4733874797821045,
      "learning_rate": 6.921245305824146e-05,
      "loss": 2.417963981628418,
      "memory(GiB)": 22.05,
      "step": 1915,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.356407
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.246661186218262,
      "learning_rate": 6.915874509685646e-05,
      "loss": 1.948196792602539,
      "memory(GiB)": 22.05,
      "step": 1920,
      "token_acc": 0.578125,
      "train_speed(iter/s)": 0.356421
    },
    {
      "epoch": 0.240625,
      "grad_norm": 1.9628790616989136,
      "learning_rate": 6.9104924719383e-05,
      "loss": 2.29290828704834,
      "memory(GiB)": 22.05,
      "step": 1925,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.356325
    },
    {
      "epoch": 0.24125,
      "grad_norm": 1.8570358753204346,
      "learning_rate": 6.905099213331547e-05,
      "loss": 1.8841991424560547,
      "memory(GiB)": 22.05,
      "step": 1930,
      "token_acc": 0.5234375,
      "train_speed(iter/s)": 0.356356
    },
    {
      "epoch": 0.241875,
      "grad_norm": 4.016757965087891,
      "learning_rate": 6.899694754658086e-05,
      "loss": 3.1241756439208985,
      "memory(GiB)": 22.05,
      "step": 1935,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.35632
    },
    {
      "epoch": 0.2425,
      "grad_norm": 1.3854864835739136,
      "learning_rate": 6.894279116753797e-05,
      "loss": 2.1589824676513674,
      "memory(GiB)": 22.05,
      "step": 1940,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.356269
    },
    {
      "epoch": 0.243125,
      "grad_norm": 1.7173242568969727,
      "learning_rate": 6.888852320497661e-05,
      "loss": 2.5880605697631838,
      "memory(GiB)": 22.05,
      "step": 1945,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.356084
    },
    {
      "epoch": 0.24375,
      "grad_norm": 1.9596571922302246,
      "learning_rate": 6.883414386811676e-05,
      "loss": 1.80975341796875,
      "memory(GiB)": 22.05,
      "step": 1950,
      "token_acc": 0.6015625,
      "train_speed(iter/s)": 0.355972
    },
    {
      "epoch": 0.244375,
      "grad_norm": 1.2306921482086182,
      "learning_rate": 6.877965336660777e-05,
      "loss": 2.0588233947753904,
      "memory(GiB)": 22.05,
      "step": 1955,
      "token_acc": 0.5323741007194245,
      "train_speed(iter/s)": 0.355943
    },
    {
      "epoch": 0.245,
      "grad_norm": 3.337775945663452,
      "learning_rate": 6.872505191052756e-05,
      "loss": 2.3576656341552735,
      "memory(GiB)": 22.05,
      "step": 1960,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.356027
    },
    {
      "epoch": 0.245625,
      "grad_norm": 3.2940127849578857,
      "learning_rate": 6.867033971038186e-05,
      "loss": 1.9397407531738282,
      "memory(GiB)": 22.05,
      "step": 1965,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.35608
    },
    {
      "epoch": 0.24625,
      "grad_norm": 2.036365270614624,
      "learning_rate": 6.861551697710332e-05,
      "loss": 1.4540480613708495,
      "memory(GiB)": 22.05,
      "step": 1970,
      "token_acc": 0.632,
      "train_speed(iter/s)": 0.35617
    },
    {
      "epoch": 0.246875,
      "grad_norm": 2.0054163932800293,
      "learning_rate": 6.856058392205073e-05,
      "loss": 1.8530307769775392,
      "memory(GiB)": 22.05,
      "step": 1975,
      "token_acc": 0.5132743362831859,
      "train_speed(iter/s)": 0.356171
    },
    {
      "epoch": 0.2475,
      "grad_norm": 3.002443790435791,
      "learning_rate": 6.850554075700822e-05,
      "loss": 2.417806625366211,
      "memory(GiB)": 22.05,
      "step": 1980,
      "token_acc": 0.503448275862069,
      "train_speed(iter/s)": 0.356155
    },
    {
      "epoch": 0.248125,
      "grad_norm": 3.522733211517334,
      "learning_rate": 6.845038769418441e-05,
      "loss": 1.9313749313354491,
      "memory(GiB)": 22.05,
      "step": 1985,
      "token_acc": 0.5797101449275363,
      "train_speed(iter/s)": 0.356137
    },
    {
      "epoch": 0.24875,
      "grad_norm": 1.5716521739959717,
      "learning_rate": 6.839512494621162e-05,
      "loss": 1.5294916152954101,
      "memory(GiB)": 22.05,
      "step": 1990,
      "token_acc": 0.6451612903225806,
      "train_speed(iter/s)": 0.355999
    },
    {
      "epoch": 0.249375,
      "grad_norm": 1.4107294082641602,
      "learning_rate": 6.833975272614504e-05,
      "loss": 1.6239015579223632,
      "memory(GiB)": 22.05,
      "step": 1995,
      "token_acc": 0.576,
      "train_speed(iter/s)": 0.355891
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8948025703430176,
      "learning_rate": 6.828427124746191e-05,
      "loss": 1.863190269470215,
      "memory(GiB)": 22.05,
      "step": 2000,
      "token_acc": 0.5422535211267606,
      "train_speed(iter/s)": 0.355997
    },
    {
      "epoch": 0.25,
      "eval_loss": 1.640838623046875,
      "eval_runtime": 5974.7548,
      "eval_samples_per_second": 1.339,
      "eval_steps_per_second": 1.339,
      "eval_token_acc": 0.6041865994027428,
      "step": 2000
    },
    {
      "epoch": 0.250625,
      "grad_norm": 1.083211064338684,
      "learning_rate": 6.82286807240607e-05,
      "loss": 2.28134708404541,
      "memory(GiB)": 22.05,
      "step": 2005,
      "token_acc": 0.6040538584045172,
      "train_speed(iter/s)": 0.172658
    },
    {
      "epoch": 0.25125,
      "grad_norm": 3.432155132293701,
      "learning_rate": 6.817298137026025e-05,
      "loss": 2.451468658447266,
      "memory(GiB)": 22.05,
      "step": 2010,
      "token_acc": 0.44166666666666665,
      "train_speed(iter/s)": 0.172881
    },
    {
      "epoch": 0.251875,
      "grad_norm": 3.1059370040893555,
      "learning_rate": 6.811717340079903e-05,
      "loss": 2.633755683898926,
      "memory(GiB)": 22.05,
      "step": 2015,
      "token_acc": 0.448,
      "train_speed(iter/s)": 0.173097
    },
    {
      "epoch": 0.2525,
      "grad_norm": 2.240327835083008,
      "learning_rate": 6.806125703083424e-05,
      "loss": 1.826352310180664,
      "memory(GiB)": 22.05,
      "step": 2020,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.17332
    },
    {
      "epoch": 0.253125,
      "grad_norm": 2.1639742851257324,
      "learning_rate": 6.800523247594095e-05,
      "loss": 1.8410768508911133,
      "memory(GiB)": 22.05,
      "step": 2025,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.173548
    },
    {
      "epoch": 0.25375,
      "grad_norm": 4.226741313934326,
      "learning_rate": 6.794909995211138e-05,
      "loss": 1.8836915969848633,
      "memory(GiB)": 22.05,
      "step": 2030,
      "token_acc": 0.5703125,
      "train_speed(iter/s)": 0.173781
    },
    {
      "epoch": 0.254375,
      "grad_norm": 1.2641963958740234,
      "learning_rate": 6.789285967575396e-05,
      "loss": 1.6861215591430665,
      "memory(GiB)": 22.05,
      "step": 2035,
      "token_acc": 0.5546218487394958,
      "train_speed(iter/s)": 0.174006
    },
    {
      "epoch": 0.255,
      "grad_norm": 4.041322231292725,
      "learning_rate": 6.783651186369258e-05,
      "loss": 2.6106796264648438,
      "memory(GiB)": 22.05,
      "step": 2040,
      "token_acc": 0.5403225806451613,
      "train_speed(iter/s)": 0.174231
    },
    {
      "epoch": 0.255625,
      "grad_norm": 1.5958117246627808,
      "learning_rate": 6.778005673316568e-05,
      "loss": 2.3658214569091798,
      "memory(GiB)": 22.05,
      "step": 2045,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.174453
    },
    {
      "epoch": 0.25625,
      "grad_norm": 4.184758186340332,
      "learning_rate": 6.772349450182545e-05,
      "loss": 2.180814743041992,
      "memory(GiB)": 22.05,
      "step": 2050,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.174671
    },
    {
      "epoch": 0.256875,
      "grad_norm": 2.973613977432251,
      "learning_rate": 6.7666825387737e-05,
      "loss": 2.407086944580078,
      "memory(GiB)": 22.05,
      "step": 2055,
      "token_acc": 0.3937007874015748,
      "train_speed(iter/s)": 0.174888
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.4628313779830933,
      "learning_rate": 6.761004960937749e-05,
      "loss": 1.8515811920166017,
      "memory(GiB)": 22.05,
      "step": 2060,
      "token_acc": 0.5241935483870968,
      "train_speed(iter/s)": 0.175111
    },
    {
      "epoch": 0.258125,
      "grad_norm": 1.7059085369110107,
      "learning_rate": 6.755316738563534e-05,
      "loss": 1.6564546585083009,
      "memory(GiB)": 22.05,
      "step": 2065,
      "token_acc": 0.546875,
      "train_speed(iter/s)": 0.17533
    },
    {
      "epoch": 0.25875,
      "grad_norm": 3.145439863204956,
      "learning_rate": 6.749617893580932e-05,
      "loss": 2.0108291625976564,
      "memory(GiB)": 22.05,
      "step": 2070,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.175547
    },
    {
      "epoch": 0.259375,
      "grad_norm": 1.801903247833252,
      "learning_rate": 6.743908447960772e-05,
      "loss": 1.83310546875,
      "memory(GiB)": 22.05,
      "step": 2075,
      "token_acc": 0.5379310344827586,
      "train_speed(iter/s)": 0.175766
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5903666019439697,
      "learning_rate": 6.738188423714756e-05,
      "loss": 1.6704395294189454,
      "memory(GiB)": 22.05,
      "step": 2080,
      "token_acc": 0.5895522388059702,
      "train_speed(iter/s)": 0.175986
    },
    {
      "epoch": 0.260625,
      "grad_norm": 3.3484137058258057,
      "learning_rate": 6.732457842895365e-05,
      "loss": 1.7033962249755858,
      "memory(GiB)": 22.05,
      "step": 2085,
      "token_acc": 0.5619834710743802,
      "train_speed(iter/s)": 0.176206
    },
    {
      "epoch": 0.26125,
      "grad_norm": 1.470321536064148,
      "learning_rate": 6.726716727595786e-05,
      "loss": 1.922542190551758,
      "memory(GiB)": 22.05,
      "step": 2090,
      "token_acc": 0.4959349593495935,
      "train_speed(iter/s)": 0.17643
    },
    {
      "epoch": 0.261875,
      "grad_norm": 2.9639780521392822,
      "learning_rate": 6.720965099949811e-05,
      "loss": 2.508056640625,
      "memory(GiB)": 22.05,
      "step": 2095,
      "token_acc": 0.45081967213114754,
      "train_speed(iter/s)": 0.176654
    },
    {
      "epoch": 0.2625,
      "grad_norm": 1.4356944561004639,
      "learning_rate": 6.715202982131768e-05,
      "loss": 1.8121774673461915,
      "memory(GiB)": 22.05,
      "step": 2100,
      "token_acc": 0.5826771653543307,
      "train_speed(iter/s)": 0.176871
    },
    {
      "epoch": 0.263125,
      "grad_norm": 1.6583279371261597,
      "learning_rate": 6.709430396356422e-05,
      "loss": 1.9506654739379883,
      "memory(GiB)": 22.05,
      "step": 2105,
      "token_acc": 0.5428571428571428,
      "train_speed(iter/s)": 0.177088
    },
    {
      "epoch": 0.26375,
      "grad_norm": 1.7365766763687134,
      "learning_rate": 6.7036473648789e-05,
      "loss": 1.6869937896728515,
      "memory(GiB)": 22.05,
      "step": 2110,
      "token_acc": 0.592,
      "train_speed(iter/s)": 0.177304
    },
    {
      "epoch": 0.264375,
      "grad_norm": 2.188551425933838,
      "learning_rate": 6.697853909994597e-05,
      "loss": 1.977305030822754,
      "memory(GiB)": 22.05,
      "step": 2115,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.177514
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.4690073728561401,
      "learning_rate": 6.692050054039094e-05,
      "loss": 2.0048215866088865,
      "memory(GiB)": 22.05,
      "step": 2120,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.177731
    },
    {
      "epoch": 0.265625,
      "grad_norm": 3.2046520709991455,
      "learning_rate": 6.686235819388075e-05,
      "loss": 1.591731357574463,
      "memory(GiB)": 22.05,
      "step": 2125,
      "token_acc": 0.6176470588235294,
      "train_speed(iter/s)": 0.17795
    },
    {
      "epoch": 0.26625,
      "grad_norm": 1.6287208795547485,
      "learning_rate": 6.680411228457231e-05,
      "loss": 2.7220396041870116,
      "memory(GiB)": 22.05,
      "step": 2130,
      "token_acc": 0.448,
      "train_speed(iter/s)": 0.178162
    },
    {
      "epoch": 0.266875,
      "grad_norm": 4.270514965057373,
      "learning_rate": 6.674576303702186e-05,
      "loss": 1.8435962677001954,
      "memory(GiB)": 22.05,
      "step": 2135,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.178381
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.2130577564239502,
      "learning_rate": 6.668731067618399e-05,
      "loss": 2.2256927490234375,
      "memory(GiB)": 22.05,
      "step": 2140,
      "token_acc": 0.539568345323741,
      "train_speed(iter/s)": 0.1786
    },
    {
      "epoch": 0.268125,
      "grad_norm": 0.9919798374176025,
      "learning_rate": 6.662875542741087e-05,
      "loss": 2.1964954376220702,
      "memory(GiB)": 22.05,
      "step": 2145,
      "token_acc": 0.5950413223140496,
      "train_speed(iter/s)": 0.178815
    },
    {
      "epoch": 0.26875,
      "grad_norm": 4.52694034576416,
      "learning_rate": 6.657009751645128e-05,
      "loss": 2.733171844482422,
      "memory(GiB)": 22.05,
      "step": 2150,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.179023
    },
    {
      "epoch": 0.269375,
      "grad_norm": 3.138488292694092,
      "learning_rate": 6.651133716944983e-05,
      "loss": 2.293905830383301,
      "memory(GiB)": 22.05,
      "step": 2155,
      "token_acc": 0.5491803278688525,
      "train_speed(iter/s)": 0.179231
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.7530057430267334,
      "learning_rate": 6.645247461294608e-05,
      "loss": 2.70084228515625,
      "memory(GiB)": 22.05,
      "step": 2160,
      "token_acc": 0.44776119402985076,
      "train_speed(iter/s)": 0.179437
    },
    {
      "epoch": 0.270625,
      "grad_norm": 1.5464396476745605,
      "learning_rate": 6.639351007387359e-05,
      "loss": 2.2336902618408203,
      "memory(GiB)": 22.05,
      "step": 2165,
      "token_acc": 0.5433070866141733,
      "train_speed(iter/s)": 0.179642
    },
    {
      "epoch": 0.27125,
      "grad_norm": 1.0675547122955322,
      "learning_rate": 6.63344437795591e-05,
      "loss": 1.6008316040039063,
      "memory(GiB)": 22.05,
      "step": 2170,
      "token_acc": 0.6062992125984252,
      "train_speed(iter/s)": 0.179853
    },
    {
      "epoch": 0.271875,
      "grad_norm": 3.874891519546509,
      "learning_rate": 6.627527595772166e-05,
      "loss": 2.332309532165527,
      "memory(GiB)": 22.05,
      "step": 2175,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.180068
    },
    {
      "epoch": 0.2725,
      "grad_norm": 4.437802791595459,
      "learning_rate": 6.621600683647175e-05,
      "loss": 3.3551410675048827,
      "memory(GiB)": 22.05,
      "step": 2180,
      "token_acc": 0.3897058823529412,
      "train_speed(iter/s)": 0.180262
    },
    {
      "epoch": 0.273125,
      "grad_norm": 1.960953712463379,
      "learning_rate": 6.615663664431041e-05,
      "loss": 2.701250457763672,
      "memory(GiB)": 22.05,
      "step": 2185,
      "token_acc": 0.4338235294117647,
      "train_speed(iter/s)": 0.18046
    },
    {
      "epoch": 0.27375,
      "grad_norm": 3.8208987712860107,
      "learning_rate": 6.609716561012827e-05,
      "loss": 2.021893119812012,
      "memory(GiB)": 22.05,
      "step": 2190,
      "token_acc": 0.5488721804511278,
      "train_speed(iter/s)": 0.180667
    },
    {
      "epoch": 0.274375,
      "grad_norm": 3.8372323513031006,
      "learning_rate": 6.603759396320481e-05,
      "loss": 3.1058628082275392,
      "memory(GiB)": 22.05,
      "step": 2195,
      "token_acc": 0.371900826446281,
      "train_speed(iter/s)": 0.180867
    },
    {
      "epoch": 0.275,
      "grad_norm": 3.7072536945343018,
      "learning_rate": 6.597792193320734e-05,
      "loss": 2.040371894836426,
      "memory(GiB)": 22.05,
      "step": 2200,
      "token_acc": 0.5144927536231884,
      "train_speed(iter/s)": 0.18107
    },
    {
      "epoch": 0.275625,
      "grad_norm": 4.634270191192627,
      "learning_rate": 6.591814975019025e-05,
      "loss": 2.899812698364258,
      "memory(GiB)": 22.05,
      "step": 2205,
      "token_acc": 0.41911764705882354,
      "train_speed(iter/s)": 0.181269
    },
    {
      "epoch": 0.27625,
      "grad_norm": 3.839768171310425,
      "learning_rate": 6.585827764459401e-05,
      "loss": 2.1096475601196287,
      "memory(GiB)": 22.05,
      "step": 2210,
      "token_acc": 0.5611510791366906,
      "train_speed(iter/s)": 0.181463
    },
    {
      "epoch": 0.276875,
      "grad_norm": 1.3342254161834717,
      "learning_rate": 6.579830584724428e-05,
      "loss": 1.8819450378417968,
      "memory(GiB)": 22.05,
      "step": 2215,
      "token_acc": 0.60431654676259,
      "train_speed(iter/s)": 0.181664
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.9588265419006348,
      "learning_rate": 6.573823458935116e-05,
      "loss": 1.5490219116210937,
      "memory(GiB)": 22.05,
      "step": 2220,
      "token_acc": 0.6357142857142857,
      "train_speed(iter/s)": 0.181863
    },
    {
      "epoch": 0.278125,
      "grad_norm": 3.2693228721618652,
      "learning_rate": 6.567806410250812e-05,
      "loss": 1.7834869384765626,
      "memory(GiB)": 22.05,
      "step": 2225,
      "token_acc": 0.578125,
      "train_speed(iter/s)": 0.182068
    },
    {
      "epoch": 0.27875,
      "grad_norm": 1.9775452613830566,
      "learning_rate": 6.561779461869125e-05,
      "loss": 2.325360870361328,
      "memory(GiB)": 22.05,
      "step": 2230,
      "token_acc": 0.48760330578512395,
      "train_speed(iter/s)": 0.182278
    },
    {
      "epoch": 0.279375,
      "grad_norm": 2.563051462173462,
      "learning_rate": 6.555742637025824e-05,
      "loss": 1.695577049255371,
      "memory(GiB)": 22.05,
      "step": 2235,
      "token_acc": 0.575,
      "train_speed(iter/s)": 0.182483
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.15480637550354,
      "learning_rate": 6.54969595899476e-05,
      "loss": 1.857309913635254,
      "memory(GiB)": 22.05,
      "step": 2240,
      "token_acc": 0.5522388059701493,
      "train_speed(iter/s)": 0.182685
    },
    {
      "epoch": 0.280625,
      "grad_norm": 1.5186673402786255,
      "learning_rate": 6.543639451087768e-05,
      "loss": 2.008587646484375,
      "memory(GiB)": 22.05,
      "step": 2245,
      "token_acc": 0.5447154471544715,
      "train_speed(iter/s)": 0.182874
    },
    {
      "epoch": 0.28125,
      "grad_norm": 3.5724587440490723,
      "learning_rate": 6.537573136654582e-05,
      "loss": 1.4236394882202148,
      "memory(GiB)": 22.05,
      "step": 2250,
      "token_acc": 0.6693548387096774,
      "train_speed(iter/s)": 0.183073
    },
    {
      "epoch": 0.281875,
      "grad_norm": 1.1319265365600586,
      "learning_rate": 6.531497039082744e-05,
      "loss": 2.1375808715820312,
      "memory(GiB)": 22.05,
      "step": 2255,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.183268
    },
    {
      "epoch": 0.2825,
      "grad_norm": 1.4213684797286987,
      "learning_rate": 6.525411181797512e-05,
      "loss": 2.143396759033203,
      "memory(GiB)": 22.05,
      "step": 2260,
      "token_acc": 0.5586206896551724,
      "train_speed(iter/s)": 0.183467
    },
    {
      "epoch": 0.283125,
      "grad_norm": 1.412750005722046,
      "learning_rate": 6.519315588261767e-05,
      "loss": 1.8409765243530274,
      "memory(GiB)": 22.05,
      "step": 2265,
      "token_acc": 0.5905511811023622,
      "train_speed(iter/s)": 0.183669
    },
    {
      "epoch": 0.28375,
      "grad_norm": 3.869776725769043,
      "learning_rate": 6.513210281975935e-05,
      "loss": 2.233432960510254,
      "memory(GiB)": 22.05,
      "step": 2270,
      "token_acc": 0.453125,
      "train_speed(iter/s)": 0.183867
    },
    {
      "epoch": 0.284375,
      "grad_norm": 1.3303086757659912,
      "learning_rate": 6.507095286477879e-05,
      "loss": 2.1860630035400392,
      "memory(GiB)": 22.05,
      "step": 2275,
      "token_acc": 0.5112781954887218,
      "train_speed(iter/s)": 0.184066
    },
    {
      "epoch": 0.285,
      "grad_norm": 9.638951301574707,
      "learning_rate": 6.500970625342822e-05,
      "loss": 3.403363800048828,
      "memory(GiB)": 22.05,
      "step": 2280,
      "token_acc": 0.46621621621621623,
      "train_speed(iter/s)": 0.184261
    },
    {
      "epoch": 0.285625,
      "grad_norm": 1.6381250619888306,
      "learning_rate": 6.494836322183248e-05,
      "loss": 2.4640878677368163,
      "memory(GiB)": 22.05,
      "step": 2285,
      "token_acc": 0.4796747967479675,
      "train_speed(iter/s)": 0.18446
    },
    {
      "epoch": 0.28625,
      "grad_norm": 1.499050498008728,
      "learning_rate": 6.488692400648817e-05,
      "loss": 2.78979434967041,
      "memory(GiB)": 22.05,
      "step": 2290,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.184649
    },
    {
      "epoch": 0.286875,
      "grad_norm": 2.1473023891448975,
      "learning_rate": 6.48253888442627e-05,
      "loss": 2.2335548400878906,
      "memory(GiB)": 22.05,
      "step": 2295,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.184838
    },
    {
      "epoch": 0.2875,
      "grad_norm": 4.214651584625244,
      "learning_rate": 6.476375797239338e-05,
      "loss": 1.7586437225341798,
      "memory(GiB)": 22.05,
      "step": 2300,
      "token_acc": 0.556390977443609,
      "train_speed(iter/s)": 0.185031
    },
    {
      "epoch": 0.288125,
      "grad_norm": 3.5434131622314453,
      "learning_rate": 6.470203162848647e-05,
      "loss": 2.297167205810547,
      "memory(GiB)": 22.05,
      "step": 2305,
      "token_acc": 0.49612403100775193,
      "train_speed(iter/s)": 0.185223
    },
    {
      "epoch": 0.28875,
      "grad_norm": 1.382688045501709,
      "learning_rate": 6.46402100505164e-05,
      "loss": 1.9565650939941406,
      "memory(GiB)": 22.05,
      "step": 2310,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.185405
    },
    {
      "epoch": 0.289375,
      "grad_norm": 2.0267646312713623,
      "learning_rate": 6.457829347682467e-05,
      "loss": 2.061530876159668,
      "memory(GiB)": 22.05,
      "step": 2315,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.185602
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.369418740272522,
      "learning_rate": 6.451628214611907e-05,
      "loss": 2.245804023742676,
      "memory(GiB)": 22.05,
      "step": 2320,
      "token_acc": 0.5428571428571428,
      "train_speed(iter/s)": 0.185797
    },
    {
      "epoch": 0.290625,
      "grad_norm": 1.5219727754592896,
      "learning_rate": 6.445417629747266e-05,
      "loss": 1.7736377716064453,
      "memory(GiB)": 22.05,
      "step": 2325,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.185991
    },
    {
      "epoch": 0.29125,
      "grad_norm": 1.6514173746109009,
      "learning_rate": 6.439197617032296e-05,
      "loss": 1.7963640213012695,
      "memory(GiB)": 22.05,
      "step": 2330,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.186176
    },
    {
      "epoch": 0.291875,
      "grad_norm": 1.5079799890518188,
      "learning_rate": 6.43296820044709e-05,
      "loss": 1.9114980697631836,
      "memory(GiB)": 22.05,
      "step": 2335,
      "token_acc": 0.5590551181102362,
      "train_speed(iter/s)": 0.186369
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.4890964031219482,
      "learning_rate": 6.426729404007999e-05,
      "loss": 1.6885711669921875,
      "memory(GiB)": 22.05,
      "step": 2340,
      "token_acc": 0.5619834710743802,
      "train_speed(iter/s)": 0.18656
    },
    {
      "epoch": 0.293125,
      "grad_norm": 1.484056830406189,
      "learning_rate": 6.420481251767537e-05,
      "loss": 2.300174331665039,
      "memory(GiB)": 22.05,
      "step": 2345,
      "token_acc": 0.4460431654676259,
      "train_speed(iter/s)": 0.186738
    },
    {
      "epoch": 0.29375,
      "grad_norm": 1.254140019416809,
      "learning_rate": 6.414223767814286e-05,
      "loss": 2.0085708618164064,
      "memory(GiB)": 22.05,
      "step": 2350,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.186927
    },
    {
      "epoch": 0.294375,
      "grad_norm": 3.2447681427001953,
      "learning_rate": 6.407956976272805e-05,
      "loss": 2.6979644775390623,
      "memory(GiB)": 22.05,
      "step": 2355,
      "token_acc": 0.4125,
      "train_speed(iter/s)": 0.187112
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.4036692380905151,
      "learning_rate": 6.401680901303537e-05,
      "loss": 1.4456166267395019,
      "memory(GiB)": 22.05,
      "step": 2360,
      "token_acc": 0.6796875,
      "train_speed(iter/s)": 0.187305
    },
    {
      "epoch": 0.295625,
      "grad_norm": 3.641225814819336,
      "learning_rate": 6.395395567102714e-05,
      "loss": 2.093757438659668,
      "memory(GiB)": 22.05,
      "step": 2365,
      "token_acc": 0.6239316239316239,
      "train_speed(iter/s)": 0.187502
    },
    {
      "epoch": 0.29625,
      "grad_norm": 2.2451841831207275,
      "learning_rate": 6.389100997902268e-05,
      "loss": 1.780604934692383,
      "memory(GiB)": 22.05,
      "step": 2370,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.187692
    },
    {
      "epoch": 0.296875,
      "grad_norm": 1.5879623889923096,
      "learning_rate": 6.382797217969734e-05,
      "loss": 2.0882894515991213,
      "memory(GiB)": 22.05,
      "step": 2375,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.187873
    },
    {
      "epoch": 0.2975,
      "grad_norm": 4.756081581115723,
      "learning_rate": 6.376484251608155e-05,
      "loss": 2.235747718811035,
      "memory(GiB)": 22.05,
      "step": 2380,
      "token_acc": 0.5210084033613446,
      "train_speed(iter/s)": 0.188063
    },
    {
      "epoch": 0.298125,
      "grad_norm": 1.5529530048370361,
      "learning_rate": 6.370162123155992e-05,
      "loss": 1.4687175750732422,
      "memory(GiB)": 22.05,
      "step": 2385,
      "token_acc": 0.5801526717557252,
      "train_speed(iter/s)": 0.188229
    },
    {
      "epoch": 0.29875,
      "grad_norm": 3.465057849884033,
      "learning_rate": 6.36383085698703e-05,
      "loss": 1.6283851623535157,
      "memory(GiB)": 22.05,
      "step": 2390,
      "token_acc": 0.6357142857142857,
      "train_speed(iter/s)": 0.188422
    },
    {
      "epoch": 0.299375,
      "grad_norm": 4.478530406951904,
      "learning_rate": 6.35749047751028e-05,
      "loss": 2.6401723861694335,
      "memory(GiB)": 22.05,
      "step": 2395,
      "token_acc": 0.4573643410852713,
      "train_speed(iter/s)": 0.18861
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.848607540130615,
      "learning_rate": 6.351141009169893e-05,
      "loss": 2.7030357360839843,
      "memory(GiB)": 22.05,
      "step": 2400,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.188789
    },
    {
      "epoch": 0.300625,
      "grad_norm": 1.2898993492126465,
      "learning_rate": 6.344782476445053e-05,
      "loss": 1.4512558937072755,
      "memory(GiB)": 22.05,
      "step": 2405,
      "token_acc": 0.616,
      "train_speed(iter/s)": 0.188971
    },
    {
      "epoch": 0.30125,
      "grad_norm": 1.4965461492538452,
      "learning_rate": 6.338414903849895e-05,
      "loss": 2.4341625213623046,
      "memory(GiB)": 22.05,
      "step": 2410,
      "token_acc": 0.5289256198347108,
      "train_speed(iter/s)": 0.189144
    },
    {
      "epoch": 0.301875,
      "grad_norm": 1.4075874090194702,
      "learning_rate": 6.332038315933404e-05,
      "loss": 2.192466163635254,
      "memory(GiB)": 22.05,
      "step": 2415,
      "token_acc": 0.49206349206349204,
      "train_speed(iter/s)": 0.189322
    },
    {
      "epoch": 0.3025,
      "grad_norm": 3.6798858642578125,
      "learning_rate": 6.325652737279323e-05,
      "loss": 2.3854145050048827,
      "memory(GiB)": 22.05,
      "step": 2420,
      "token_acc": 0.5179856115107914,
      "train_speed(iter/s)": 0.189509
    },
    {
      "epoch": 0.303125,
      "grad_norm": 2.5084238052368164,
      "learning_rate": 6.319258192506056e-05,
      "loss": 2.940394401550293,
      "memory(GiB)": 22.05,
      "step": 2425,
      "token_acc": 0.4065040650406504,
      "train_speed(iter/s)": 0.189687
    },
    {
      "epoch": 0.30375,
      "grad_norm": 2.202840805053711,
      "learning_rate": 6.312854706266573e-05,
      "loss": 2.3418983459472655,
      "memory(GiB)": 22.05,
      "step": 2430,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.189868
    },
    {
      "epoch": 0.304375,
      "grad_norm": 4.195931911468506,
      "learning_rate": 6.30644230324832e-05,
      "loss": 2.2548490524291993,
      "memory(GiB)": 22.05,
      "step": 2435,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.190045
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.8756012916564941,
      "learning_rate": 6.300021008173116e-05,
      "loss": 1.327945613861084,
      "memory(GiB)": 22.05,
      "step": 2440,
      "token_acc": 0.6461538461538462,
      "train_speed(iter/s)": 0.190224
    },
    {
      "epoch": 0.305625,
      "grad_norm": 4.39923620223999,
      "learning_rate": 6.293590845797063e-05,
      "loss": 1.5971334457397461,
      "memory(GiB)": 22.05,
      "step": 2445,
      "token_acc": 0.5470085470085471,
      "train_speed(iter/s)": 0.190407
    },
    {
      "epoch": 0.30625,
      "grad_norm": 1.1686123609542847,
      "learning_rate": 6.287151840910449e-05,
      "loss": 1.5640390396118165,
      "memory(GiB)": 22.05,
      "step": 2450,
      "token_acc": 0.6240601503759399,
      "train_speed(iter/s)": 0.190584
    },
    {
      "epoch": 0.306875,
      "grad_norm": 4.372931003570557,
      "learning_rate": 6.280704018337656e-05,
      "loss": 2.8297775268554686,
      "memory(GiB)": 22.05,
      "step": 2455,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.190759
    },
    {
      "epoch": 0.3075,
      "grad_norm": 1.4852991104125977,
      "learning_rate": 6.274247402937057e-05,
      "loss": 2.19759578704834,
      "memory(GiB)": 22.05,
      "step": 2460,
      "token_acc": 0.5413533834586466,
      "train_speed(iter/s)": 0.190939
    },
    {
      "epoch": 0.308125,
      "grad_norm": 1.4064525365829468,
      "learning_rate": 6.267782019600922e-05,
      "loss": 2.3730705261230467,
      "memory(GiB)": 22.05,
      "step": 2465,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.191123
    },
    {
      "epoch": 0.30875,
      "grad_norm": 3.8656833171844482,
      "learning_rate": 6.261307893255332e-05,
      "loss": 2.1319820404052736,
      "memory(GiB)": 22.05,
      "step": 2470,
      "token_acc": 0.4892086330935252,
      "train_speed(iter/s)": 0.191305
    },
    {
      "epoch": 0.309375,
      "grad_norm": 1.8574095964431763,
      "learning_rate": 6.254825048860067e-05,
      "loss": 1.7024164199829102,
      "memory(GiB)": 22.05,
      "step": 2475,
      "token_acc": 0.5982905982905983,
      "train_speed(iter/s)": 0.191486
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.398271918296814,
      "learning_rate": 6.248333511408522e-05,
      "loss": 1.9502727508544921,
      "memory(GiB)": 22.05,
      "step": 2480,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.191665
    },
    {
      "epoch": 0.310625,
      "grad_norm": 1.184758186340332,
      "learning_rate": 6.241833305927608e-05,
      "loss": 2.3159343719482424,
      "memory(GiB)": 22.05,
      "step": 2485,
      "token_acc": 0.518796992481203,
      "train_speed(iter/s)": 0.191843
    },
    {
      "epoch": 0.31125,
      "grad_norm": 5.709011077880859,
      "learning_rate": 6.235324457477646e-05,
      "loss": 3.559207534790039,
      "memory(GiB)": 22.05,
      "step": 2490,
      "token_acc": 0.3937007874015748,
      "train_speed(iter/s)": 0.192024
    },
    {
      "epoch": 0.311875,
      "grad_norm": 3.4078211784362793,
      "learning_rate": 6.22880699115229e-05,
      "loss": 2.358433151245117,
      "memory(GiB)": 22.05,
      "step": 2495,
      "token_acc": 0.4881889763779528,
      "train_speed(iter/s)": 0.192203
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.165501356124878,
      "learning_rate": 6.22228093207841e-05,
      "loss": 2.8248317718505858,
      "memory(GiB)": 22.05,
      "step": 2500,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.192379
    },
    {
      "epoch": 0.313125,
      "grad_norm": 4.760200023651123,
      "learning_rate": 6.215746305416005e-05,
      "loss": 2.254996681213379,
      "memory(GiB)": 22.05,
      "step": 2505,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.19255
    },
    {
      "epoch": 0.31375,
      "grad_norm": 1.9277422428131104,
      "learning_rate": 6.209203136358109e-05,
      "loss": 1.7941646575927734,
      "memory(GiB)": 22.05,
      "step": 2510,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.192722
    },
    {
      "epoch": 0.314375,
      "grad_norm": 3.5339016914367676,
      "learning_rate": 6.202651450130681e-05,
      "loss": 2.1127861022949217,
      "memory(GiB)": 22.05,
      "step": 2515,
      "token_acc": 0.5074626865671642,
      "train_speed(iter/s)": 0.192895
    },
    {
      "epoch": 0.315,
      "grad_norm": 2.957796812057495,
      "learning_rate": 6.196091271992528e-05,
      "loss": 2.3346763610839845,
      "memory(GiB)": 22.05,
      "step": 2520,
      "token_acc": 0.5474452554744526,
      "train_speed(iter/s)": 0.193067
    },
    {
      "epoch": 0.315625,
      "grad_norm": 1.5517438650131226,
      "learning_rate": 6.189522627235188e-05,
      "loss": 1.5450135231018067,
      "memory(GiB)": 22.05,
      "step": 2525,
      "token_acc": 0.608,
      "train_speed(iter/s)": 0.193249
    },
    {
      "epoch": 0.31625,
      "grad_norm": 1.528137445449829,
      "learning_rate": 6.18294554118284e-05,
      "loss": 1.9285783767700195,
      "memory(GiB)": 22.05,
      "step": 2530,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.19342
    },
    {
      "epoch": 0.316875,
      "grad_norm": 4.80593204498291,
      "learning_rate": 6.176360039192213e-05,
      "loss": 3.0632213592529296,
      "memory(GiB)": 22.05,
      "step": 2535,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.193587
    },
    {
      "epoch": 0.3175,
      "grad_norm": 1.8993799686431885,
      "learning_rate": 6.169766146652476e-05,
      "loss": 1.710819625854492,
      "memory(GiB)": 22.05,
      "step": 2540,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.193754
    },
    {
      "epoch": 0.318125,
      "grad_norm": 2.0943689346313477,
      "learning_rate": 6.163163888985148e-05,
      "loss": 2.1387453079223633,
      "memory(GiB)": 22.05,
      "step": 2545,
      "token_acc": 0.4793388429752066,
      "train_speed(iter/s)": 0.19393
    },
    {
      "epoch": 0.31875,
      "grad_norm": 1.529523491859436,
      "learning_rate": 6.156553291644002e-05,
      "loss": 1.752423095703125,
      "memory(GiB)": 22.05,
      "step": 2550,
      "token_acc": 0.6048387096774194,
      "train_speed(iter/s)": 0.194106
    },
    {
      "epoch": 0.319375,
      "grad_norm": 1.3550935983657837,
      "learning_rate": 6.149934380114957e-05,
      "loss": 1.9598161697387695,
      "memory(GiB)": 22.05,
      "step": 2555,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.194276
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2010231018066406,
      "learning_rate": 6.143307179915987e-05,
      "loss": 2.079849433898926,
      "memory(GiB)": 22.05,
      "step": 2560,
      "token_acc": 0.5522388059701493,
      "train_speed(iter/s)": 0.194449
    },
    {
      "epoch": 0.320625,
      "grad_norm": 3.3262839317321777,
      "learning_rate": 6.136671716597027e-05,
      "loss": 2.614425468444824,
      "memory(GiB)": 22.05,
      "step": 2565,
      "token_acc": 0.4435483870967742,
      "train_speed(iter/s)": 0.194617
    },
    {
      "epoch": 0.32125,
      "grad_norm": 3.404054880142212,
      "learning_rate": 6.130028015739862e-05,
      "loss": 2.9150333404541016,
      "memory(GiB)": 22.05,
      "step": 2570,
      "token_acc": 0.42748091603053434,
      "train_speed(iter/s)": 0.19478
    },
    {
      "epoch": 0.321875,
      "grad_norm": 1.4764578342437744,
      "learning_rate": 6.123376102958038e-05,
      "loss": 2.2834863662719727,
      "memory(GiB)": 22.05,
      "step": 2575,
      "token_acc": 0.46564885496183206,
      "train_speed(iter/s)": 0.194949
    },
    {
      "epoch": 0.3225,
      "grad_norm": 3.5350544452667236,
      "learning_rate": 6.116716003896763e-05,
      "loss": 2.384893035888672,
      "memory(GiB)": 22.05,
      "step": 2580,
      "token_acc": 0.4794520547945205,
      "train_speed(iter/s)": 0.195117
    },
    {
      "epoch": 0.323125,
      "grad_norm": 1.3573455810546875,
      "learning_rate": 6.110047744232802e-05,
      "loss": 1.8750062942504884,
      "memory(GiB)": 22.05,
      "step": 2585,
      "token_acc": 0.49193548387096775,
      "train_speed(iter/s)": 0.19529
    },
    {
      "epoch": 0.32375,
      "grad_norm": 1.6938362121582031,
      "learning_rate": 6.103371349674383e-05,
      "loss": 2.365224838256836,
      "memory(GiB)": 22.05,
      "step": 2590,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.195461
    },
    {
      "epoch": 0.324375,
      "grad_norm": 3.7662720680236816,
      "learning_rate": 6.096686845961095e-05,
      "loss": 2.3313220977783202,
      "memory(GiB)": 22.05,
      "step": 2595,
      "token_acc": 0.4732824427480916,
      "train_speed(iter/s)": 0.195628
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.3731770515441895,
      "learning_rate": 6.0899942588637955e-05,
      "loss": 1.897021484375,
      "memory(GiB)": 22.05,
      "step": 2600,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.195796
    },
    {
      "epoch": 0.325625,
      "grad_norm": 1.466524362564087,
      "learning_rate": 6.083293614184501e-05,
      "loss": 1.8693508148193358,
      "memory(GiB)": 22.05,
      "step": 2605,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.195958
    },
    {
      "epoch": 0.32625,
      "grad_norm": 1.4154964685440063,
      "learning_rate": 6.0765849377562925e-05,
      "loss": 2.2943382263183594,
      "memory(GiB)": 22.05,
      "step": 2610,
      "token_acc": 0.4690265486725664,
      "train_speed(iter/s)": 0.196123
    },
    {
      "epoch": 0.326875,
      "grad_norm": 1.4294092655181885,
      "learning_rate": 6.069868255443218e-05,
      "loss": 1.8381013870239258,
      "memory(GiB)": 22.05,
      "step": 2615,
      "token_acc": 0.5923076923076923,
      "train_speed(iter/s)": 0.196278
    },
    {
      "epoch": 0.3275,
      "grad_norm": 2.390929698944092,
      "learning_rate": 6.06314359314019e-05,
      "loss": 1.5047934532165528,
      "memory(GiB)": 22.05,
      "step": 2620,
      "token_acc": 0.6083333333333333,
      "train_speed(iter/s)": 0.196434
    },
    {
      "epoch": 0.328125,
      "grad_norm": 5.264823913574219,
      "learning_rate": 6.056410976772887e-05,
      "loss": 2.1709568023681642,
      "memory(GiB)": 22.05,
      "step": 2625,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.196575
    },
    {
      "epoch": 0.32875,
      "grad_norm": 2.1272387504577637,
      "learning_rate": 6.049670432297653e-05,
      "loss": 2.6283288955688477,
      "memory(GiB)": 22.05,
      "step": 2630,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.196737
    },
    {
      "epoch": 0.329375,
      "grad_norm": 0.9911550879478455,
      "learning_rate": 6.042921985701394e-05,
      "loss": 1.9173648834228516,
      "memory(GiB)": 22.05,
      "step": 2635,
      "token_acc": 0.5289256198347108,
      "train_speed(iter/s)": 0.196922
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8138257265090942,
      "learning_rate": 6.036165663001486e-05,
      "loss": 2.6576709747314453,
      "memory(GiB)": 22.05,
      "step": 2640,
      "token_acc": 0.4492753623188406,
      "train_speed(iter/s)": 0.197054
    },
    {
      "epoch": 0.330625,
      "grad_norm": 1.680385947227478,
      "learning_rate": 6.0294014902456665e-05,
      "loss": 2.3167579650878904,
      "memory(GiB)": 22.05,
      "step": 2645,
      "token_acc": 0.49230769230769234,
      "train_speed(iter/s)": 0.197194
    },
    {
      "epoch": 0.33125,
      "grad_norm": 5.188974380493164,
      "learning_rate": 6.022629493511939e-05,
      "loss": 2.9814401626586915,
      "memory(GiB)": 22.05,
      "step": 2650,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.197333
    },
    {
      "epoch": 0.331875,
      "grad_norm": 3.811201810836792,
      "learning_rate": 6.01584969890847e-05,
      "loss": 2.366851043701172,
      "memory(GiB)": 22.05,
      "step": 2655,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.197477
    },
    {
      "epoch": 0.3325,
      "grad_norm": 3.9025208950042725,
      "learning_rate": 6.00906213257349e-05,
      "loss": 3.0231433868408204,
      "memory(GiB)": 22.05,
      "step": 2660,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.197631
    },
    {
      "epoch": 0.333125,
      "grad_norm": 1.4040098190307617,
      "learning_rate": 6.002266820675193e-05,
      "loss": 1.4298032760620116,
      "memory(GiB)": 22.05,
      "step": 2665,
      "token_acc": 0.6484375,
      "train_speed(iter/s)": 0.197797
    },
    {
      "epoch": 0.33375,
      "grad_norm": 1.3908591270446777,
      "learning_rate": 5.99546378941163e-05,
      "loss": 2.0474992752075196,
      "memory(GiB)": 22.05,
      "step": 2670,
      "token_acc": 0.5522388059701493,
      "train_speed(iter/s)": 0.197956
    },
    {
      "epoch": 0.334375,
      "grad_norm": 3.5128087997436523,
      "learning_rate": 5.988653065010618e-05,
      "loss": 2.181230926513672,
      "memory(GiB)": 22.05,
      "step": 2675,
      "token_acc": 0.5433070866141733,
      "train_speed(iter/s)": 0.198115
    },
    {
      "epoch": 0.335,
      "grad_norm": 8.121283531188965,
      "learning_rate": 5.981834673729631e-05,
      "loss": 3.156988334655762,
      "memory(GiB)": 22.05,
      "step": 2680,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.198274
    },
    {
      "epoch": 0.335625,
      "grad_norm": 1.599379301071167,
      "learning_rate": 5.9750086418557005e-05,
      "loss": 1.881545639038086,
      "memory(GiB)": 22.05,
      "step": 2685,
      "token_acc": 0.568,
      "train_speed(iter/s)": 0.198439
    },
    {
      "epoch": 0.33625,
      "grad_norm": 3.258434772491455,
      "learning_rate": 5.9681749957053165e-05,
      "loss": 2.246723937988281,
      "memory(GiB)": 22.05,
      "step": 2690,
      "token_acc": 0.49645390070921985,
      "train_speed(iter/s)": 0.198603
    },
    {
      "epoch": 0.336875,
      "grad_norm": 1.2194654941558838,
      "learning_rate": 5.961333761624324e-05,
      "loss": 2.4534778594970703,
      "memory(GiB)": 22.05,
      "step": 2695,
      "token_acc": 0.4806201550387597,
      "train_speed(iter/s)": 0.19877
    },
    {
      "epoch": 0.3375,
      "grad_norm": 2.1467764377593994,
      "learning_rate": 5.9544849659878206e-05,
      "loss": 2.33033447265625,
      "memory(GiB)": 22.05,
      "step": 2700,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.198933
    },
    {
      "epoch": 0.338125,
      "grad_norm": 1.090043544769287,
      "learning_rate": 5.9476286352000574e-05,
      "loss": 2.8102510452270506,
      "memory(GiB)": 22.05,
      "step": 2705,
      "token_acc": 0.423728813559322,
      "train_speed(iter/s)": 0.19909
    },
    {
      "epoch": 0.33875,
      "grad_norm": 1.3937597274780273,
      "learning_rate": 5.940764795694335e-05,
      "loss": 2.1854042053222655,
      "memory(GiB)": 22.05,
      "step": 2710,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.199254
    },
    {
      "epoch": 0.339375,
      "grad_norm": 1.2789428234100342,
      "learning_rate": 5.9338934739329064e-05,
      "loss": 1.346017074584961,
      "memory(GiB)": 22.05,
      "step": 2715,
      "token_acc": 0.664179104477612,
      "train_speed(iter/s)": 0.199417
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.093527793884277,
      "learning_rate": 5.9270146964068614e-05,
      "loss": 2.338277244567871,
      "memory(GiB)": 22.05,
      "step": 2720,
      "token_acc": 0.49606299212598426,
      "train_speed(iter/s)": 0.199577
    },
    {
      "epoch": 0.340625,
      "grad_norm": 1.3640199899673462,
      "learning_rate": 5.9201284896360454e-05,
      "loss": 1.9605112075805664,
      "memory(GiB)": 22.05,
      "step": 2725,
      "token_acc": 0.5390625,
      "train_speed(iter/s)": 0.199736
    },
    {
      "epoch": 0.34125,
      "grad_norm": 1.8343353271484375,
      "learning_rate": 5.9132348801689384e-05,
      "loss": 1.5163668632507323,
      "memory(GiB)": 22.05,
      "step": 2730,
      "token_acc": 0.6587301587301587,
      "train_speed(iter/s)": 0.199899
    },
    {
      "epoch": 0.341875,
      "grad_norm": 1.465149998664856,
      "learning_rate": 5.906333894582563e-05,
      "loss": 1.775990104675293,
      "memory(GiB)": 22.05,
      "step": 2735,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.200057
    },
    {
      "epoch": 0.3425,
      "grad_norm": 2.017307996749878,
      "learning_rate": 5.899425559482378e-05,
      "loss": 1.6413019180297852,
      "memory(GiB)": 22.05,
      "step": 2740,
      "token_acc": 0.6434108527131783,
      "train_speed(iter/s)": 0.200219
    },
    {
      "epoch": 0.343125,
      "grad_norm": 1.0808063745498657,
      "learning_rate": 5.89250990150218e-05,
      "loss": 1.742044448852539,
      "memory(GiB)": 22.05,
      "step": 2745,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.200384
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.333058476448059,
      "learning_rate": 5.8855869473039924e-05,
      "loss": 2.229608345031738,
      "memory(GiB)": 22.05,
      "step": 2750,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.200543
    },
    {
      "epoch": 0.344375,
      "grad_norm": 5.392983913421631,
      "learning_rate": 5.878656723577969e-05,
      "loss": 2.362833786010742,
      "memory(GiB)": 22.05,
      "step": 2755,
      "token_acc": 0.5169491525423728,
      "train_speed(iter/s)": 0.200703
    },
    {
      "epoch": 0.345,
      "grad_norm": 2.138160228729248,
      "learning_rate": 5.871719257042294e-05,
      "loss": 1.8807655334472657,
      "memory(GiB)": 22.05,
      "step": 2760,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.200865
    },
    {
      "epoch": 0.345625,
      "grad_norm": 1.8584141731262207,
      "learning_rate": 5.864774574443072e-05,
      "loss": 1.8123041152954102,
      "memory(GiB)": 22.05,
      "step": 2765,
      "token_acc": 0.5447761194029851,
      "train_speed(iter/s)": 0.201028
    },
    {
      "epoch": 0.34625,
      "grad_norm": 1.3257200717926025,
      "learning_rate": 5.8578227025542267e-05,
      "loss": 1.3575405120849608,
      "memory(GiB)": 22.05,
      "step": 2770,
      "token_acc": 0.6333333333333333,
      "train_speed(iter/s)": 0.201183
    },
    {
      "epoch": 0.346875,
      "grad_norm": 2.141855001449585,
      "learning_rate": 5.8508636681774017e-05,
      "loss": 2.551423454284668,
      "memory(GiB)": 22.05,
      "step": 2775,
      "token_acc": 0.47101449275362317,
      "train_speed(iter/s)": 0.201347
    },
    {
      "epoch": 0.3475,
      "grad_norm": 3.1280272006988525,
      "learning_rate": 5.84389749814185e-05,
      "loss": 2.089363861083984,
      "memory(GiB)": 22.05,
      "step": 2780,
      "token_acc": 0.47540983606557374,
      "train_speed(iter/s)": 0.201506
    },
    {
      "epoch": 0.348125,
      "grad_norm": 4.825096607208252,
      "learning_rate": 5.8369242193043395e-05,
      "loss": 2.210035705566406,
      "memory(GiB)": 22.05,
      "step": 2785,
      "token_acc": 0.5633802816901409,
      "train_speed(iter/s)": 0.201667
    },
    {
      "epoch": 0.34875,
      "grad_norm": 3.3458659648895264,
      "learning_rate": 5.829943858549042e-05,
      "loss": 2.5273099899291993,
      "memory(GiB)": 22.05,
      "step": 2790,
      "token_acc": 0.38345864661654133,
      "train_speed(iter/s)": 0.201824
    },
    {
      "epoch": 0.349375,
      "grad_norm": 4.0586113929748535,
      "learning_rate": 5.822956442787433e-05,
      "loss": 1.8168594360351562,
      "memory(GiB)": 22.05,
      "step": 2795,
      "token_acc": 0.6068376068376068,
      "train_speed(iter/s)": 0.201998
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.6338348388671875,
      "learning_rate": 5.8159619989581874e-05,
      "loss": 2.1660207748413085,
      "memory(GiB)": 22.05,
      "step": 2800,
      "token_acc": 0.5691056910569106,
      "train_speed(iter/s)": 0.202156
    },
    {
      "epoch": 0.350625,
      "grad_norm": 2.095705032348633,
      "learning_rate": 5.808960554027075e-05,
      "loss": 2.0033512115478516,
      "memory(GiB)": 22.05,
      "step": 2805,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.20231
    },
    {
      "epoch": 0.35125,
      "grad_norm": 1.8675516843795776,
      "learning_rate": 5.801952134986858e-05,
      "loss": 2.4512306213378907,
      "memory(GiB)": 22.05,
      "step": 2810,
      "token_acc": 0.46825396825396826,
      "train_speed(iter/s)": 0.202464
    },
    {
      "epoch": 0.351875,
      "grad_norm": 5.025633335113525,
      "learning_rate": 5.794936768857183e-05,
      "loss": 2.2708362579345702,
      "memory(GiB)": 22.05,
      "step": 2815,
      "token_acc": 0.472,
      "train_speed(iter/s)": 0.202622
    },
    {
      "epoch": 0.3525,
      "grad_norm": 1.253568410873413,
      "learning_rate": 5.787914482684485e-05,
      "loss": 2.2255760192871095,
      "memory(GiB)": 22.05,
      "step": 2820,
      "token_acc": 0.6015037593984962,
      "train_speed(iter/s)": 0.202776
    },
    {
      "epoch": 0.353125,
      "grad_norm": 2.2903385162353516,
      "learning_rate": 5.7808853035418736e-05,
      "loss": 2.024211311340332,
      "memory(GiB)": 22.05,
      "step": 2825,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.20293
    },
    {
      "epoch": 0.35375,
      "grad_norm": 1.251103401184082,
      "learning_rate": 5.773849258529034e-05,
      "loss": 2.161915588378906,
      "memory(GiB)": 22.05,
      "step": 2830,
      "token_acc": 0.46218487394957986,
      "train_speed(iter/s)": 0.203086
    },
    {
      "epoch": 0.354375,
      "grad_norm": 1.1379458904266357,
      "learning_rate": 5.766806374772123e-05,
      "loss": 2.2584907531738283,
      "memory(GiB)": 22.05,
      "step": 2835,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.203234
    },
    {
      "epoch": 0.355,
      "grad_norm": 4.102532386779785,
      "learning_rate": 5.759756679423661e-05,
      "loss": 2.0783802032470704,
      "memory(GiB)": 22.05,
      "step": 2840,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.203381
    },
    {
      "epoch": 0.355625,
      "grad_norm": 1.209791898727417,
      "learning_rate": 5.75270019966243e-05,
      "loss": 2.0721473693847656,
      "memory(GiB)": 22.05,
      "step": 2845,
      "token_acc": 0.5916666666666667,
      "train_speed(iter/s)": 0.203515
    },
    {
      "epoch": 0.35625,
      "grad_norm": 4.853459358215332,
      "learning_rate": 5.745636962693368e-05,
      "loss": 2.6805530548095704,
      "memory(GiB)": 22.05,
      "step": 2850,
      "token_acc": 0.475177304964539,
      "train_speed(iter/s)": 0.203666
    },
    {
      "epoch": 0.356875,
      "grad_norm": 3.9043688774108887,
      "learning_rate": 5.7385669957474656e-05,
      "loss": 1.9804058074951172,
      "memory(GiB)": 22.05,
      "step": 2855,
      "token_acc": 0.562962962962963,
      "train_speed(iter/s)": 0.20382
    },
    {
      "epoch": 0.3575,
      "grad_norm": 4.586770534515381,
      "learning_rate": 5.731490326081657e-05,
      "loss": 2.2596607208251953,
      "memory(GiB)": 22.05,
      "step": 2860,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.203968
    },
    {
      "epoch": 0.358125,
      "grad_norm": 2.1335248947143555,
      "learning_rate": 5.7244069809787165e-05,
      "loss": 2.472047805786133,
      "memory(GiB)": 22.05,
      "step": 2865,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.204121
    },
    {
      "epoch": 0.35875,
      "grad_norm": 4.075613498687744,
      "learning_rate": 5.71731698774716e-05,
      "loss": 1.6714061737060546,
      "memory(GiB)": 22.05,
      "step": 2870,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.204272
    },
    {
      "epoch": 0.359375,
      "grad_norm": 2.126655340194702,
      "learning_rate": 5.710220373721129e-05,
      "loss": 1.8906692504882812,
      "memory(GiB)": 22.05,
      "step": 2875,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.204428
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.605289936065674,
      "learning_rate": 5.703117166260291e-05,
      "loss": 2.6647293090820314,
      "memory(GiB)": 22.05,
      "step": 2880,
      "token_acc": 0.408,
      "train_speed(iter/s)": 0.204582
    },
    {
      "epoch": 0.360625,
      "grad_norm": 1.064284086227417,
      "learning_rate": 5.6960073927497354e-05,
      "loss": 1.6715087890625,
      "memory(GiB)": 22.05,
      "step": 2885,
      "token_acc": 0.6119402985074627,
      "train_speed(iter/s)": 0.204734
    },
    {
      "epoch": 0.36125,
      "grad_norm": 1.6078687906265259,
      "learning_rate": 5.688891080599862e-05,
      "loss": 2.3118413925170898,
      "memory(GiB)": 22.05,
      "step": 2890,
      "token_acc": 0.48091603053435117,
      "train_speed(iter/s)": 0.204885
    },
    {
      "epoch": 0.361875,
      "grad_norm": 3.120028018951416,
      "learning_rate": 5.681768257246284e-05,
      "loss": 1.7821136474609376,
      "memory(GiB)": 22.05,
      "step": 2895,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.205032
    },
    {
      "epoch": 0.3625,
      "grad_norm": 1.2763751745224,
      "learning_rate": 5.674638950149713e-05,
      "loss": 2.2907947540283202,
      "memory(GiB)": 22.05,
      "step": 2900,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.205176
    },
    {
      "epoch": 0.363125,
      "grad_norm": 1.5032726526260376,
      "learning_rate": 5.66750318679586e-05,
      "loss": 1.972137451171875,
      "memory(GiB)": 22.05,
      "step": 2905,
      "token_acc": 0.5619834710743802,
      "train_speed(iter/s)": 0.205325
    },
    {
      "epoch": 0.36375,
      "grad_norm": 1.2295337915420532,
      "learning_rate": 5.6603609946953256e-05,
      "loss": 1.5994250297546386,
      "memory(GiB)": 22.05,
      "step": 2910,
      "token_acc": 0.6287878787878788,
      "train_speed(iter/s)": 0.205476
    },
    {
      "epoch": 0.364375,
      "grad_norm": 1.214989185333252,
      "learning_rate": 5.6532124013834954e-05,
      "loss": 2.2661764144897463,
      "memory(GiB)": 22.05,
      "step": 2915,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.205625
    },
    {
      "epoch": 0.365,
      "grad_norm": 3.5860817432403564,
      "learning_rate": 5.646057434420436e-05,
      "loss": 3.598817825317383,
      "memory(GiB)": 22.05,
      "step": 2920,
      "token_acc": 0.2809917355371901,
      "train_speed(iter/s)": 0.205773
    },
    {
      "epoch": 0.365625,
      "grad_norm": 3.5948798656463623,
      "learning_rate": 5.638896121390782e-05,
      "loss": 1.6336238861083985,
      "memory(GiB)": 22.05,
      "step": 2925,
      "token_acc": 0.6183206106870229,
      "train_speed(iter/s)": 0.205922
    },
    {
      "epoch": 0.36625,
      "grad_norm": 1.1141160726547241,
      "learning_rate": 5.631728489903637e-05,
      "loss": 1.7198604583740233,
      "memory(GiB)": 22.05,
      "step": 2930,
      "token_acc": 0.6166666666666667,
      "train_speed(iter/s)": 0.206075
    },
    {
      "epoch": 0.366875,
      "grad_norm": 2.3336753845214844,
      "learning_rate": 5.624554567592465e-05,
      "loss": 2.095917510986328,
      "memory(GiB)": 22.05,
      "step": 2935,
      "token_acc": 0.518796992481203,
      "train_speed(iter/s)": 0.20622
    },
    {
      "epoch": 0.3675,
      "grad_norm": 3.8193657398223877,
      "learning_rate": 5.617374382114981e-05,
      "loss": 3.0984519958496093,
      "memory(GiB)": 22.05,
      "step": 2940,
      "token_acc": 0.391304347826087,
      "train_speed(iter/s)": 0.206364
    },
    {
      "epoch": 0.368125,
      "grad_norm": 0.9916272759437561,
      "learning_rate": 5.610187961153046e-05,
      "loss": 1.3338729858398437,
      "memory(GiB)": 22.05,
      "step": 2945,
      "token_acc": 0.6811594202898551,
      "train_speed(iter/s)": 0.206509
    },
    {
      "epoch": 0.36875,
      "grad_norm": 1.6747342348098755,
      "learning_rate": 5.6029953324125636e-05,
      "loss": 1.5427863121032714,
      "memory(GiB)": 22.05,
      "step": 2950,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.206658
    },
    {
      "epoch": 0.369375,
      "grad_norm": 3.205410957336426,
      "learning_rate": 5.59579652362337e-05,
      "loss": 1.4561871528625487,
      "memory(GiB)": 22.05,
      "step": 2955,
      "token_acc": 0.6090225563909775,
      "train_speed(iter/s)": 0.206804
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0183420181274414,
      "learning_rate": 5.5885915625391226e-05,
      "loss": 1.6091171264648438,
      "memory(GiB)": 22.05,
      "step": 2960,
      "token_acc": 0.6065573770491803,
      "train_speed(iter/s)": 0.206951
    },
    {
      "epoch": 0.370625,
      "grad_norm": 1.8948220014572144,
      "learning_rate": 5.581380476937204e-05,
      "loss": 2.0152944564819335,
      "memory(GiB)": 22.05,
      "step": 2965,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.207093
    },
    {
      "epoch": 0.37125,
      "grad_norm": 1.5070046186447144,
      "learning_rate": 5.574163294618606e-05,
      "loss": 1.904595184326172,
      "memory(GiB)": 22.05,
      "step": 2970,
      "token_acc": 0.5289256198347108,
      "train_speed(iter/s)": 0.20724
    },
    {
      "epoch": 0.371875,
      "grad_norm": 3.8182218074798584,
      "learning_rate": 5.566940043407824e-05,
      "loss": 1.9965669631958007,
      "memory(GiB)": 22.05,
      "step": 2975,
      "token_acc": 0.5984251968503937,
      "train_speed(iter/s)": 0.207369
    },
    {
      "epoch": 0.3725,
      "grad_norm": 1.7911033630371094,
      "learning_rate": 5.5597107511527536e-05,
      "loss": 1.881398582458496,
      "memory(GiB)": 22.05,
      "step": 2980,
      "token_acc": 0.5671641791044776,
      "train_speed(iter/s)": 0.207488
    },
    {
      "epoch": 0.373125,
      "grad_norm": 4.564986705780029,
      "learning_rate": 5.552475445724579e-05,
      "loss": 2.5072568893432616,
      "memory(GiB)": 22.05,
      "step": 2985,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.207605
    },
    {
      "epoch": 0.37375,
      "grad_norm": 1.354315996170044,
      "learning_rate": 5.545234155017665e-05,
      "loss": 2.6814794540405273,
      "memory(GiB)": 22.05,
      "step": 2990,
      "token_acc": 0.4453125,
      "train_speed(iter/s)": 0.207714
    },
    {
      "epoch": 0.374375,
      "grad_norm": 0.7100548148155212,
      "learning_rate": 5.537986906949455e-05,
      "loss": 1.7257057189941407,
      "memory(GiB)": 22.05,
      "step": 2995,
      "token_acc": 0.584,
      "train_speed(iter/s)": 0.207832
    },
    {
      "epoch": 0.375,
      "grad_norm": 3.741741895675659,
      "learning_rate": 5.5307337294603595e-05,
      "loss": 2.3185548782348633,
      "memory(GiB)": 22.05,
      "step": 3000,
      "token_acc": 0.5234375,
      "train_speed(iter/s)": 0.207949
    },
    {
      "epoch": 0.375625,
      "grad_norm": 4.082173824310303,
      "learning_rate": 5.5234746505136474e-05,
      "loss": 1.9693307876586914,
      "memory(GiB)": 22.05,
      "step": 3005,
      "token_acc": 0.6339285714285714,
      "train_speed(iter/s)": 0.208088
    },
    {
      "epoch": 0.37625,
      "grad_norm": 1.9486267566680908,
      "learning_rate": 5.516209698095339e-05,
      "loss": 1.923975944519043,
      "memory(GiB)": 22.05,
      "step": 3010,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.208237
    },
    {
      "epoch": 0.376875,
      "grad_norm": 1.8004096746444702,
      "learning_rate": 5.5089389002141e-05,
      "loss": 2.647327423095703,
      "memory(GiB)": 22.05,
      "step": 3015,
      "token_acc": 0.424,
      "train_speed(iter/s)": 0.20838
    },
    {
      "epoch": 0.3775,
      "grad_norm": 1.8110133409500122,
      "learning_rate": 5.501662284901133e-05,
      "loss": 2.358669090270996,
      "memory(GiB)": 22.05,
      "step": 3020,
      "token_acc": 0.5390625,
      "train_speed(iter/s)": 0.208521
    },
    {
      "epoch": 0.378125,
      "grad_norm": 1.4161587953567505,
      "learning_rate": 5.494379880210066e-05,
      "loss": 2.1893959045410156,
      "memory(GiB)": 22.05,
      "step": 3025,
      "token_acc": 0.5036496350364964,
      "train_speed(iter/s)": 0.208664
    },
    {
      "epoch": 0.37875,
      "grad_norm": 1.644302487373352,
      "learning_rate": 5.487091714216849e-05,
      "loss": 1.778790283203125,
      "memory(GiB)": 22.05,
      "step": 3030,
      "token_acc": 0.5923076923076923,
      "train_speed(iter/s)": 0.208818
    },
    {
      "epoch": 0.379375,
      "grad_norm": 2.0186164379119873,
      "learning_rate": 5.479797815019643e-05,
      "loss": 2.279379463195801,
      "memory(GiB)": 22.05,
      "step": 3035,
      "token_acc": 0.460431654676259,
      "train_speed(iter/s)": 0.208963
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6603507995605469,
      "learning_rate": 5.472498210738713e-05,
      "loss": 2.279492950439453,
      "memory(GiB)": 22.05,
      "step": 3040,
      "token_acc": 0.48120300751879697,
      "train_speed(iter/s)": 0.209102
    },
    {
      "epoch": 0.380625,
      "grad_norm": 1.0774794816970825,
      "learning_rate": 5.465192929516316e-05,
      "loss": 2.17450065612793,
      "memory(GiB)": 22.05,
      "step": 3045,
      "token_acc": 0.5307692307692308,
      "train_speed(iter/s)": 0.209241
    },
    {
      "epoch": 0.38125,
      "grad_norm": 1.3392047882080078,
      "learning_rate": 5.4578819995166005e-05,
      "loss": 1.9230337142944336,
      "memory(GiB)": 22.05,
      "step": 3050,
      "token_acc": 0.5254237288135594,
      "train_speed(iter/s)": 0.209353
    },
    {
      "epoch": 0.381875,
      "grad_norm": 2.181551456451416,
      "learning_rate": 5.450565448925486e-05,
      "loss": 2.4132251739501953,
      "memory(GiB)": 22.05,
      "step": 3055,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.209466
    },
    {
      "epoch": 0.3825,
      "grad_norm": 3.8830456733703613,
      "learning_rate": 5.443243305950567e-05,
      "loss": 2.080982780456543,
      "memory(GiB)": 22.05,
      "step": 3060,
      "token_acc": 0.46099290780141844,
      "train_speed(iter/s)": 0.209575
    },
    {
      "epoch": 0.383125,
      "grad_norm": 3.3920135498046875,
      "learning_rate": 5.4359155988209985e-05,
      "loss": 2.3062849044799805,
      "memory(GiB)": 22.05,
      "step": 3065,
      "token_acc": 0.5658914728682171,
      "train_speed(iter/s)": 0.209674
    },
    {
      "epoch": 0.38375,
      "grad_norm": 4.313268184661865,
      "learning_rate": 5.4285823557873826e-05,
      "loss": 1.9357770919799804,
      "memory(GiB)": 22.05,
      "step": 3070,
      "token_acc": 0.5289256198347108,
      "train_speed(iter/s)": 0.209786
    },
    {
      "epoch": 0.384375,
      "grad_norm": 2.954005241394043,
      "learning_rate": 5.421243605121665e-05,
      "loss": 2.0337900161743163,
      "memory(GiB)": 22.05,
      "step": 3075,
      "token_acc": 0.5378787878787878,
      "train_speed(iter/s)": 0.209897
    },
    {
      "epoch": 0.385,
      "grad_norm": 4.243803024291992,
      "learning_rate": 5.413899375117029e-05,
      "loss": 2.3474475860595705,
      "memory(GiB)": 22.05,
      "step": 3080,
      "token_acc": 0.49295774647887325,
      "train_speed(iter/s)": 0.210037
    },
    {
      "epoch": 0.385625,
      "grad_norm": 3.5862743854522705,
      "learning_rate": 5.4065496940877796e-05,
      "loss": 2.0569074630737303,
      "memory(GiB)": 22.05,
      "step": 3085,
      "token_acc": 0.5310344827586206,
      "train_speed(iter/s)": 0.210178
    },
    {
      "epoch": 0.38625,
      "grad_norm": 1.3250014781951904,
      "learning_rate": 5.3991945903692354e-05,
      "loss": 1.8938280105590821,
      "memory(GiB)": 22.05,
      "step": 3090,
      "token_acc": 0.5954198473282443,
      "train_speed(iter/s)": 0.21032
    },
    {
      "epoch": 0.386875,
      "grad_norm": 1.813811182975769,
      "learning_rate": 5.3918340923176254e-05,
      "loss": 1.8670665740966796,
      "memory(GiB)": 22.05,
      "step": 3095,
      "token_acc": 0.6212121212121212,
      "train_speed(iter/s)": 0.210441
    },
    {
      "epoch": 0.3875,
      "grad_norm": 1.8733110427856445,
      "learning_rate": 5.384468228309972e-05,
      "loss": 1.806539535522461,
      "memory(GiB)": 22.05,
      "step": 3100,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.210546
    },
    {
      "epoch": 0.388125,
      "grad_norm": 2.9140894412994385,
      "learning_rate": 5.377097026743988e-05,
      "loss": 2.476528358459473,
      "memory(GiB)": 22.05,
      "step": 3105,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.210651
    },
    {
      "epoch": 0.38875,
      "grad_norm": 1.5522408485412598,
      "learning_rate": 5.36972051603796e-05,
      "loss": 2.1842817306518554,
      "memory(GiB)": 22.05,
      "step": 3110,
      "token_acc": 0.5041322314049587,
      "train_speed(iter/s)": 0.210758
    },
    {
      "epoch": 0.389375,
      "grad_norm": 1.699141263961792,
      "learning_rate": 5.362338724630648e-05,
      "loss": 2.247726821899414,
      "memory(GiB)": 22.05,
      "step": 3115,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.21087
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3950490951538086,
      "learning_rate": 5.3549516809811667e-05,
      "loss": 1.9008581161499023,
      "memory(GiB)": 22.05,
      "step": 3120,
      "token_acc": 0.5203252032520326,
      "train_speed(iter/s)": 0.21098
    },
    {
      "epoch": 0.390625,
      "grad_norm": 1.0679081678390503,
      "learning_rate": 5.347559413568881e-05,
      "loss": 1.707117462158203,
      "memory(GiB)": 22.05,
      "step": 3125,
      "token_acc": 0.6142857142857143,
      "train_speed(iter/s)": 0.211093
    },
    {
      "epoch": 0.39125,
      "grad_norm": 1.7533512115478516,
      "learning_rate": 5.340161950893296e-05,
      "loss": 2.2144725799560545,
      "memory(GiB)": 22.05,
      "step": 3130,
      "token_acc": 0.4965034965034965,
      "train_speed(iter/s)": 0.211196
    },
    {
      "epoch": 0.391875,
      "grad_norm": 1.0696372985839844,
      "learning_rate": 5.3327593214739476e-05,
      "loss": 1.7608135223388672,
      "memory(GiB)": 22.05,
      "step": 3135,
      "token_acc": 0.6124031007751938,
      "train_speed(iter/s)": 0.211312
    },
    {
      "epoch": 0.3925,
      "grad_norm": 1.630449891090393,
      "learning_rate": 5.325351553850284e-05,
      "loss": 1.1754145622253418,
      "memory(GiB)": 22.05,
      "step": 3140,
      "token_acc": 0.6616541353383458,
      "train_speed(iter/s)": 0.211433
    },
    {
      "epoch": 0.393125,
      "grad_norm": 4.500960826873779,
      "learning_rate": 5.317938676581573e-05,
      "loss": 2.3328506469726564,
      "memory(GiB)": 22.05,
      "step": 3145,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.211537
    },
    {
      "epoch": 0.39375,
      "grad_norm": 2.3441619873046875,
      "learning_rate": 5.310520718246775e-05,
      "loss": 2.329913330078125,
      "memory(GiB)": 22.05,
      "step": 3150,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.211638
    },
    {
      "epoch": 0.394375,
      "grad_norm": 4.195586681365967,
      "learning_rate": 5.3030977074444396e-05,
      "loss": 2.336709976196289,
      "memory(GiB)": 22.05,
      "step": 3155,
      "token_acc": 0.5042016806722689,
      "train_speed(iter/s)": 0.21175
    },
    {
      "epoch": 0.395,
      "grad_norm": 4.602992534637451,
      "learning_rate": 5.295669672792598e-05,
      "loss": 2.4173099517822267,
      "memory(GiB)": 22.05,
      "step": 3160,
      "token_acc": 0.425,
      "train_speed(iter/s)": 0.211887
    },
    {
      "epoch": 0.395625,
      "grad_norm": 3.659933090209961,
      "learning_rate": 5.288236642928649e-05,
      "loss": 1.7592405319213866,
      "memory(GiB)": 22.05,
      "step": 3165,
      "token_acc": 0.6290322580645161,
      "train_speed(iter/s)": 0.212021
    },
    {
      "epoch": 0.39625,
      "grad_norm": 1.9089382886886597,
      "learning_rate": 5.280798646509247e-05,
      "loss": 1.6385129928588866,
      "memory(GiB)": 22.05,
      "step": 3170,
      "token_acc": 0.5983606557377049,
      "train_speed(iter/s)": 0.212163
    },
    {
      "epoch": 0.396875,
      "grad_norm": 4.383667945861816,
      "learning_rate": 5.273355712210199e-05,
      "loss": 2.029781723022461,
      "memory(GiB)": 22.05,
      "step": 3175,
      "token_acc": 0.5128205128205128,
      "train_speed(iter/s)": 0.212308
    },
    {
      "epoch": 0.3975,
      "grad_norm": 4.55924129486084,
      "learning_rate": 5.265907868726345e-05,
      "loss": 1.9605792999267577,
      "memory(GiB)": 22.05,
      "step": 3180,
      "token_acc": 0.4892086330935252,
      "train_speed(iter/s)": 0.212447
    },
    {
      "epoch": 0.398125,
      "grad_norm": 1.5242114067077637,
      "learning_rate": 5.258455144771453e-05,
      "loss": 2.808903694152832,
      "memory(GiB)": 22.05,
      "step": 3185,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.212573
    },
    {
      "epoch": 0.39875,
      "grad_norm": 1.2392373085021973,
      "learning_rate": 5.250997569078104e-05,
      "loss": 1.8002796173095703,
      "memory(GiB)": 22.05,
      "step": 3190,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.212703
    },
    {
      "epoch": 0.399375,
      "grad_norm": 1.482567548751831,
      "learning_rate": 5.2435351703975895e-05,
      "loss": 2.514382743835449,
      "memory(GiB)": 22.05,
      "step": 3195,
      "token_acc": 0.4701492537313433,
      "train_speed(iter/s)": 0.212828
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7714951038360596,
      "learning_rate": 5.23606797749979e-05,
      "loss": 2.882085990905762,
      "memory(GiB)": 22.05,
      "step": 3200,
      "token_acc": 0.4573643410852713,
      "train_speed(iter/s)": 0.212955
    },
    {
      "epoch": 0.400625,
      "grad_norm": 1.1540346145629883,
      "learning_rate": 5.228596019173072e-05,
      "loss": 1.2710433959960938,
      "memory(GiB)": 22.05,
      "step": 3205,
      "token_acc": 0.6714285714285714,
      "train_speed(iter/s)": 0.213095
    },
    {
      "epoch": 0.40125,
      "grad_norm": 2.1224405765533447,
      "learning_rate": 5.2211193242241746e-05,
      "loss": 1.9926372528076173,
      "memory(GiB)": 22.05,
      "step": 3210,
      "token_acc": 0.5304347826086957,
      "train_speed(iter/s)": 0.213233
    },
    {
      "epoch": 0.401875,
      "grad_norm": 1.3471914529800415,
      "learning_rate": 5.2136379214780966e-05,
      "loss": 1.863272476196289,
      "memory(GiB)": 22.05,
      "step": 3215,
      "token_acc": 0.6083333333333333,
      "train_speed(iter/s)": 0.213352
    },
    {
      "epoch": 0.4025,
      "grad_norm": 1.8883092403411865,
      "learning_rate": 5.206151839777983e-05,
      "loss": 1.9294166564941406,
      "memory(GiB)": 22.05,
      "step": 3220,
      "token_acc": 0.6044776119402985,
      "train_speed(iter/s)": 0.213485
    },
    {
      "epoch": 0.403125,
      "grad_norm": 0.9786465167999268,
      "learning_rate": 5.198661107985027e-05,
      "loss": 1.6469171524047852,
      "memory(GiB)": 22.05,
      "step": 3225,
      "token_acc": 0.5826771653543307,
      "train_speed(iter/s)": 0.213617
    },
    {
      "epoch": 0.40375,
      "grad_norm": 1.3390016555786133,
      "learning_rate": 5.191165754978342e-05,
      "loss": 1.6740041732788087,
      "memory(GiB)": 22.05,
      "step": 3230,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.213742
    },
    {
      "epoch": 0.404375,
      "grad_norm": 1.499755620956421,
      "learning_rate": 5.183665809654859e-05,
      "loss": 1.9930320739746095,
      "memory(GiB)": 22.05,
      "step": 3235,
      "token_acc": 0.6166666666666667,
      "train_speed(iter/s)": 0.21388
    },
    {
      "epoch": 0.405,
      "grad_norm": 2.105177879333496,
      "learning_rate": 5.176161300929216e-05,
      "loss": 2.3034061431884765,
      "memory(GiB)": 22.05,
      "step": 3240,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.214008
    },
    {
      "epoch": 0.405625,
      "grad_norm": 1.805194616317749,
      "learning_rate": 5.1686522577336424e-05,
      "loss": 1.892445945739746,
      "memory(GiB)": 22.05,
      "step": 3245,
      "token_acc": 0.6141732283464567,
      "train_speed(iter/s)": 0.214144
    },
    {
      "epoch": 0.40625,
      "grad_norm": 5.095785617828369,
      "learning_rate": 5.16113870901785e-05,
      "loss": 1.6255527496337892,
      "memory(GiB)": 22.05,
      "step": 3250,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.214277
    },
    {
      "epoch": 0.406875,
      "grad_norm": 4.0116286277771,
      "learning_rate": 5.15362068374892e-05,
      "loss": 1.9102455139160157,
      "memory(GiB)": 22.05,
      "step": 3255,
      "token_acc": 0.6015625,
      "train_speed(iter/s)": 0.214408
    },
    {
      "epoch": 0.4075,
      "grad_norm": 3.8927862644195557,
      "learning_rate": 5.146098210911194e-05,
      "loss": 2.2672895431518554,
      "memory(GiB)": 22.05,
      "step": 3260,
      "token_acc": 0.45323741007194246,
      "train_speed(iter/s)": 0.214527
    },
    {
      "epoch": 0.408125,
      "grad_norm": 1.5284740924835205,
      "learning_rate": 5.138571319506158e-05,
      "loss": 2.3778541564941404,
      "memory(GiB)": 22.05,
      "step": 3265,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.214651
    },
    {
      "epoch": 0.40875,
      "grad_norm": 1.4715327024459839,
      "learning_rate": 5.1310400385523335e-05,
      "loss": 1.5331130981445313,
      "memory(GiB)": 22.05,
      "step": 3270,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.214787
    },
    {
      "epoch": 0.409375,
      "grad_norm": 2.9128124713897705,
      "learning_rate": 5.123504397085169e-05,
      "loss": 1.9980403900146484,
      "memory(GiB)": 22.05,
      "step": 3275,
      "token_acc": 0.568,
      "train_speed(iter/s)": 0.214923
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.723268985748291,
      "learning_rate": 5.115964424156918e-05,
      "loss": 2.2288606643676756,
      "memory(GiB)": 22.05,
      "step": 3280,
      "token_acc": 0.5042735042735043,
      "train_speed(iter/s)": 0.215054
    },
    {
      "epoch": 0.410625,
      "grad_norm": 1.6486440896987915,
      "learning_rate": 5.1084201488365354e-05,
      "loss": 1.6045824050903321,
      "memory(GiB)": 22.05,
      "step": 3285,
      "token_acc": 0.6311475409836066,
      "train_speed(iter/s)": 0.215151
    },
    {
      "epoch": 0.41125,
      "grad_norm": 1.7169485092163086,
      "learning_rate": 5.100871600209566e-05,
      "loss": 2.529000663757324,
      "memory(GiB)": 22.05,
      "step": 3290,
      "token_acc": 0.3884297520661157,
      "train_speed(iter/s)": 0.215255
    },
    {
      "epoch": 0.411875,
      "grad_norm": 1.7692128419876099,
      "learning_rate": 5.093318807378028e-05,
      "loss": 1.974724578857422,
      "memory(GiB)": 22.05,
      "step": 3295,
      "token_acc": 0.5038167938931297,
      "train_speed(iter/s)": 0.215373
    },
    {
      "epoch": 0.4125,
      "grad_norm": 4.358580112457275,
      "learning_rate": 5.085761799460297e-05,
      "loss": 2.059488296508789,
      "memory(GiB)": 22.05,
      "step": 3300,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.215512
    },
    {
      "epoch": 0.413125,
      "grad_norm": 1.2915812730789185,
      "learning_rate": 5.078200605591009e-05,
      "loss": 1.3505331039428712,
      "memory(GiB)": 22.05,
      "step": 3305,
      "token_acc": 0.6692307692307692,
      "train_speed(iter/s)": 0.21565
    },
    {
      "epoch": 0.41375,
      "grad_norm": 2.0660667419433594,
      "learning_rate": 5.07063525492093e-05,
      "loss": 2.0667810440063477,
      "memory(GiB)": 22.05,
      "step": 3310,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.215788
    },
    {
      "epoch": 0.414375,
      "grad_norm": 3.2848780155181885,
      "learning_rate": 5.063065776616855e-05,
      "loss": 2.9662155151367187,
      "memory(GiB)": 22.05,
      "step": 3315,
      "token_acc": 0.33076923076923076,
      "train_speed(iter/s)": 0.215915
    },
    {
      "epoch": 0.415,
      "grad_norm": 2.6269443035125732,
      "learning_rate": 5.0554921998614925e-05,
      "loss": 1.7867090225219726,
      "memory(GiB)": 22.05,
      "step": 3320,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.216051
    },
    {
      "epoch": 0.415625,
      "grad_norm": 1.3078186511993408,
      "learning_rate": 5.04791455385335e-05,
      "loss": 1.4901725769042968,
      "memory(GiB)": 22.05,
      "step": 3325,
      "token_acc": 0.5724137931034483,
      "train_speed(iter/s)": 0.216191
    },
    {
      "epoch": 0.41625,
      "grad_norm": 1.2696950435638428,
      "learning_rate": 5.0403328678066275e-05,
      "loss": 2.092755126953125,
      "memory(GiB)": 22.05,
      "step": 3330,
      "token_acc": 0.4573643410852713,
      "train_speed(iter/s)": 0.216333
    },
    {
      "epoch": 0.416875,
      "grad_norm": 1.4983834028244019,
      "learning_rate": 5.0327471709510944e-05,
      "loss": 2.094492721557617,
      "memory(GiB)": 22.05,
      "step": 3335,
      "token_acc": 0.5114503816793893,
      "train_speed(iter/s)": 0.216485
    },
    {
      "epoch": 0.4175,
      "grad_norm": 1.637695550918579,
      "learning_rate": 5.025157492531987e-05,
      "loss": 1.86187686920166,
      "memory(GiB)": 22.05,
      "step": 3340,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.216618
    },
    {
      "epoch": 0.418125,
      "grad_norm": 1.9476608037948608,
      "learning_rate": 5.017563861809892e-05,
      "loss": 2.1230106353759766,
      "memory(GiB)": 22.05,
      "step": 3345,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.216751
    },
    {
      "epoch": 0.41875,
      "grad_norm": 1.3596205711364746,
      "learning_rate": 5.009966308060632e-05,
      "loss": 2.7364032745361326,
      "memory(GiB)": 22.05,
      "step": 3350,
      "token_acc": 0.4152542372881356,
      "train_speed(iter/s)": 0.216877
    },
    {
      "epoch": 0.419375,
      "grad_norm": 1.7058058977127075,
      "learning_rate": 5.002364860575156e-05,
      "loss": 1.8678842544555665,
      "memory(GiB)": 22.05,
      "step": 3355,
      "token_acc": 0.5648854961832062,
      "train_speed(iter/s)": 0.216998
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3379933834075928,
      "learning_rate": 4.9947595486594206e-05,
      "loss": 2.013092041015625,
      "memory(GiB)": 22.05,
      "step": 3360,
      "token_acc": 0.5891472868217055,
      "train_speed(iter/s)": 0.217129
    },
    {
      "epoch": 0.420625,
      "grad_norm": 1.1509572267532349,
      "learning_rate": 4.987150401634283e-05,
      "loss": 2.074118804931641,
      "memory(GiB)": 22.05,
      "step": 3365,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.217259
    },
    {
      "epoch": 0.42125,
      "grad_norm": 2.9942288398742676,
      "learning_rate": 4.97953744883539e-05,
      "loss": 2.122214126586914,
      "memory(GiB)": 22.05,
      "step": 3370,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.217386
    },
    {
      "epoch": 0.421875,
      "grad_norm": 3.3821139335632324,
      "learning_rate": 4.971920719613056e-05,
      "loss": 1.6742172241210938,
      "memory(GiB)": 22.05,
      "step": 3375,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.217512
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.0866035223007202,
      "learning_rate": 4.9643002433321555e-05,
      "loss": 1.1514527320861816,
      "memory(GiB)": 22.05,
      "step": 3380,
      "token_acc": 0.6976744186046512,
      "train_speed(iter/s)": 0.217641
    },
    {
      "epoch": 0.423125,
      "grad_norm": 1.420568823814392,
      "learning_rate": 4.956676049372009e-05,
      "loss": 1.6137224197387696,
      "memory(GiB)": 22.05,
      "step": 3385,
      "token_acc": 0.6201550387596899,
      "train_speed(iter/s)": 0.217771
    },
    {
      "epoch": 0.42375,
      "grad_norm": 4.237583160400391,
      "learning_rate": 4.949048167126272e-05,
      "loss": 2.705534744262695,
      "memory(GiB)": 22.05,
      "step": 3390,
      "token_acc": 0.41732283464566927,
      "train_speed(iter/s)": 0.217893
    },
    {
      "epoch": 0.424375,
      "grad_norm": 3.598923444747925,
      "learning_rate": 4.941416626002816e-05,
      "loss": 2.1796136856079102,
      "memory(GiB)": 22.05,
      "step": 3395,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.218017
    },
    {
      "epoch": 0.425,
      "grad_norm": 4.715360641479492,
      "learning_rate": 4.933781455423623e-05,
      "loss": 2.338058090209961,
      "memory(GiB)": 22.05,
      "step": 3400,
      "token_acc": 0.532051282051282,
      "train_speed(iter/s)": 0.218143
    },
    {
      "epoch": 0.425625,
      "grad_norm": 1.3393301963806152,
      "learning_rate": 4.926142684824663e-05,
      "loss": 2.096149444580078,
      "memory(GiB)": 22.05,
      "step": 3405,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.21827
    },
    {
      "epoch": 0.42625,
      "grad_norm": 1.3200381994247437,
      "learning_rate": 4.918500343655788e-05,
      "loss": 1.9479413986206056,
      "memory(GiB)": 22.05,
      "step": 3410,
      "token_acc": 0.5851851851851851,
      "train_speed(iter/s)": 0.218392
    },
    {
      "epoch": 0.426875,
      "grad_norm": 4.17298698425293,
      "learning_rate": 4.910854461380615e-05,
      "loss": 2.17812557220459,
      "memory(GiB)": 22.05,
      "step": 3415,
      "token_acc": 0.549618320610687,
      "train_speed(iter/s)": 0.21852
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.3337132930755615,
      "learning_rate": 4.9032050674764156e-05,
      "loss": 2.142839050292969,
      "memory(GiB)": 22.05,
      "step": 3420,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.218648
    },
    {
      "epoch": 0.428125,
      "grad_norm": 1.423647165298462,
      "learning_rate": 4.895552191433995e-05,
      "loss": 2.269148254394531,
      "memory(GiB)": 22.05,
      "step": 3425,
      "token_acc": 0.5338983050847458,
      "train_speed(iter/s)": 0.218771
    },
    {
      "epoch": 0.42875,
      "grad_norm": 1.3918150663375854,
      "learning_rate": 4.887895862757584e-05,
      "loss": 2.086065673828125,
      "memory(GiB)": 22.05,
      "step": 3430,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.218901
    },
    {
      "epoch": 0.429375,
      "grad_norm": 3.3687686920166016,
      "learning_rate": 4.8802361109647296e-05,
      "loss": 2.417272186279297,
      "memory(GiB)": 22.05,
      "step": 3435,
      "token_acc": 0.45081967213114754,
      "train_speed(iter/s)": 0.219
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.6435577869415283,
      "learning_rate": 4.872572965586171e-05,
      "loss": 2.158513641357422,
      "memory(GiB)": 22.05,
      "step": 3440,
      "token_acc": 0.5190839694656488,
      "train_speed(iter/s)": 0.219092
    },
    {
      "epoch": 0.430625,
      "grad_norm": 1.5126007795333862,
      "learning_rate": 4.864906456165731e-05,
      "loss": 1.6946073532104493,
      "memory(GiB)": 22.05,
      "step": 3445,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.21921
    },
    {
      "epoch": 0.43125,
      "grad_norm": 1.5864253044128418,
      "learning_rate": 4.857236612260203e-05,
      "loss": 1.769424057006836,
      "memory(GiB)": 22.05,
      "step": 3450,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.21931
    },
    {
      "epoch": 0.431875,
      "grad_norm": 1.5492414236068726,
      "learning_rate": 4.8495634634392377e-05,
      "loss": 2.179892158508301,
      "memory(GiB)": 22.05,
      "step": 3455,
      "token_acc": 0.5079365079365079,
      "train_speed(iter/s)": 0.219406
    },
    {
      "epoch": 0.4325,
      "grad_norm": 5.5601935386657715,
      "learning_rate": 4.8418870392852224e-05,
      "loss": 1.8989606857299806,
      "memory(GiB)": 22.05,
      "step": 3460,
      "token_acc": 0.568,
      "train_speed(iter/s)": 0.219504
    },
    {
      "epoch": 0.433125,
      "grad_norm": 1.8456367254257202,
      "learning_rate": 4.834207369393178e-05,
      "loss": 2.116120147705078,
      "memory(GiB)": 22.05,
      "step": 3465,
      "token_acc": 0.48226950354609927,
      "train_speed(iter/s)": 0.219625
    },
    {
      "epoch": 0.43375,
      "grad_norm": 1.806213617324829,
      "learning_rate": 4.826524483370633e-05,
      "loss": 2.455687713623047,
      "memory(GiB)": 22.05,
      "step": 3470,
      "token_acc": 0.5114503816793893,
      "train_speed(iter/s)": 0.219748
    },
    {
      "epoch": 0.434375,
      "grad_norm": 1.090073585510254,
      "learning_rate": 4.818838410837519e-05,
      "loss": 1.5839348793029786,
      "memory(GiB)": 22.05,
      "step": 3475,
      "token_acc": 0.6451612903225806,
      "train_speed(iter/s)": 0.21987
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.2476500272750854,
      "learning_rate": 4.81114918142605e-05,
      "loss": 1.4606307029724122,
      "memory(GiB)": 22.05,
      "step": 3480,
      "token_acc": 0.6183206106870229,
      "train_speed(iter/s)": 0.219993
    },
    {
      "epoch": 0.435625,
      "grad_norm": 1.161436915397644,
      "learning_rate": 4.803456824780614e-05,
      "loss": 1.9458454132080079,
      "memory(GiB)": 22.05,
      "step": 3485,
      "token_acc": 0.562962962962963,
      "train_speed(iter/s)": 0.220116
    },
    {
      "epoch": 0.43625,
      "grad_norm": 1.19035804271698,
      "learning_rate": 4.7957613705576506e-05,
      "loss": 2.3144098281860352,
      "memory(GiB)": 22.05,
      "step": 3490,
      "token_acc": 0.4806201550387597,
      "train_speed(iter/s)": 0.220232
    },
    {
      "epoch": 0.436875,
      "grad_norm": 2.186436414718628,
      "learning_rate": 4.7880628484255465e-05,
      "loss": 2.050570487976074,
      "memory(GiB)": 22.05,
      "step": 3495,
      "token_acc": 0.5352112676056338,
      "train_speed(iter/s)": 0.220378
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.7658787965774536,
      "learning_rate": 4.780361288064514e-05,
      "loss": 2.4258390426635743,
      "memory(GiB)": 22.05,
      "step": 3500,
      "token_acc": 0.4596774193548387,
      "train_speed(iter/s)": 0.220522
    },
    {
      "epoch": 0.438125,
      "grad_norm": 3.52011775970459,
      "learning_rate": 4.772656719166477e-05,
      "loss": 2.2528717041015627,
      "memory(GiB)": 22.05,
      "step": 3505,
      "token_acc": 0.460431654676259,
      "train_speed(iter/s)": 0.220667
    },
    {
      "epoch": 0.43875,
      "grad_norm": 1.1167269945144653,
      "learning_rate": 4.764949171434962e-05,
      "loss": 2.2212078094482424,
      "memory(GiB)": 22.05,
      "step": 3510,
      "token_acc": 0.5546875,
      "train_speed(iter/s)": 0.22081
    },
    {
      "epoch": 0.439375,
      "grad_norm": 2.0109219551086426,
      "learning_rate": 4.757238674584976e-05,
      "loss": 2.4491203308105467,
      "memory(GiB)": 22.05,
      "step": 3515,
      "token_acc": 0.4365079365079365,
      "train_speed(iter/s)": 0.220953
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5854452848434448,
      "learning_rate": 4.7495252583429e-05,
      "loss": 1.9095783233642578,
      "memory(GiB)": 22.05,
      "step": 3520,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.221076
    },
    {
      "epoch": 0.440625,
      "grad_norm": 1.3513717651367188,
      "learning_rate": 4.741808952446364e-05,
      "loss": 2.158000946044922,
      "memory(GiB)": 22.05,
      "step": 3525,
      "token_acc": 0.5343511450381679,
      "train_speed(iter/s)": 0.221192
    },
    {
      "epoch": 0.44125,
      "grad_norm": 1.9480646848678589,
      "learning_rate": 4.7340897866441465e-05,
      "loss": 2.0177465438842774,
      "memory(GiB)": 22.05,
      "step": 3530,
      "token_acc": 0.5620437956204379,
      "train_speed(iter/s)": 0.221309
    },
    {
      "epoch": 0.441875,
      "grad_norm": 1.1915744543075562,
      "learning_rate": 4.726367790696044e-05,
      "loss": 1.665785789489746,
      "memory(GiB)": 22.05,
      "step": 3535,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.221427
    },
    {
      "epoch": 0.4425,
      "grad_norm": 4.327455997467041,
      "learning_rate": 4.718642994372771e-05,
      "loss": 2.2016477584838867,
      "memory(GiB)": 22.05,
      "step": 3540,
      "token_acc": 0.5327868852459017,
      "train_speed(iter/s)": 0.221547
    },
    {
      "epoch": 0.443125,
      "grad_norm": 1.7799490690231323,
      "learning_rate": 4.710915427455833e-05,
      "loss": 2.6558351516723633,
      "memory(GiB)": 22.05,
      "step": 3545,
      "token_acc": 0.4307692307692308,
      "train_speed(iter/s)": 0.221557
    },
    {
      "epoch": 0.44375,
      "grad_norm": 1.5054594278335571,
      "learning_rate": 4.703185119737419e-05,
      "loss": 1.7611139297485352,
      "memory(GiB)": 22.05,
      "step": 3550,
      "token_acc": 0.6187050359712231,
      "train_speed(iter/s)": 0.221532
    },
    {
      "epoch": 0.444375,
      "grad_norm": 1.6634451150894165,
      "learning_rate": 4.6954521010202854e-05,
      "loss": 1.8360889434814454,
      "memory(GiB)": 22.05,
      "step": 3555,
      "token_acc": 0.5254237288135594,
      "train_speed(iter/s)": 0.221608
    },
    {
      "epoch": 0.445,
      "grad_norm": 2.1490585803985596,
      "learning_rate": 4.6877164011176383e-05,
      "loss": 2.3488693237304688,
      "memory(GiB)": 22.05,
      "step": 3560,
      "token_acc": 0.4049586776859504,
      "train_speed(iter/s)": 0.221565
    },
    {
      "epoch": 0.445625,
      "grad_norm": 1.7782975435256958,
      "learning_rate": 4.6799780498530244e-05,
      "loss": 1.876657485961914,
      "memory(GiB)": 22.05,
      "step": 3565,
      "token_acc": 0.5546875,
      "train_speed(iter/s)": 0.221576
    },
    {
      "epoch": 0.44625,
      "grad_norm": 1.6106923818588257,
      "learning_rate": 4.6722370770602084e-05,
      "loss": 2.777251625061035,
      "memory(GiB)": 22.05,
      "step": 3570,
      "token_acc": 0.4393939393939394,
      "train_speed(iter/s)": 0.221637
    },
    {
      "epoch": 0.446875,
      "grad_norm": 1.7357022762298584,
      "learning_rate": 4.664493512583062e-05,
      "loss": 2.322175979614258,
      "memory(GiB)": 22.05,
      "step": 3575,
      "token_acc": 0.47580645161290325,
      "train_speed(iter/s)": 0.221573
    },
    {
      "epoch": 0.4475,
      "grad_norm": 3.4595229625701904,
      "learning_rate": 4.656747386275452e-05,
      "loss": 2.195138168334961,
      "memory(GiB)": 22.05,
      "step": 3580,
      "token_acc": 0.5578231292517006,
      "train_speed(iter/s)": 0.221645
    },
    {
      "epoch": 0.448125,
      "grad_norm": 3.4455926418304443,
      "learning_rate": 4.648998728001119e-05,
      "loss": 2.036397171020508,
      "memory(GiB)": 22.05,
      "step": 3585,
      "token_acc": 0.45528455284552843,
      "train_speed(iter/s)": 0.221621
    },
    {
      "epoch": 0.44875,
      "grad_norm": 4.309427261352539,
      "learning_rate": 4.641247567633565e-05,
      "loss": 2.8519506454467773,
      "memory(GiB)": 22.05,
      "step": 3590,
      "token_acc": 0.37681159420289856,
      "train_speed(iter/s)": 0.221554
    },
    {
      "epoch": 0.449375,
      "grad_norm": 1.084362268447876,
      "learning_rate": 4.6334939350559394e-05,
      "loss": 1.9872896194458007,
      "memory(GiB)": 22.05,
      "step": 3595,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.221524
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6201486587524414,
      "learning_rate": 4.625737860160924e-05,
      "loss": 2.0376142501831054,
      "memory(GiB)": 22.05,
      "step": 3600,
      "token_acc": 0.5507246376811594,
      "train_speed(iter/s)": 0.221614
    },
    {
      "epoch": 0.450625,
      "grad_norm": 1.9458321332931519,
      "learning_rate": 4.617979372850613e-05,
      "loss": 1.686575698852539,
      "memory(GiB)": 22.05,
      "step": 3605,
      "token_acc": 0.5615384615384615,
      "train_speed(iter/s)": 0.221543
    },
    {
      "epoch": 0.45125,
      "grad_norm": 4.553123950958252,
      "learning_rate": 4.6102185030364044e-05,
      "loss": 1.9900192260742187,
      "memory(GiB)": 22.05,
      "step": 3610,
      "token_acc": 0.5538461538461539,
      "train_speed(iter/s)": 0.221483
    },
    {
      "epoch": 0.451875,
      "grad_norm": 1.219691514968872,
      "learning_rate": 4.6024552806388805e-05,
      "loss": 2.1656064987182617,
      "memory(GiB)": 22.05,
      "step": 3615,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.221317
    },
    {
      "epoch": 0.4525,
      "grad_norm": 1.2340970039367676,
      "learning_rate": 4.594689735587693e-05,
      "loss": 2.3168445587158204,
      "memory(GiB)": 22.05,
      "step": 3620,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.221286
    },
    {
      "epoch": 0.453125,
      "grad_norm": 3.253537178039551,
      "learning_rate": 4.586921897821447e-05,
      "loss": 2.154311943054199,
      "memory(GiB)": 22.05,
      "step": 3625,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.221092
    },
    {
      "epoch": 0.45375,
      "grad_norm": 4.1132073402404785,
      "learning_rate": 4.579151797287592e-05,
      "loss": 2.4181514739990235,
      "memory(GiB)": 22.05,
      "step": 3630,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.221102
    },
    {
      "epoch": 0.454375,
      "grad_norm": 3.7017664909362793,
      "learning_rate": 4.571379463942294e-05,
      "loss": 1.7645767211914063,
      "memory(GiB)": 22.05,
      "step": 3635,
      "token_acc": 0.5603448275862069,
      "train_speed(iter/s)": 0.221114
    },
    {
      "epoch": 0.455,
      "grad_norm": 1.2655833959579468,
      "learning_rate": 4.563604927750331e-05,
      "loss": 1.8247764587402344,
      "memory(GiB)": 22.05,
      "step": 3640,
      "token_acc": 0.5163934426229508,
      "train_speed(iter/s)": 0.220929
    },
    {
      "epoch": 0.455625,
      "grad_norm": 1.8073701858520508,
      "learning_rate": 4.5558282186849754e-05,
      "loss": 1.8912212371826171,
      "memory(GiB)": 22.05,
      "step": 3645,
      "token_acc": 0.5594405594405595,
      "train_speed(iter/s)": 0.220949
    },
    {
      "epoch": 0.45625,
      "grad_norm": 4.818944454193115,
      "learning_rate": 4.548049366727873e-05,
      "loss": 1.9015438079833984,
      "memory(GiB)": 22.05,
      "step": 3650,
      "token_acc": 0.5196850393700787,
      "train_speed(iter/s)": 0.220969
    },
    {
      "epoch": 0.456875,
      "grad_norm": 3.6300642490386963,
      "learning_rate": 4.540268401868932e-05,
      "loss": 2.6897037506103514,
      "memory(GiB)": 22.05,
      "step": 3655,
      "token_acc": 0.4452054794520548,
      "train_speed(iter/s)": 0.220984
    },
    {
      "epoch": 0.4575,
      "grad_norm": 1.2054868936538696,
      "learning_rate": 4.53248535410621e-05,
      "loss": 1.9482147216796875,
      "memory(GiB)": 22.05,
      "step": 3660,
      "token_acc": 0.48854961832061067,
      "train_speed(iter/s)": 0.220961
    },
    {
      "epoch": 0.458125,
      "grad_norm": 1.6307471990585327,
      "learning_rate": 4.52470025344579e-05,
      "loss": 1.1956903457641601,
      "memory(GiB)": 22.05,
      "step": 3665,
      "token_acc": 0.6771653543307087,
      "train_speed(iter/s)": 0.220899
    },
    {
      "epoch": 0.45875,
      "grad_norm": 1.1958668231964111,
      "learning_rate": 4.516913129901671e-05,
      "loss": 1.7820226669311523,
      "memory(GiB)": 22.05,
      "step": 3670,
      "token_acc": 0.575,
      "train_speed(iter/s)": 0.220981
    },
    {
      "epoch": 0.459375,
      "grad_norm": 1.913416862487793,
      "learning_rate": 4.5091240134956535e-05,
      "loss": 2.2017343521118162,
      "memory(GiB)": 22.05,
      "step": 3675,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.221067
    },
    {
      "epoch": 0.46,
      "grad_norm": 7.9943461418151855,
      "learning_rate": 4.501332934257217e-05,
      "loss": 2.2694833755493162,
      "memory(GiB)": 22.05,
      "step": 3680,
      "token_acc": 0.47019867549668876,
      "train_speed(iter/s)": 0.221154
    },
    {
      "epoch": 0.460625,
      "grad_norm": 3.0218756198883057,
      "learning_rate": 4.493539922223413e-05,
      "loss": 1.9249505996704102,
      "memory(GiB)": 22.05,
      "step": 3685,
      "token_acc": 0.5586206896551724,
      "train_speed(iter/s)": 0.221242
    },
    {
      "epoch": 0.46125,
      "grad_norm": 1.5647773742675781,
      "learning_rate": 4.4857450074387394e-05,
      "loss": 2.122753715515137,
      "memory(GiB)": 22.05,
      "step": 3690,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.221318
    },
    {
      "epoch": 0.461875,
      "grad_norm": 4.329008102416992,
      "learning_rate": 4.4779482199550335e-05,
      "loss": 1.991733932495117,
      "memory(GiB)": 22.05,
      "step": 3695,
      "token_acc": 0.549618320610687,
      "train_speed(iter/s)": 0.22141
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.3850730657577515,
      "learning_rate": 4.470149589831351e-05,
      "loss": 2.423171806335449,
      "memory(GiB)": 22.05,
      "step": 3700,
      "token_acc": 0.5109489051094891,
      "train_speed(iter/s)": 0.221502
    },
    {
      "epoch": 0.463125,
      "grad_norm": 4.5569682121276855,
      "learning_rate": 4.4623491471338517e-05,
      "loss": 2.1939334869384766,
      "memory(GiB)": 22.05,
      "step": 3705,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.22159
    },
    {
      "epoch": 0.46375,
      "grad_norm": 1.4733296632766724,
      "learning_rate": 4.454546921935685e-05,
      "loss": 1.6479156494140625,
      "memory(GiB)": 22.05,
      "step": 3710,
      "token_acc": 0.6031746031746031,
      "train_speed(iter/s)": 0.221681
    },
    {
      "epoch": 0.464375,
      "grad_norm": 1.2158100605010986,
      "learning_rate": 4.44674294431687e-05,
      "loss": 1.8970041275024414,
      "memory(GiB)": 22.05,
      "step": 3715,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.221793
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.524804711341858,
      "learning_rate": 4.438937244364181e-05,
      "loss": 1.9363794326782227,
      "memory(GiB)": 22.05,
      "step": 3720,
      "token_acc": 0.6554621848739496,
      "train_speed(iter/s)": 0.221899
    },
    {
      "epoch": 0.465625,
      "grad_norm": 1.3839071989059448,
      "learning_rate": 4.431129852171037e-05,
      "loss": 1.9628597259521485,
      "memory(GiB)": 22.05,
      "step": 3725,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.222015
    },
    {
      "epoch": 0.46625,
      "grad_norm": 1.6901137828826904,
      "learning_rate": 4.423320797837379e-05,
      "loss": 1.9227811813354492,
      "memory(GiB)": 22.05,
      "step": 3730,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.22213
    },
    {
      "epoch": 0.466875,
      "grad_norm": 2.0337276458740234,
      "learning_rate": 4.415510111469552e-05,
      "loss": 2.066330337524414,
      "memory(GiB)": 22.05,
      "step": 3735,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.222244
    },
    {
      "epoch": 0.4675,
      "grad_norm": 3.0789389610290527,
      "learning_rate": 4.4076978231802e-05,
      "loss": 2.3804910659790037,
      "memory(GiB)": 22.05,
      "step": 3740,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.222358
    },
    {
      "epoch": 0.468125,
      "grad_norm": 5.632770538330078,
      "learning_rate": 4.3998839630881384e-05,
      "loss": 2.2503084182739257,
      "memory(GiB)": 22.05,
      "step": 3745,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.22247
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.959970474243164,
      "learning_rate": 4.392068561318244e-05,
      "loss": 1.7220775604248046,
      "memory(GiB)": 22.05,
      "step": 3750,
      "token_acc": 0.6198347107438017,
      "train_speed(iter/s)": 0.222583
    },
    {
      "epoch": 0.469375,
      "grad_norm": 1.344810128211975,
      "learning_rate": 4.384251648001334e-05,
      "loss": 1.5341194152832032,
      "memory(GiB)": 22.05,
      "step": 3755,
      "token_acc": 0.6511627906976745,
      "train_speed(iter/s)": 0.222696
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.561336874961853,
      "learning_rate": 4.3764332532740584e-05,
      "loss": 2.0914520263671874,
      "memory(GiB)": 22.05,
      "step": 3760,
      "token_acc": 0.5142857142857142,
      "train_speed(iter/s)": 0.222807
    },
    {
      "epoch": 0.470625,
      "grad_norm": 1.8706762790679932,
      "learning_rate": 4.3686134072787745e-05,
      "loss": 2.180426597595215,
      "memory(GiB)": 22.05,
      "step": 3765,
      "token_acc": 0.43537414965986393,
      "train_speed(iter/s)": 0.222919
    },
    {
      "epoch": 0.47125,
      "grad_norm": 1.7474877834320068,
      "learning_rate": 4.360792140163437e-05,
      "loss": 1.876032829284668,
      "memory(GiB)": 22.05,
      "step": 3770,
      "token_acc": 0.5669291338582677,
      "train_speed(iter/s)": 0.223037
    },
    {
      "epoch": 0.471875,
      "grad_norm": 3.0554213523864746,
      "learning_rate": 4.352969482081479e-05,
      "loss": 1.8852893829345703,
      "memory(GiB)": 22.05,
      "step": 3775,
      "token_acc": 0.582089552238806,
      "train_speed(iter/s)": 0.223165
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.4241909980773926,
      "learning_rate": 4.3451454631916946e-05,
      "loss": 1.2089530944824218,
      "memory(GiB)": 22.05,
      "step": 3780,
      "token_acc": 0.7286821705426356,
      "train_speed(iter/s)": 0.223295
    },
    {
      "epoch": 0.473125,
      "grad_norm": 3.727346181869507,
      "learning_rate": 4.337320113658124e-05,
      "loss": 2.014921951293945,
      "memory(GiB)": 22.05,
      "step": 3785,
      "token_acc": 0.5481481481481482,
      "train_speed(iter/s)": 0.223404
    },
    {
      "epoch": 0.47375,
      "grad_norm": 1.6904475688934326,
      "learning_rate": 4.329493463649943e-05,
      "loss": 2.1908805847167967,
      "memory(GiB)": 22.05,
      "step": 3790,
      "token_acc": 0.4621212121212121,
      "train_speed(iter/s)": 0.223507
    },
    {
      "epoch": 0.474375,
      "grad_norm": 1.2863564491271973,
      "learning_rate": 4.321665543341334e-05,
      "loss": 1.8028409957885743,
      "memory(GiB)": 22.05,
      "step": 3795,
      "token_acc": 0.5428571428571428,
      "train_speed(iter/s)": 0.223616
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.3809410333633423,
      "learning_rate": 4.313836382911381e-05,
      "loss": 2.237852096557617,
      "memory(GiB)": 22.05,
      "step": 3800,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.223718
    },
    {
      "epoch": 0.475625,
      "grad_norm": 1.3867822885513306,
      "learning_rate": 4.306006012543945e-05,
      "loss": 2.010717010498047,
      "memory(GiB)": 22.05,
      "step": 3805,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.223826
    },
    {
      "epoch": 0.47625,
      "grad_norm": 1.3231585025787354,
      "learning_rate": 4.298174462427559e-05,
      "loss": 2.228987693786621,
      "memory(GiB)": 22.05,
      "step": 3810,
      "token_acc": 0.5071428571428571,
      "train_speed(iter/s)": 0.223935
    },
    {
      "epoch": 0.476875,
      "grad_norm": 1.340785026550293,
      "learning_rate": 4.290341762755296e-05,
      "loss": 2.383513641357422,
      "memory(GiB)": 22.05,
      "step": 3815,
      "token_acc": 0.41911764705882354,
      "train_speed(iter/s)": 0.22404
    },
    {
      "epoch": 0.4775,
      "grad_norm": 1.6138741970062256,
      "learning_rate": 4.2825079437246675e-05,
      "loss": 2.596460151672363,
      "memory(GiB)": 22.05,
      "step": 3820,
      "token_acc": 0.4921875,
      "train_speed(iter/s)": 0.224139
    },
    {
      "epoch": 0.478125,
      "grad_norm": 4.192572593688965,
      "learning_rate": 4.274673035537495e-05,
      "loss": 2.1796268463134765,
      "memory(GiB)": 22.05,
      "step": 3825,
      "token_acc": 0.48695652173913045,
      "train_speed(iter/s)": 0.224249
    },
    {
      "epoch": 0.47875,
      "grad_norm": 3.2542896270751953,
      "learning_rate": 4.266837068399805e-05,
      "loss": 1.5990300178527832,
      "memory(GiB)": 22.05,
      "step": 3830,
      "token_acc": 0.556390977443609,
      "train_speed(iter/s)": 0.224367
    },
    {
      "epoch": 0.479375,
      "grad_norm": 1.3977916240692139,
      "learning_rate": 4.2590000725216996e-05,
      "loss": 2.2853702545166015,
      "memory(GiB)": 22.05,
      "step": 3835,
      "token_acc": 0.5271317829457365,
      "train_speed(iter/s)": 0.224474
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.024240016937256,
      "learning_rate": 4.251162078117254e-05,
      "loss": 3.009485626220703,
      "memory(GiB)": 22.05,
      "step": 3840,
      "token_acc": 0.3893129770992366,
      "train_speed(iter/s)": 0.224578
    },
    {
      "epoch": 0.480625,
      "grad_norm": 1.6096128225326538,
      "learning_rate": 4.243323115404388e-05,
      "loss": 1.7336391448974608,
      "memory(GiB)": 22.05,
      "step": 3845,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.224686
    },
    {
      "epoch": 0.48125,
      "grad_norm": 1.8219256401062012,
      "learning_rate": 4.235483214604756e-05,
      "loss": 1.505497360229492,
      "memory(GiB)": 22.05,
      "step": 3850,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.224797
    },
    {
      "epoch": 0.481875,
      "grad_norm": 3.6432268619537354,
      "learning_rate": 4.2276424059436315e-05,
      "loss": 1.7699924468994142,
      "memory(GiB)": 22.05,
      "step": 3855,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.224928
    },
    {
      "epoch": 0.4825,
      "grad_norm": 2.5580263137817383,
      "learning_rate": 4.219800719649784e-05,
      "loss": 2.0484081268310548,
      "memory(GiB)": 22.05,
      "step": 3860,
      "token_acc": 0.5877862595419847,
      "train_speed(iter/s)": 0.225069
    },
    {
      "epoch": 0.483125,
      "grad_norm": 1.9271012544631958,
      "learning_rate": 4.211958185955367e-05,
      "loss": 2.404846954345703,
      "memory(GiB)": 22.05,
      "step": 3865,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.225173
    },
    {
      "epoch": 0.48375,
      "grad_norm": 1.3261064291000366,
      "learning_rate": 4.204114835095807e-05,
      "loss": 1.6010213851928712,
      "memory(GiB)": 22.05,
      "step": 3870,
      "token_acc": 0.6015037593984962,
      "train_speed(iter/s)": 0.225286
    },
    {
      "epoch": 0.484375,
      "grad_norm": 1.8502275943756104,
      "learning_rate": 4.1962706973096726e-05,
      "loss": 2.2819791793823243,
      "memory(GiB)": 22.05,
      "step": 3875,
      "token_acc": 0.4918032786885246,
      "train_speed(iter/s)": 0.225396
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.5171114206314087,
      "learning_rate": 4.188425802838571e-05,
      "loss": 2.167735290527344,
      "memory(GiB)": 22.05,
      "step": 3880,
      "token_acc": 0.496,
      "train_speed(iter/s)": 0.225504
    },
    {
      "epoch": 0.485625,
      "grad_norm": 1.6977002620697021,
      "learning_rate": 4.1805801819270265e-05,
      "loss": 2.1293899536132814,
      "memory(GiB)": 22.05,
      "step": 3885,
      "token_acc": 0.5378787878787878,
      "train_speed(iter/s)": 0.225611
    },
    {
      "epoch": 0.48625,
      "grad_norm": 4.550335884094238,
      "learning_rate": 4.1727338648223615e-05,
      "loss": 2.889128875732422,
      "memory(GiB)": 22.05,
      "step": 3890,
      "token_acc": 0.448,
      "train_speed(iter/s)": 0.225719
    },
    {
      "epoch": 0.486875,
      "grad_norm": 1.3917896747589111,
      "learning_rate": 4.164886881774587e-05,
      "loss": 2.1684146881103517,
      "memory(GiB)": 22.05,
      "step": 3895,
      "token_acc": 0.4878048780487805,
      "train_speed(iter/s)": 0.225822
    },
    {
      "epoch": 0.4875,
      "grad_norm": 3.4725499153137207,
      "learning_rate": 4.157039263036275e-05,
      "loss": 1.56927433013916,
      "memory(GiB)": 22.05,
      "step": 3900,
      "token_acc": 0.6341463414634146,
      "train_speed(iter/s)": 0.225927
    },
    {
      "epoch": 0.488125,
      "grad_norm": 3.8588008880615234,
      "learning_rate": 4.149191038862455e-05,
      "loss": 1.6668582916259767,
      "memory(GiB)": 22.05,
      "step": 3905,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.226031
    },
    {
      "epoch": 0.48875,
      "grad_norm": 1.4869511127471924,
      "learning_rate": 4.141342239510485e-05,
      "loss": 2.008845329284668,
      "memory(GiB)": 22.05,
      "step": 3910,
      "token_acc": 0.5877862595419847,
      "train_speed(iter/s)": 0.226139
    },
    {
      "epoch": 0.489375,
      "grad_norm": 1.5962473154067993,
      "learning_rate": 4.1334928952399454e-05,
      "loss": 1.701045608520508,
      "memory(GiB)": 22.05,
      "step": 3915,
      "token_acc": 0.6356589147286822,
      "train_speed(iter/s)": 0.226254
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1171356439590454,
      "learning_rate": 4.1256430363125134e-05,
      "loss": 2.266487884521484,
      "memory(GiB)": 22.05,
      "step": 3920,
      "token_acc": 0.5317460317460317,
      "train_speed(iter/s)": 0.226349
    },
    {
      "epoch": 0.490625,
      "grad_norm": 2.0563695430755615,
      "learning_rate": 4.117792692991854e-05,
      "loss": 2.1047880172729494,
      "memory(GiB)": 22.05,
      "step": 3925,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.226456
    },
    {
      "epoch": 0.49125,
      "grad_norm": 2.345409870147705,
      "learning_rate": 4.109941895543494e-05,
      "loss": 3.005440902709961,
      "memory(GiB)": 22.05,
      "step": 3930,
      "token_acc": 0.3247863247863248,
      "train_speed(iter/s)": 0.226563
    },
    {
      "epoch": 0.491875,
      "grad_norm": 1.2222368717193604,
      "learning_rate": 4.1020906742347185e-05,
      "loss": 2.3776134490966796,
      "memory(GiB)": 22.05,
      "step": 3935,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.226665
    },
    {
      "epoch": 0.4925,
      "grad_norm": 1.4521818161010742,
      "learning_rate": 4.094239059334441e-05,
      "loss": 1.9282926559448241,
      "memory(GiB)": 22.05,
      "step": 3940,
      "token_acc": 0.643312101910828,
      "train_speed(iter/s)": 0.226769
    },
    {
      "epoch": 0.493125,
      "grad_norm": 1.2560404539108276,
      "learning_rate": 4.086387081113095e-05,
      "loss": 1.2411571502685548,
      "memory(GiB)": 22.05,
      "step": 3945,
      "token_acc": 0.648854961832061,
      "train_speed(iter/s)": 0.226875
    },
    {
      "epoch": 0.49375,
      "grad_norm": 1.6538275480270386,
      "learning_rate": 4.078534769842513e-05,
      "loss": 1.7226459503173828,
      "memory(GiB)": 22.05,
      "step": 3950,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.226975
    },
    {
      "epoch": 0.494375,
      "grad_norm": 1.981142282485962,
      "learning_rate": 4.070682155795815e-05,
      "loss": 2.0997642517089843,
      "memory(GiB)": 22.05,
      "step": 3955,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.227078
    },
    {
      "epoch": 0.495,
      "grad_norm": 4.078260898590088,
      "learning_rate": 4.062829269247283e-05,
      "loss": 2.1815853118896484,
      "memory(GiB)": 22.05,
      "step": 3960,
      "token_acc": 0.46956521739130436,
      "train_speed(iter/s)": 0.227178
    },
    {
      "epoch": 0.495625,
      "grad_norm": 0.9078883528709412,
      "learning_rate": 4.054976140472254e-05,
      "loss": 1.9721361160278321,
      "memory(GiB)": 22.05,
      "step": 3965,
      "token_acc": 0.5403225806451613,
      "train_speed(iter/s)": 0.227281
    },
    {
      "epoch": 0.49625,
      "grad_norm": 4.191254138946533,
      "learning_rate": 4.047122799746997e-05,
      "loss": 2.321419906616211,
      "memory(GiB)": 22.05,
      "step": 3970,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.227383
    },
    {
      "epoch": 0.496875,
      "grad_norm": 4.018939018249512,
      "learning_rate": 4.039269277348599e-05,
      "loss": 2.5391525268554687,
      "memory(GiB)": 22.05,
      "step": 3975,
      "token_acc": 0.4878048780487805,
      "train_speed(iter/s)": 0.227482
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.8065913915634155,
      "learning_rate": 4.0314156035548456e-05,
      "loss": 2.011351203918457,
      "memory(GiB)": 22.05,
      "step": 3980,
      "token_acc": 0.5514705882352942,
      "train_speed(iter/s)": 0.227587
    },
    {
      "epoch": 0.498125,
      "grad_norm": 1.3699641227722168,
      "learning_rate": 4.0235618086441095e-05,
      "loss": 1.9407045364379882,
      "memory(GiB)": 22.05,
      "step": 3985,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.227683
    },
    {
      "epoch": 0.49875,
      "grad_norm": 1.5202852487564087,
      "learning_rate": 4.0157079228952245e-05,
      "loss": 1.3764165878295898,
      "memory(GiB)": 22.05,
      "step": 3990,
      "token_acc": 0.640625,
      "train_speed(iter/s)": 0.227791
    },
    {
      "epoch": 0.499375,
      "grad_norm": 1.6975294351577759,
      "learning_rate": 4.007853976587381e-05,
      "loss": 2.4156946182250976,
      "memory(GiB)": 22.05,
      "step": 3995,
      "token_acc": 0.4846153846153846,
      "train_speed(iter/s)": 0.227886
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.285238265991211,
      "learning_rate": 4e-05,
      "loss": 3.1096288681030275,
      "memory(GiB)": 22.05,
      "step": 4000,
      "token_acc": 0.43089430894308944,
      "train_speed(iter/s)": 0.227983
    },
    {
      "epoch": 0.5,
      "eval_loss": 1.616034746170044,
      "eval_runtime": 5567.8404,
      "eval_samples_per_second": 1.437,
      "eval_steps_per_second": 1.437,
      "eval_token_acc": 0.6084485807891914,
      "step": 4000
    },
    {
      "epoch": 0.500625,
      "grad_norm": 5.767704010009766,
      "learning_rate": 3.99214602341262e-05,
      "loss": 1.8080856323242187,
      "memory(GiB)": 22.05,
      "step": 4005,
      "token_acc": 0.6083511095238555,
      "train_speed(iter/s)": 0.173121
    },
    {
      "epoch": 0.50125,
      "grad_norm": 1.4705655574798584,
      "learning_rate": 3.984292077104777e-05,
      "loss": 1.740196418762207,
      "memory(GiB)": 22.05,
      "step": 4010,
      "token_acc": 0.5663716814159292,
      "train_speed(iter/s)": 0.173221
    },
    {
      "epoch": 0.501875,
      "grad_norm": 1.6639155149459839,
      "learning_rate": 3.976438191355893e-05,
      "loss": 1.6681293487548827,
      "memory(GiB)": 22.05,
      "step": 4015,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.17333
    },
    {
      "epoch": 0.5025,
      "grad_norm": 1.2923773527145386,
      "learning_rate": 3.9685843964451565e-05,
      "loss": 1.259568691253662,
      "memory(GiB)": 22.05,
      "step": 4020,
      "token_acc": 0.712,
      "train_speed(iter/s)": 0.173442
    },
    {
      "epoch": 0.503125,
      "grad_norm": 1.5980271100997925,
      "learning_rate": 3.960730722651402e-05,
      "loss": 2.1109609603881836,
      "memory(GiB)": 22.05,
      "step": 4025,
      "token_acc": 0.5590551181102362,
      "train_speed(iter/s)": 0.173554
    },
    {
      "epoch": 0.50375,
      "grad_norm": 0.9466233849525452,
      "learning_rate": 3.952877200253003e-05,
      "loss": 1.7305421829223633,
      "memory(GiB)": 22.05,
      "step": 4030,
      "token_acc": 0.5648854961832062,
      "train_speed(iter/s)": 0.173666
    },
    {
      "epoch": 0.504375,
      "grad_norm": 1.5617952346801758,
      "learning_rate": 3.9450238595277463e-05,
      "loss": 2.2428508758544923,
      "memory(GiB)": 22.05,
      "step": 4035,
      "token_acc": 0.4262295081967213,
      "train_speed(iter/s)": 0.173781
    },
    {
      "epoch": 0.505,
      "grad_norm": 2.3165245056152344,
      "learning_rate": 3.9371707307527184e-05,
      "loss": 1.6560455322265626,
      "memory(GiB)": 22.05,
      "step": 4040,
      "token_acc": 0.5811965811965812,
      "train_speed(iter/s)": 0.1739
    },
    {
      "epoch": 0.505625,
      "grad_norm": 4.079299449920654,
      "learning_rate": 3.929317844204186e-05,
      "loss": 3.0547428131103516,
      "memory(GiB)": 22.05,
      "step": 4045,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.174006
    },
    {
      "epoch": 0.50625,
      "grad_norm": 1.5628899335861206,
      "learning_rate": 3.921465230157488e-05,
      "loss": 1.9282363891601562,
      "memory(GiB)": 22.05,
      "step": 4050,
      "token_acc": 0.5441176470588235,
      "train_speed(iter/s)": 0.174118
    },
    {
      "epoch": 0.506875,
      "grad_norm": 3.003629207611084,
      "learning_rate": 3.913612918886906e-05,
      "loss": 2.201742935180664,
      "memory(GiB)": 22.05,
      "step": 4055,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.174225
    },
    {
      "epoch": 0.5075,
      "grad_norm": 3.273158311843872,
      "learning_rate": 3.90576094066556e-05,
      "loss": 2.0441867828369142,
      "memory(GiB)": 22.05,
      "step": 4060,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.174332
    },
    {
      "epoch": 0.508125,
      "grad_norm": 1.5607610940933228,
      "learning_rate": 3.897909325765282e-05,
      "loss": 2.0506475448608397,
      "memory(GiB)": 22.05,
      "step": 4065,
      "token_acc": 0.5038759689922481,
      "train_speed(iter/s)": 0.17444
    },
    {
      "epoch": 0.50875,
      "grad_norm": 3.5301196575164795,
      "learning_rate": 3.8900581044565066e-05,
      "loss": 1.7514108657836913,
      "memory(GiB)": 22.05,
      "step": 4070,
      "token_acc": 0.6071428571428571,
      "train_speed(iter/s)": 0.174549
    },
    {
      "epoch": 0.509375,
      "grad_norm": 4.2990899085998535,
      "learning_rate": 3.8822073070081475e-05,
      "loss": 2.823354721069336,
      "memory(GiB)": 22.05,
      "step": 4075,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.174656
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2276341915130615,
      "learning_rate": 3.874356963687487e-05,
      "loss": 2.2754934310913084,
      "memory(GiB)": 22.05,
      "step": 4080,
      "token_acc": 0.45925925925925926,
      "train_speed(iter/s)": 0.174762
    },
    {
      "epoch": 0.510625,
      "grad_norm": 5.559763431549072,
      "learning_rate": 3.866507104760056e-05,
      "loss": 2.3533782958984375,
      "memory(GiB)": 22.05,
      "step": 4085,
      "token_acc": 0.5286624203821656,
      "train_speed(iter/s)": 0.174872
    },
    {
      "epoch": 0.51125,
      "grad_norm": 4.244390964508057,
      "learning_rate": 3.858657760489516e-05,
      "loss": 2.6502029418945314,
      "memory(GiB)": 22.05,
      "step": 4090,
      "token_acc": 0.4965034965034965,
      "train_speed(iter/s)": 0.174983
    },
    {
      "epoch": 0.511875,
      "grad_norm": 2.3235883712768555,
      "learning_rate": 3.850808961137547e-05,
      "loss": 2.3103322982788086,
      "memory(GiB)": 22.05,
      "step": 4095,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.175093
    },
    {
      "epoch": 0.5125,
      "grad_norm": 2.025017023086548,
      "learning_rate": 3.842960736963727e-05,
      "loss": 1.6396556854248048,
      "memory(GiB)": 22.05,
      "step": 4100,
      "token_acc": 0.6484375,
      "train_speed(iter/s)": 0.175203
    },
    {
      "epoch": 0.513125,
      "grad_norm": 5.325440406799316,
      "learning_rate": 3.8351131182254146e-05,
      "loss": 2.2694585800170897,
      "memory(GiB)": 22.05,
      "step": 4105,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.175306
    },
    {
      "epoch": 0.51375,
      "grad_norm": 4.629547595977783,
      "learning_rate": 3.8272661351776385e-05,
      "loss": 1.880235481262207,
      "memory(GiB)": 22.05,
      "step": 4110,
      "token_acc": 0.5867768595041323,
      "train_speed(iter/s)": 0.175415
    },
    {
      "epoch": 0.514375,
      "grad_norm": 4.917431354522705,
      "learning_rate": 3.819419818072974e-05,
      "loss": 1.876198959350586,
      "memory(GiB)": 22.05,
      "step": 4115,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.175524
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.3280776739120483,
      "learning_rate": 3.81157419716143e-05,
      "loss": 1.7475040435791016,
      "memory(GiB)": 22.05,
      "step": 4120,
      "token_acc": 0.5734265734265734,
      "train_speed(iter/s)": 0.175633
    },
    {
      "epoch": 0.515625,
      "grad_norm": 3.7021563053131104,
      "learning_rate": 3.803729302690328e-05,
      "loss": 2.0431041717529297,
      "memory(GiB)": 22.05,
      "step": 4125,
      "token_acc": 0.5038759689922481,
      "train_speed(iter/s)": 0.175742
    },
    {
      "epoch": 0.51625,
      "grad_norm": 3.284334421157837,
      "learning_rate": 3.795885164904194e-05,
      "loss": 2.0993961334228515,
      "memory(GiB)": 22.05,
      "step": 4130,
      "token_acc": 0.5307692307692308,
      "train_speed(iter/s)": 0.175849
    },
    {
      "epoch": 0.516875,
      "grad_norm": 1.6942377090454102,
      "learning_rate": 3.7880418140446336e-05,
      "loss": 1.8664566040039063,
      "memory(GiB)": 22.05,
      "step": 4135,
      "token_acc": 0.5970149253731343,
      "train_speed(iter/s)": 0.175958
    },
    {
      "epoch": 0.5175,
      "grad_norm": 5.401129722595215,
      "learning_rate": 3.780199280350218e-05,
      "loss": 2.334530258178711,
      "memory(GiB)": 22.05,
      "step": 4140,
      "token_acc": 0.5398230088495575,
      "train_speed(iter/s)": 0.176067
    },
    {
      "epoch": 0.518125,
      "grad_norm": 1.2845251560211182,
      "learning_rate": 3.7723575940563705e-05,
      "loss": 2.097111129760742,
      "memory(GiB)": 22.05,
      "step": 4145,
      "token_acc": 0.4921875,
      "train_speed(iter/s)": 0.176171
    },
    {
      "epoch": 0.51875,
      "grad_norm": 3.1276848316192627,
      "learning_rate": 3.764516785395244e-05,
      "loss": 2.1684890747070313,
      "memory(GiB)": 22.05,
      "step": 4150,
      "token_acc": 0.49295774647887325,
      "train_speed(iter/s)": 0.176277
    },
    {
      "epoch": 0.519375,
      "grad_norm": 1.924700379371643,
      "learning_rate": 3.756676884595613e-05,
      "loss": 1.787827491760254,
      "memory(GiB)": 22.05,
      "step": 4155,
      "token_acc": 0.5864661654135338,
      "train_speed(iter/s)": 0.176383
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5011622905731201,
      "learning_rate": 3.7488379218827466e-05,
      "loss": 2.4604949951171875,
      "memory(GiB)": 22.05,
      "step": 4160,
      "token_acc": 0.4485294117647059,
      "train_speed(iter/s)": 0.176492
    },
    {
      "epoch": 0.520625,
      "grad_norm": 1.5193549394607544,
      "learning_rate": 3.740999927478301e-05,
      "loss": 1.7956634521484376,
      "memory(GiB)": 22.05,
      "step": 4165,
      "token_acc": 0.6147540983606558,
      "train_speed(iter/s)": 0.176599
    },
    {
      "epoch": 0.52125,
      "grad_norm": 2.2131359577178955,
      "learning_rate": 3.7331629316001964e-05,
      "loss": 2.1603044509887694,
      "memory(GiB)": 22.05,
      "step": 4170,
      "token_acc": 0.45925925925925926,
      "train_speed(iter/s)": 0.176707
    },
    {
      "epoch": 0.521875,
      "grad_norm": 1.1479138135910034,
      "learning_rate": 3.725326964462506e-05,
      "loss": 2.000416946411133,
      "memory(GiB)": 22.05,
      "step": 4175,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.176813
    },
    {
      "epoch": 0.5225,
      "grad_norm": 3.4653148651123047,
      "learning_rate": 3.7174920562753345e-05,
      "loss": 3.119207191467285,
      "memory(GiB)": 22.05,
      "step": 4180,
      "token_acc": 0.38571428571428573,
      "train_speed(iter/s)": 0.176918
    },
    {
      "epoch": 0.523125,
      "grad_norm": 1.4009361267089844,
      "learning_rate": 3.709658237244705e-05,
      "loss": 1.5261222839355468,
      "memory(GiB)": 22.05,
      "step": 4185,
      "token_acc": 0.592,
      "train_speed(iter/s)": 0.177021
    },
    {
      "epoch": 0.52375,
      "grad_norm": 2.9847445487976074,
      "learning_rate": 3.7018255375724416e-05,
      "loss": 1.7094196319580077,
      "memory(GiB)": 22.05,
      "step": 4190,
      "token_acc": 0.6124031007751938,
      "train_speed(iter/s)": 0.177126
    },
    {
      "epoch": 0.524375,
      "grad_norm": 1.4819817543029785,
      "learning_rate": 3.693993987456055e-05,
      "loss": 2.195392036437988,
      "memory(GiB)": 22.05,
      "step": 4195,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.177231
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.6938472986221313,
      "learning_rate": 3.686163617088621e-05,
      "loss": 1.7590360641479492,
      "memory(GiB)": 22.05,
      "step": 4200,
      "token_acc": 0.6312056737588653,
      "train_speed(iter/s)": 0.177338
    },
    {
      "epoch": 0.525625,
      "grad_norm": 1.3650991916656494,
      "learning_rate": 3.6783344566586665e-05,
      "loss": 1.6711538314819336,
      "memory(GiB)": 22.05,
      "step": 4205,
      "token_acc": 0.6397058823529411,
      "train_speed(iter/s)": 0.177448
    },
    {
      "epoch": 0.52625,
      "grad_norm": 4.258857727050781,
      "learning_rate": 3.670506536350058e-05,
      "loss": 2.162323760986328,
      "memory(GiB)": 22.05,
      "step": 4210,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.177553
    },
    {
      "epoch": 0.526875,
      "grad_norm": 3.4515631198883057,
      "learning_rate": 3.662679886341877e-05,
      "loss": 2.0739826202392577,
      "memory(GiB)": 22.05,
      "step": 4215,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.177657
    },
    {
      "epoch": 0.5275,
      "grad_norm": 1.3874599933624268,
      "learning_rate": 3.6548545368083074e-05,
      "loss": 2.662574577331543,
      "memory(GiB)": 22.05,
      "step": 4220,
      "token_acc": 0.4453125,
      "train_speed(iter/s)": 0.177761
    },
    {
      "epoch": 0.528125,
      "grad_norm": 1.6508368253707886,
      "learning_rate": 3.647030517918523e-05,
      "loss": 2.496569061279297,
      "memory(GiB)": 22.05,
      "step": 4225,
      "token_acc": 0.4322033898305085,
      "train_speed(iter/s)": 0.177866
    },
    {
      "epoch": 0.52875,
      "grad_norm": 4.566071033477783,
      "learning_rate": 3.6392078598365636e-05,
      "loss": 1.4968252182006836,
      "memory(GiB)": 22.05,
      "step": 4230,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.17797
    },
    {
      "epoch": 0.529375,
      "grad_norm": 5.388280868530273,
      "learning_rate": 3.631386592721227e-05,
      "loss": 2.3380714416503907,
      "memory(GiB)": 22.05,
      "step": 4235,
      "token_acc": 0.5620437956204379,
      "train_speed(iter/s)": 0.178076
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3983333110809326,
      "learning_rate": 3.623566746725943e-05,
      "loss": 1.8772552490234375,
      "memory(GiB)": 22.05,
      "step": 4240,
      "token_acc": 0.6014492753623188,
      "train_speed(iter/s)": 0.178184
    },
    {
      "epoch": 0.530625,
      "grad_norm": 2.6023478507995605,
      "learning_rate": 3.6157483519986676e-05,
      "loss": 2.082284355163574,
      "memory(GiB)": 22.05,
      "step": 4245,
      "token_acc": 0.47107438016528924,
      "train_speed(iter/s)": 0.178288
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.0554559230804443,
      "learning_rate": 3.6079314386817575e-05,
      "loss": 1.6303445816040039,
      "memory(GiB)": 22.05,
      "step": 4250,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.178396
    },
    {
      "epoch": 0.531875,
      "grad_norm": 3.0035035610198975,
      "learning_rate": 3.600116036911863e-05,
      "loss": 2.031885528564453,
      "memory(GiB)": 22.05,
      "step": 4255,
      "token_acc": 0.5564516129032258,
      "train_speed(iter/s)": 0.178498
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.172474980354309,
      "learning_rate": 3.592302176819801e-05,
      "loss": 1.7281801223754882,
      "memory(GiB)": 22.05,
      "step": 4260,
      "token_acc": 0.6141732283464567,
      "train_speed(iter/s)": 0.178602
    },
    {
      "epoch": 0.533125,
      "grad_norm": 1.2747129201889038,
      "learning_rate": 3.5844898885304485e-05,
      "loss": 2.811337471008301,
      "memory(GiB)": 22.05,
      "step": 4265,
      "token_acc": 0.48507462686567165,
      "train_speed(iter/s)": 0.178705
    },
    {
      "epoch": 0.53375,
      "grad_norm": 1.7096202373504639,
      "learning_rate": 3.576679202162623e-05,
      "loss": 1.8838150024414062,
      "memory(GiB)": 22.05,
      "step": 4270,
      "token_acc": 0.562962962962963,
      "train_speed(iter/s)": 0.178804
    },
    {
      "epoch": 0.534375,
      "grad_norm": 2.86923885345459,
      "learning_rate": 3.568870147828963e-05,
      "loss": 2.4521522521972656,
      "memory(GiB)": 22.05,
      "step": 4275,
      "token_acc": 0.45038167938931295,
      "train_speed(iter/s)": 0.178903
    },
    {
      "epoch": 0.535,
      "grad_norm": 1.1425580978393555,
      "learning_rate": 3.561062755635819e-05,
      "loss": 1.5681297302246093,
      "memory(GiB)": 22.05,
      "step": 4280,
      "token_acc": 0.627906976744186,
      "train_speed(iter/s)": 0.17901
    },
    {
      "epoch": 0.535625,
      "grad_norm": 2.0770251750946045,
      "learning_rate": 3.553257055683131e-05,
      "loss": 1.8863265991210938,
      "memory(GiB)": 22.05,
      "step": 4285,
      "token_acc": 0.5785714285714286,
      "train_speed(iter/s)": 0.179118
    },
    {
      "epoch": 0.53625,
      "grad_norm": 4.219502925872803,
      "learning_rate": 3.545453078064316e-05,
      "loss": 2.144917297363281,
      "memory(GiB)": 22.05,
      "step": 4290,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.179224
    },
    {
      "epoch": 0.536875,
      "grad_norm": 1.890790343284607,
      "learning_rate": 3.537650852866149e-05,
      "loss": 2.4127933502197267,
      "memory(GiB)": 22.05,
      "step": 4295,
      "token_acc": 0.5079365079365079,
      "train_speed(iter/s)": 0.179327
    },
    {
      "epoch": 0.5375,
      "grad_norm": 1.521560549736023,
      "learning_rate": 3.52985041016865e-05,
      "loss": 1.7950448989868164,
      "memory(GiB)": 22.05,
      "step": 4300,
      "token_acc": 0.5703703703703704,
      "train_speed(iter/s)": 0.179432
    },
    {
      "epoch": 0.538125,
      "grad_norm": 4.338151931762695,
      "learning_rate": 3.5220517800449685e-05,
      "loss": 2.1171642303466798,
      "memory(GiB)": 22.05,
      "step": 4305,
      "token_acc": 0.5891472868217055,
      "train_speed(iter/s)": 0.179535
    },
    {
      "epoch": 0.53875,
      "grad_norm": 1.87291419506073,
      "learning_rate": 3.514254992561263e-05,
      "loss": 2.3366601943969725,
      "memory(GiB)": 22.05,
      "step": 4310,
      "token_acc": 0.48507462686567165,
      "train_speed(iter/s)": 0.179633
    },
    {
      "epoch": 0.539375,
      "grad_norm": 1.1800928115844727,
      "learning_rate": 3.506460077776588e-05,
      "loss": 3.013932991027832,
      "memory(GiB)": 22.05,
      "step": 4315,
      "token_acc": 0.3923076923076923,
      "train_speed(iter/s)": 0.179731
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.347949028015137,
      "learning_rate": 3.498667065742783e-05,
      "loss": 2.2411033630371096,
      "memory(GiB)": 22.05,
      "step": 4320,
      "token_acc": 0.4728682170542636,
      "train_speed(iter/s)": 0.179837
    },
    {
      "epoch": 0.540625,
      "grad_norm": 1.3139328956604004,
      "learning_rate": 3.490875986504348e-05,
      "loss": 1.633803367614746,
      "memory(GiB)": 22.05,
      "step": 4325,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.179943
    },
    {
      "epoch": 0.54125,
      "grad_norm": 1.044124960899353,
      "learning_rate": 3.48308687009833e-05,
      "loss": 0.9092823028564453,
      "memory(GiB)": 22.05,
      "step": 4330,
      "token_acc": 0.788135593220339,
      "train_speed(iter/s)": 0.180034
    },
    {
      "epoch": 0.541875,
      "grad_norm": 1.3809314966201782,
      "learning_rate": 3.475299746554211e-05,
      "loss": 1.6027961730957032,
      "memory(GiB)": 22.05,
      "step": 4335,
      "token_acc": 0.6571428571428571,
      "train_speed(iter/s)": 0.180137
    },
    {
      "epoch": 0.5425,
      "grad_norm": 0.9574234485626221,
      "learning_rate": 3.4675146458937916e-05,
      "loss": 1.8359357833862304,
      "memory(GiB)": 22.05,
      "step": 4340,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.180239
    },
    {
      "epoch": 0.543125,
      "grad_norm": 3.559790849685669,
      "learning_rate": 3.4597315981310684e-05,
      "loss": 2.329361152648926,
      "memory(GiB)": 22.05,
      "step": 4345,
      "token_acc": 0.49137931034482757,
      "train_speed(iter/s)": 0.18034
    },
    {
      "epoch": 0.54375,
      "grad_norm": 5.675775051116943,
      "learning_rate": 3.451950633272129e-05,
      "loss": 1.3967348098754884,
      "memory(GiB)": 22.05,
      "step": 4350,
      "token_acc": 0.6515151515151515,
      "train_speed(iter/s)": 0.180442
    },
    {
      "epoch": 0.544375,
      "grad_norm": 2.8511712551116943,
      "learning_rate": 3.444171781315025e-05,
      "loss": 2.8258880615234374,
      "memory(GiB)": 22.05,
      "step": 4355,
      "token_acc": 0.49635036496350365,
      "train_speed(iter/s)": 0.18054
    },
    {
      "epoch": 0.545,
      "grad_norm": 1.7447595596313477,
      "learning_rate": 3.4363950722496696e-05,
      "loss": 2.5459733963012696,
      "memory(GiB)": 22.05,
      "step": 4360,
      "token_acc": 0.4696969696969697,
      "train_speed(iter/s)": 0.180641
    },
    {
      "epoch": 0.545625,
      "grad_norm": 3.661440849304199,
      "learning_rate": 3.428620536057707e-05,
      "loss": 1.8893543243408204,
      "memory(GiB)": 22.05,
      "step": 4365,
      "token_acc": 0.5642857142857143,
      "train_speed(iter/s)": 0.180744
    },
    {
      "epoch": 0.54625,
      "grad_norm": 2.411144495010376,
      "learning_rate": 3.420848202712409e-05,
      "loss": 1.6939598083496095,
      "memory(GiB)": 22.05,
      "step": 4370,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.180849
    },
    {
      "epoch": 0.546875,
      "grad_norm": 1.2342056035995483,
      "learning_rate": 3.4130781021785535e-05,
      "loss": 1.9827568054199218,
      "memory(GiB)": 22.05,
      "step": 4375,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.18095
    },
    {
      "epoch": 0.5475,
      "grad_norm": 4.326310157775879,
      "learning_rate": 3.405310264412308e-05,
      "loss": 2.263703536987305,
      "memory(GiB)": 22.05,
      "step": 4380,
      "token_acc": 0.5255474452554745,
      "train_speed(iter/s)": 0.181052
    },
    {
      "epoch": 0.548125,
      "grad_norm": 1.4606144428253174,
      "learning_rate": 3.397544719361121e-05,
      "loss": 2.5056385040283202,
      "memory(GiB)": 22.05,
      "step": 4385,
      "token_acc": 0.44680851063829785,
      "train_speed(iter/s)": 0.181144
    },
    {
      "epoch": 0.54875,
      "grad_norm": 1.5058715343475342,
      "learning_rate": 3.389781496963597e-05,
      "loss": 2.066593360900879,
      "memory(GiB)": 22.05,
      "step": 4390,
      "token_acc": 0.49635036496350365,
      "train_speed(iter/s)": 0.18123
    },
    {
      "epoch": 0.549375,
      "grad_norm": 1.6653927564620972,
      "learning_rate": 3.382020627149388e-05,
      "loss": 2.4403898239135744,
      "memory(GiB)": 22.05,
      "step": 4395,
      "token_acc": 0.5206611570247934,
      "train_speed(iter/s)": 0.181322
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.9969048500061035,
      "learning_rate": 3.374262139839076e-05,
      "loss": 1.9919645309448242,
      "memory(GiB)": 22.05,
      "step": 4400,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.181411
    },
    {
      "epoch": 0.550625,
      "grad_norm": 2.050398588180542,
      "learning_rate": 3.3665060649440606e-05,
      "loss": 1.968785858154297,
      "memory(GiB)": 22.05,
      "step": 4405,
      "token_acc": 0.6015625,
      "train_speed(iter/s)": 0.181499
    },
    {
      "epoch": 0.55125,
      "grad_norm": 3.0840179920196533,
      "learning_rate": 3.358752432366436e-05,
      "loss": 2.22421875,
      "memory(GiB)": 22.05,
      "step": 4410,
      "token_acc": 0.49635036496350365,
      "train_speed(iter/s)": 0.181589
    },
    {
      "epoch": 0.551875,
      "grad_norm": 1.6690276861190796,
      "learning_rate": 3.3510012719988816e-05,
      "loss": 3.0522518157958984,
      "memory(GiB)": 22.05,
      "step": 4415,
      "token_acc": 0.3504273504273504,
      "train_speed(iter/s)": 0.181675
    },
    {
      "epoch": 0.5525,
      "grad_norm": 4.019243240356445,
      "learning_rate": 3.343252613724549e-05,
      "loss": 2.2812484741210937,
      "memory(GiB)": 22.05,
      "step": 4420,
      "token_acc": 0.5086206896551724,
      "train_speed(iter/s)": 0.181762
    },
    {
      "epoch": 0.553125,
      "grad_norm": 5.255859375,
      "learning_rate": 3.335506487416939e-05,
      "loss": 1.8912261962890624,
      "memory(GiB)": 22.05,
      "step": 4425,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.181854
    },
    {
      "epoch": 0.55375,
      "grad_norm": 1.5529941320419312,
      "learning_rate": 3.327762922939793e-05,
      "loss": 2.464903450012207,
      "memory(GiB)": 22.05,
      "step": 4430,
      "token_acc": 0.4806201550387597,
      "train_speed(iter/s)": 0.181953
    },
    {
      "epoch": 0.554375,
      "grad_norm": 1.5530949831008911,
      "learning_rate": 3.3200219501469776e-05,
      "loss": 2.012795257568359,
      "memory(GiB)": 22.05,
      "step": 4435,
      "token_acc": 0.4857142857142857,
      "train_speed(iter/s)": 0.182055
    },
    {
      "epoch": 0.555,
      "grad_norm": 1.2364075183868408,
      "learning_rate": 3.3122835988823616e-05,
      "loss": 1.4993511199951173,
      "memory(GiB)": 22.05,
      "step": 4440,
      "token_acc": 0.6376811594202898,
      "train_speed(iter/s)": 0.182152
    },
    {
      "epoch": 0.555625,
      "grad_norm": 1.6618168354034424,
      "learning_rate": 3.304547898979716e-05,
      "loss": 2.396870994567871,
      "memory(GiB)": 22.05,
      "step": 4445,
      "token_acc": 0.49242424242424243,
      "train_speed(iter/s)": 0.182241
    },
    {
      "epoch": 0.55625,
      "grad_norm": 1.0973753929138184,
      "learning_rate": 3.296814880262582e-05,
      "loss": 1.8883298873901366,
      "memory(GiB)": 22.05,
      "step": 4450,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.182327
    },
    {
      "epoch": 0.556875,
      "grad_norm": 1.4996060132980347,
      "learning_rate": 3.289084572544169e-05,
      "loss": 1.3309330940246582,
      "memory(GiB)": 22.05,
      "step": 4455,
      "token_acc": 0.6307692307692307,
      "train_speed(iter/s)": 0.182418
    },
    {
      "epoch": 0.5575,
      "grad_norm": 3.537334442138672,
      "learning_rate": 3.28135700562723e-05,
      "loss": 2.2515865325927735,
      "memory(GiB)": 22.05,
      "step": 4460,
      "token_acc": 0.5289855072463768,
      "train_speed(iter/s)": 0.182507
    },
    {
      "epoch": 0.558125,
      "grad_norm": 4.01478910446167,
      "learning_rate": 3.273632209303957e-05,
      "loss": 2.1878496170043946,
      "memory(GiB)": 22.05,
      "step": 4465,
      "token_acc": 0.5114503816793893,
      "train_speed(iter/s)": 0.182595
    },
    {
      "epoch": 0.55875,
      "grad_norm": 1.6934794187545776,
      "learning_rate": 3.2659102133558555e-05,
      "loss": 2.221732521057129,
      "memory(GiB)": 22.05,
      "step": 4470,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.182678
    },
    {
      "epoch": 0.559375,
      "grad_norm": 1.75347900390625,
      "learning_rate": 3.2581910475536366e-05,
      "loss": 2.1562664031982424,
      "memory(GiB)": 22.05,
      "step": 4475,
      "token_acc": 0.5106382978723404,
      "train_speed(iter/s)": 0.182767
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3796675205230713,
      "learning_rate": 3.250474741657101e-05,
      "loss": 1.9798381805419922,
      "memory(GiB)": 22.05,
      "step": 4480,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.182854
    },
    {
      "epoch": 0.560625,
      "grad_norm": 1.6265523433685303,
      "learning_rate": 3.242761325415024e-05,
      "loss": 2.493106460571289,
      "memory(GiB)": 22.05,
      "step": 4485,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.182941
    },
    {
      "epoch": 0.56125,
      "grad_norm": 1.589766025543213,
      "learning_rate": 3.235050828565039e-05,
      "loss": 1.6494319915771485,
      "memory(GiB)": 22.05,
      "step": 4490,
      "token_acc": 0.5954198473282443,
      "train_speed(iter/s)": 0.183027
    },
    {
      "epoch": 0.561875,
      "grad_norm": 1.4197697639465332,
      "learning_rate": 3.227343280833524e-05,
      "loss": 2.2928585052490233,
      "memory(GiB)": 22.05,
      "step": 4495,
      "token_acc": 0.4825174825174825,
      "train_speed(iter/s)": 0.183126
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.045225977897644,
      "learning_rate": 3.219638711935488e-05,
      "loss": 1.6687128067016601,
      "memory(GiB)": 22.05,
      "step": 4500,
      "token_acc": 0.6546762589928058,
      "train_speed(iter/s)": 0.183225
    },
    {
      "epoch": 0.563125,
      "grad_norm": 2.2941207885742188,
      "learning_rate": 3.211937151574455e-05,
      "loss": 2.183871841430664,
      "memory(GiB)": 22.05,
      "step": 4505,
      "token_acc": 0.5407407407407407,
      "train_speed(iter/s)": 0.183322
    },
    {
      "epoch": 0.56375,
      "grad_norm": 1.4093633890151978,
      "learning_rate": 3.20423862944235e-05,
      "loss": 1.8418426513671875,
      "memory(GiB)": 22.05,
      "step": 4510,
      "token_acc": 0.5864661654135338,
      "train_speed(iter/s)": 0.183421
    },
    {
      "epoch": 0.564375,
      "grad_norm": 1.6192454099655151,
      "learning_rate": 3.1965431752193875e-05,
      "loss": 2.2864452362060548,
      "memory(GiB)": 22.05,
      "step": 4515,
      "token_acc": 0.48854961832061067,
      "train_speed(iter/s)": 0.183521
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.4995497465133667,
      "learning_rate": 3.188850818573951e-05,
      "loss": 2.1017208099365234,
      "memory(GiB)": 22.05,
      "step": 4520,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.183621
    },
    {
      "epoch": 0.565625,
      "grad_norm": 2.1813547611236572,
      "learning_rate": 3.181161589162482e-05,
      "loss": 1.8287752151489258,
      "memory(GiB)": 22.05,
      "step": 4525,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.183721
    },
    {
      "epoch": 0.56625,
      "grad_norm": 1.5680348873138428,
      "learning_rate": 3.173475516629367e-05,
      "loss": 2.501573944091797,
      "memory(GiB)": 22.05,
      "step": 4530,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.183817
    },
    {
      "epoch": 0.566875,
      "grad_norm": 4.284144401550293,
      "learning_rate": 3.1657926306068225e-05,
      "loss": 2.074422073364258,
      "memory(GiB)": 22.05,
      "step": 4535,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.183911
    },
    {
      "epoch": 0.5675,
      "grad_norm": 1.430005431175232,
      "learning_rate": 3.158112960714778e-05,
      "loss": 2.081225776672363,
      "memory(GiB)": 22.05,
      "step": 4540,
      "token_acc": 0.5874125874125874,
      "train_speed(iter/s)": 0.184007
    },
    {
      "epoch": 0.568125,
      "grad_norm": 1.6787875890731812,
      "learning_rate": 3.150436536560763e-05,
      "loss": 1.61480770111084,
      "memory(GiB)": 22.05,
      "step": 4545,
      "token_acc": 0.6030534351145038,
      "train_speed(iter/s)": 0.184106
    },
    {
      "epoch": 0.56875,
      "grad_norm": 5.430604457855225,
      "learning_rate": 3.142763387739798e-05,
      "loss": 2.826669120788574,
      "memory(GiB)": 22.05,
      "step": 4550,
      "token_acc": 0.3923076923076923,
      "train_speed(iter/s)": 0.184201
    },
    {
      "epoch": 0.569375,
      "grad_norm": 1.4619780778884888,
      "learning_rate": 3.13509354383427e-05,
      "loss": 2.3325897216796876,
      "memory(GiB)": 22.05,
      "step": 4555,
      "token_acc": 0.4726027397260274,
      "train_speed(iter/s)": 0.184289
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.839110374450684,
      "learning_rate": 3.127427034413831e-05,
      "loss": 2.441924285888672,
      "memory(GiB)": 22.05,
      "step": 4560,
      "token_acc": 0.46923076923076923,
      "train_speed(iter/s)": 0.184372
    },
    {
      "epoch": 0.570625,
      "grad_norm": 4.285619258880615,
      "learning_rate": 3.1197638890352704e-05,
      "loss": 2.740767478942871,
      "memory(GiB)": 22.05,
      "step": 4565,
      "token_acc": 0.4621212121212121,
      "train_speed(iter/s)": 0.184458
    },
    {
      "epoch": 0.57125,
      "grad_norm": 1.8821275234222412,
      "learning_rate": 3.1121041372424166e-05,
      "loss": 2.2724536895751952,
      "memory(GiB)": 22.05,
      "step": 4570,
      "token_acc": 0.4726027397260274,
      "train_speed(iter/s)": 0.184553
    },
    {
      "epoch": 0.571875,
      "grad_norm": 1.1623338460922241,
      "learning_rate": 3.1044478085660066e-05,
      "loss": 2.1263238906860353,
      "memory(GiB)": 22.05,
      "step": 4575,
      "token_acc": 0.5390625,
      "train_speed(iter/s)": 0.184648
    },
    {
      "epoch": 0.5725,
      "grad_norm": 2.4432454109191895,
      "learning_rate": 3.096794932523586e-05,
      "loss": 2.6884994506835938,
      "memory(GiB)": 22.05,
      "step": 4580,
      "token_acc": 0.4015748031496063,
      "train_speed(iter/s)": 0.184743
    },
    {
      "epoch": 0.573125,
      "grad_norm": 1.0980228185653687,
      "learning_rate": 3.0891455386193855e-05,
      "loss": 1.1549105644226074,
      "memory(GiB)": 22.05,
      "step": 4585,
      "token_acc": 0.6976744186046512,
      "train_speed(iter/s)": 0.18484
    },
    {
      "epoch": 0.57375,
      "grad_norm": 1.648024559020996,
      "learning_rate": 3.081499656344213e-05,
      "loss": 1.830636978149414,
      "memory(GiB)": 22.05,
      "step": 4590,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.184937
    },
    {
      "epoch": 0.574375,
      "grad_norm": 1.8593889474868774,
      "learning_rate": 3.073857315175339e-05,
      "loss": 1.8817962646484374,
      "memory(GiB)": 22.05,
      "step": 4595,
      "token_acc": 0.4957983193277311,
      "train_speed(iter/s)": 0.185047
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.6751817464828491,
      "learning_rate": 3.06621854457638e-05,
      "loss": 1.9808771133422851,
      "memory(GiB)": 22.05,
      "step": 4600,
      "token_acc": 0.5583333333333333,
      "train_speed(iter/s)": 0.185154
    },
    {
      "epoch": 0.575625,
      "grad_norm": 1.3821613788604736,
      "learning_rate": 3.058583373997184e-05,
      "loss": 2.1413930892944335,
      "memory(GiB)": 22.05,
      "step": 4605,
      "token_acc": 0.5298507462686567,
      "train_speed(iter/s)": 0.185265
    },
    {
      "epoch": 0.57625,
      "grad_norm": 3.7781572341918945,
      "learning_rate": 3.0509518328737287e-05,
      "loss": 2.0346994400024414,
      "memory(GiB)": 22.05,
      "step": 4610,
      "token_acc": 0.49107142857142855,
      "train_speed(iter/s)": 0.185372
    },
    {
      "epoch": 0.576875,
      "grad_norm": 1.4871232509613037,
      "learning_rate": 3.0433239506279916e-05,
      "loss": 1.7329687118530273,
      "memory(GiB)": 22.05,
      "step": 4615,
      "token_acc": 0.5939849624060151,
      "train_speed(iter/s)": 0.185469
    },
    {
      "epoch": 0.5775,
      "grad_norm": 5.753275394439697,
      "learning_rate": 3.035699756667846e-05,
      "loss": 2.020528030395508,
      "memory(GiB)": 22.05,
      "step": 4620,
      "token_acc": 0.5491803278688525,
      "train_speed(iter/s)": 0.185565
    },
    {
      "epoch": 0.578125,
      "grad_norm": 4.524964809417725,
      "learning_rate": 3.028079280386945e-05,
      "loss": 2.2468971252441405,
      "memory(GiB)": 22.05,
      "step": 4625,
      "token_acc": 0.5827338129496403,
      "train_speed(iter/s)": 0.185663
    },
    {
      "epoch": 0.57875,
      "grad_norm": 1.0838333368301392,
      "learning_rate": 3.0204625511646105e-05,
      "loss": 1.8802713394165038,
      "memory(GiB)": 22.05,
      "step": 4630,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.185759
    },
    {
      "epoch": 0.579375,
      "grad_norm": 1.8029100894927979,
      "learning_rate": 3.012849598365718e-05,
      "loss": 1.8134811401367188,
      "memory(GiB)": 22.05,
      "step": 4635,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.185852
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6824989318847656,
      "learning_rate": 3.0052404513405817e-05,
      "loss": 3.0159278869628907,
      "memory(GiB)": 22.05,
      "step": 4640,
      "token_acc": 0.436241610738255,
      "train_speed(iter/s)": 0.185945
    },
    {
      "epoch": 0.580625,
      "grad_norm": 3.3773794174194336,
      "learning_rate": 2.997635139424847e-05,
      "loss": 1.6005041122436523,
      "memory(GiB)": 22.05,
      "step": 4645,
      "token_acc": 0.609271523178808,
      "train_speed(iter/s)": 0.186044
    },
    {
      "epoch": 0.58125,
      "grad_norm": 2.1506259441375732,
      "learning_rate": 2.9900336919393682e-05,
      "loss": 2.280208778381348,
      "memory(GiB)": 22.05,
      "step": 4650,
      "token_acc": 0.4409448818897638,
      "train_speed(iter/s)": 0.186138
    },
    {
      "epoch": 0.581875,
      "grad_norm": 1.4888255596160889,
      "learning_rate": 2.982436138190109e-05,
      "loss": 2.398411750793457,
      "memory(GiB)": 22.05,
      "step": 4655,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.186234
    },
    {
      "epoch": 0.5825,
      "grad_norm": 4.617473125457764,
      "learning_rate": 2.9748425074680133e-05,
      "loss": 2.4942020416259765,
      "memory(GiB)": 22.05,
      "step": 4660,
      "token_acc": 0.4394904458598726,
      "train_speed(iter/s)": 0.186331
    },
    {
      "epoch": 0.583125,
      "grad_norm": 1.6143041849136353,
      "learning_rate": 2.9672528290489073e-05,
      "loss": 2.2128456115722654,
      "memory(GiB)": 22.05,
      "step": 4665,
      "token_acc": 0.5118110236220472,
      "train_speed(iter/s)": 0.186426
    },
    {
      "epoch": 0.58375,
      "grad_norm": 1.405349612236023,
      "learning_rate": 2.9596671321933738e-05,
      "loss": 1.7712902069091796,
      "memory(GiB)": 22.05,
      "step": 4670,
      "token_acc": 0.5864661654135338,
      "train_speed(iter/s)": 0.186519
    },
    {
      "epoch": 0.584375,
      "grad_norm": 5.083706378936768,
      "learning_rate": 2.952085446146651e-05,
      "loss": 2.3859413146972654,
      "memory(GiB)": 22.05,
      "step": 4675,
      "token_acc": 0.48091603053435117,
      "train_speed(iter/s)": 0.186616
    },
    {
      "epoch": 0.585,
      "grad_norm": 2.1921451091766357,
      "learning_rate": 2.9445078001385096e-05,
      "loss": 1.6814701080322265,
      "memory(GiB)": 22.05,
      "step": 4680,
      "token_acc": 0.5873015873015873,
      "train_speed(iter/s)": 0.186712
    },
    {
      "epoch": 0.585625,
      "grad_norm": 1.3833929300308228,
      "learning_rate": 2.9369342233831467e-05,
      "loss": 2.0043745040893555,
      "memory(GiB)": 22.05,
      "step": 4685,
      "token_acc": 0.5367647058823529,
      "train_speed(iter/s)": 0.18681
    },
    {
      "epoch": 0.58625,
      "grad_norm": 1.350807785987854,
      "learning_rate": 2.9293647450790703e-05,
      "loss": 2.1884641647338867,
      "memory(GiB)": 22.05,
      "step": 4690,
      "token_acc": 0.6356589147286822,
      "train_speed(iter/s)": 0.186903
    },
    {
      "epoch": 0.586875,
      "grad_norm": 3.8660802841186523,
      "learning_rate": 2.921799394408992e-05,
      "loss": 2.173741340637207,
      "memory(GiB)": 22.05,
      "step": 4695,
      "token_acc": 0.5214285714285715,
      "train_speed(iter/s)": 0.186998
    },
    {
      "epoch": 0.5875,
      "grad_norm": 1.217070460319519,
      "learning_rate": 2.9142382005397035e-05,
      "loss": 2.0311384201049805,
      "memory(GiB)": 22.05,
      "step": 4700,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.187089
    },
    {
      "epoch": 0.588125,
      "grad_norm": 2.5545520782470703,
      "learning_rate": 2.9066811926219734e-05,
      "loss": 2.456922912597656,
      "memory(GiB)": 22.05,
      "step": 4705,
      "token_acc": 0.4966887417218543,
      "train_speed(iter/s)": 0.187182
    },
    {
      "epoch": 0.58875,
      "grad_norm": 1.262999415397644,
      "learning_rate": 2.8991283997904343e-05,
      "loss": 1.1721273422241212,
      "memory(GiB)": 22.05,
      "step": 4710,
      "token_acc": 0.704,
      "train_speed(iter/s)": 0.187279
    },
    {
      "epoch": 0.589375,
      "grad_norm": 1.1915851831436157,
      "learning_rate": 2.8915798511634653e-05,
      "loss": 1.9677528381347655,
      "memory(GiB)": 22.05,
      "step": 4715,
      "token_acc": 0.5343511450381679,
      "train_speed(iter/s)": 0.187366
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4678161144256592,
      "learning_rate": 2.8840355758430837e-05,
      "loss": 2.7326543807983397,
      "memory(GiB)": 22.05,
      "step": 4720,
      "token_acc": 0.47761194029850745,
      "train_speed(iter/s)": 0.187459
    },
    {
      "epoch": 0.590625,
      "grad_norm": 3.4449715614318848,
      "learning_rate": 2.8764956029148328e-05,
      "loss": 1.7519678115844726,
      "memory(GiB)": 22.05,
      "step": 4725,
      "token_acc": 0.5851851851851851,
      "train_speed(iter/s)": 0.187553
    },
    {
      "epoch": 0.59125,
      "grad_norm": 3.6729023456573486,
      "learning_rate": 2.868959961447666e-05,
      "loss": 2.2257179260253905,
      "memory(GiB)": 22.05,
      "step": 4730,
      "token_acc": 0.5298507462686567,
      "train_speed(iter/s)": 0.187645
    },
    {
      "epoch": 0.591875,
      "grad_norm": 2.6977896690368652,
      "learning_rate": 2.861428680493843e-05,
      "loss": 1.936654281616211,
      "memory(GiB)": 22.05,
      "step": 4735,
      "token_acc": 0.5797101449275363,
      "train_speed(iter/s)": 0.187738
    },
    {
      "epoch": 0.5925,
      "grad_norm": 1.8773866891860962,
      "learning_rate": 2.8539017890888067e-05,
      "loss": 1.7942028045654297,
      "memory(GiB)": 22.05,
      "step": 4740,
      "token_acc": 0.5887096774193549,
      "train_speed(iter/s)": 0.187829
    },
    {
      "epoch": 0.593125,
      "grad_norm": 1.6737370491027832,
      "learning_rate": 2.846379316251081e-05,
      "loss": 1.9059316635131835,
      "memory(GiB)": 22.05,
      "step": 4745,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.187931
    },
    {
      "epoch": 0.59375,
      "grad_norm": 1.4986313581466675,
      "learning_rate": 2.8388612909821515e-05,
      "loss": 2.035122871398926,
      "memory(GiB)": 22.05,
      "step": 4750,
      "token_acc": 0.5891472868217055,
      "train_speed(iter/s)": 0.188023
    },
    {
      "epoch": 0.594375,
      "grad_norm": 4.990082740783691,
      "learning_rate": 2.8313477422663586e-05,
      "loss": 2.6527177810668947,
      "memory(GiB)": 22.05,
      "step": 4755,
      "token_acc": 0.5036496350364964,
      "train_speed(iter/s)": 0.188114
    },
    {
      "epoch": 0.595,
      "grad_norm": 2.530488967895508,
      "learning_rate": 2.823838699070785e-05,
      "loss": 2.7267986297607423,
      "memory(GiB)": 22.05,
      "step": 4760,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.188207
    },
    {
      "epoch": 0.595625,
      "grad_norm": 4.694415092468262,
      "learning_rate": 2.816334190345142e-05,
      "loss": 2.1395763397216796,
      "memory(GiB)": 22.05,
      "step": 4765,
      "token_acc": 0.546875,
      "train_speed(iter/s)": 0.188297
    },
    {
      "epoch": 0.59625,
      "grad_norm": 1.533023476600647,
      "learning_rate": 2.80883424502166e-05,
      "loss": 2.296736145019531,
      "memory(GiB)": 22.05,
      "step": 4770,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.188388
    },
    {
      "epoch": 0.596875,
      "grad_norm": 1.3657827377319336,
      "learning_rate": 2.8013388920149735e-05,
      "loss": 1.5755685806274413,
      "memory(GiB)": 22.05,
      "step": 4775,
      "token_acc": 0.5748031496062992,
      "train_speed(iter/s)": 0.188482
    },
    {
      "epoch": 0.5975,
      "grad_norm": 1.6420433521270752,
      "learning_rate": 2.7938481602220176e-05,
      "loss": 1.9889827728271485,
      "memory(GiB)": 22.05,
      "step": 4780,
      "token_acc": 0.47580645161290325,
      "train_speed(iter/s)": 0.188578
    },
    {
      "epoch": 0.598125,
      "grad_norm": 1.3539855480194092,
      "learning_rate": 2.786362078521905e-05,
      "loss": 2.0034303665161133,
      "memory(GiB)": 22.05,
      "step": 4785,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.18867
    },
    {
      "epoch": 0.59875,
      "grad_norm": 1.2960892915725708,
      "learning_rate": 2.7788806757758264e-05,
      "loss": 1.923360824584961,
      "memory(GiB)": 22.05,
      "step": 4790,
      "token_acc": 0.5671641791044776,
      "train_speed(iter/s)": 0.188764
    },
    {
      "epoch": 0.599375,
      "grad_norm": 2.2649292945861816,
      "learning_rate": 2.7714039808269287e-05,
      "loss": 2.0658920288085936,
      "memory(GiB)": 22.05,
      "step": 4795,
      "token_acc": 0.49122807017543857,
      "train_speed(iter/s)": 0.188858
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3712137937545776,
      "learning_rate": 2.7639320225002108e-05,
      "loss": 1.9814393997192383,
      "memory(GiB)": 22.05,
      "step": 4800,
      "token_acc": 0.5579710144927537,
      "train_speed(iter/s)": 0.188957
    },
    {
      "epoch": 0.600625,
      "grad_norm": 2.445828437805176,
      "learning_rate": 2.7564648296024122e-05,
      "loss": 2.57950496673584,
      "memory(GiB)": 22.05,
      "step": 4805,
      "token_acc": 0.5142857142857142,
      "train_speed(iter/s)": 0.189047
    },
    {
      "epoch": 0.60125,
      "grad_norm": 5.032279968261719,
      "learning_rate": 2.7490024309218984e-05,
      "loss": 2.748651695251465,
      "memory(GiB)": 22.05,
      "step": 4810,
      "token_acc": 0.43089430894308944,
      "train_speed(iter/s)": 0.189141
    },
    {
      "epoch": 0.601875,
      "grad_norm": 3.793264389038086,
      "learning_rate": 2.7415448552285488e-05,
      "loss": 2.0961931228637694,
      "memory(GiB)": 22.05,
      "step": 4815,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.189231
    },
    {
      "epoch": 0.6025,
      "grad_norm": 1.111082911491394,
      "learning_rate": 2.7340921312736557e-05,
      "loss": 2.3625131607055665,
      "memory(GiB)": 22.05,
      "step": 4820,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.189322
    },
    {
      "epoch": 0.603125,
      "grad_norm": 1.0251362323760986,
      "learning_rate": 2.7266442877898013e-05,
      "loss": 1.671583366394043,
      "memory(GiB)": 22.05,
      "step": 4825,
      "token_acc": 0.6356589147286822,
      "train_speed(iter/s)": 0.189406
    },
    {
      "epoch": 0.60375,
      "grad_norm": 1.5737345218658447,
      "learning_rate": 2.7192013534907532e-05,
      "loss": 1.9779972076416015,
      "memory(GiB)": 22.05,
      "step": 4830,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.189494
    },
    {
      "epoch": 0.604375,
      "grad_norm": 1.1257331371307373,
      "learning_rate": 2.7117633570713523e-05,
      "loss": 2.0124179840087892,
      "memory(GiB)": 22.05,
      "step": 4835,
      "token_acc": 0.5864661654135338,
      "train_speed(iter/s)": 0.189579
    },
    {
      "epoch": 0.605,
      "grad_norm": 1.3890992403030396,
      "learning_rate": 2.7043303272074034e-05,
      "loss": 1.6972784042358398,
      "memory(GiB)": 22.05,
      "step": 4840,
      "token_acc": 0.6016260162601627,
      "train_speed(iter/s)": 0.189673
    },
    {
      "epoch": 0.605625,
      "grad_norm": 1.104933738708496,
      "learning_rate": 2.6969022925555614e-05,
      "loss": 1.7877153396606444,
      "memory(GiB)": 22.05,
      "step": 4845,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.189766
    },
    {
      "epoch": 0.60625,
      "grad_norm": 1.2295993566513062,
      "learning_rate": 2.6894792817532267e-05,
      "loss": 1.2678964614868165,
      "memory(GiB)": 22.05,
      "step": 4850,
      "token_acc": 0.6693548387096774,
      "train_speed(iter/s)": 0.189858
    },
    {
      "epoch": 0.606875,
      "grad_norm": 4.972466945648193,
      "learning_rate": 2.682061323418427e-05,
      "loss": 1.7852584838867187,
      "memory(GiB)": 22.05,
      "step": 4855,
      "token_acc": 0.608,
      "train_speed(iter/s)": 0.189956
    },
    {
      "epoch": 0.6075,
      "grad_norm": 3.575056314468384,
      "learning_rate": 2.6746484461497158e-05,
      "loss": 2.640817070007324,
      "memory(GiB)": 22.05,
      "step": 4860,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.190048
    },
    {
      "epoch": 0.608125,
      "grad_norm": 3.2149152755737305,
      "learning_rate": 2.6672406785260537e-05,
      "loss": 2.9640045166015625,
      "memory(GiB)": 22.05,
      "step": 4865,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.190131
    },
    {
      "epoch": 0.60875,
      "grad_norm": 2.655522584915161,
      "learning_rate": 2.6598380491067044e-05,
      "loss": 2.0164600372314454,
      "memory(GiB)": 22.05,
      "step": 4870,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.190225
    },
    {
      "epoch": 0.609375,
      "grad_norm": 3.3718793392181396,
      "learning_rate": 2.6524405864311203e-05,
      "loss": 2.1837366104125975,
      "memory(GiB)": 22.05,
      "step": 4875,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.190313
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.03883695602417,
      "learning_rate": 2.6450483190188347e-05,
      "loss": 1.7251527786254883,
      "memory(GiB)": 22.05,
      "step": 4880,
      "token_acc": 0.6893939393939394,
      "train_speed(iter/s)": 0.190406
    },
    {
      "epoch": 0.610625,
      "grad_norm": 1.1824922561645508,
      "learning_rate": 2.637661275369354e-05,
      "loss": 1.746102523803711,
      "memory(GiB)": 22.05,
      "step": 4885,
      "token_acc": 0.5725806451612904,
      "train_speed(iter/s)": 0.190496
    },
    {
      "epoch": 0.61125,
      "grad_norm": 1.9037387371063232,
      "learning_rate": 2.6302794839620415e-05,
      "loss": 1.8897350311279297,
      "memory(GiB)": 22.05,
      "step": 4890,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.190589
    },
    {
      "epoch": 0.611875,
      "grad_norm": 1.7446528673171997,
      "learning_rate": 2.6229029732560136e-05,
      "loss": 2.3347368240356445,
      "memory(GiB)": 22.05,
      "step": 4895,
      "token_acc": 0.49586776859504134,
      "train_speed(iter/s)": 0.190681
    },
    {
      "epoch": 0.6125,
      "grad_norm": 3.754532814025879,
      "learning_rate": 2.6155317716900274e-05,
      "loss": 2.2776205062866213,
      "memory(GiB)": 22.05,
      "step": 4900,
      "token_acc": 0.5477707006369427,
      "train_speed(iter/s)": 0.190771
    },
    {
      "epoch": 0.613125,
      "grad_norm": 3.2080581188201904,
      "learning_rate": 2.6081659076823753e-05,
      "loss": 2.036007308959961,
      "memory(GiB)": 22.05,
      "step": 4905,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.190859
    },
    {
      "epoch": 0.61375,
      "grad_norm": 1.6197142601013184,
      "learning_rate": 2.6008054096307653e-05,
      "loss": 2.020248794555664,
      "memory(GiB)": 22.05,
      "step": 4910,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.190952
    },
    {
      "epoch": 0.614375,
      "grad_norm": 1.646846890449524,
      "learning_rate": 2.5934503059122217e-05,
      "loss": 1.940298843383789,
      "memory(GiB)": 22.05,
      "step": 4915,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.191043
    },
    {
      "epoch": 0.615,
      "grad_norm": 3.988835096359253,
      "learning_rate": 2.5861006248829723e-05,
      "loss": 1.6885032653808594,
      "memory(GiB)": 22.05,
      "step": 4920,
      "token_acc": 0.5594405594405595,
      "train_speed(iter/s)": 0.191132
    },
    {
      "epoch": 0.615625,
      "grad_norm": 1.4144177436828613,
      "learning_rate": 2.578756394878337e-05,
      "loss": 1.4517550468444824,
      "memory(GiB)": 22.05,
      "step": 4925,
      "token_acc": 0.6412213740458015,
      "train_speed(iter/s)": 0.191224
    },
    {
      "epoch": 0.61625,
      "grad_norm": 2.343766689300537,
      "learning_rate": 2.5714176442126197e-05,
      "loss": 1.6406265258789063,
      "memory(GiB)": 22.05,
      "step": 4930,
      "token_acc": 0.6140350877192983,
      "train_speed(iter/s)": 0.191314
    },
    {
      "epoch": 0.616875,
      "grad_norm": 1.280031681060791,
      "learning_rate": 2.5640844011790035e-05,
      "loss": 1.7316001892089843,
      "memory(GiB)": 22.05,
      "step": 4935,
      "token_acc": 0.5826771653543307,
      "train_speed(iter/s)": 0.191402
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.1982028484344482,
      "learning_rate": 2.5567566940494328e-05,
      "loss": 1.6789125442504882,
      "memory(GiB)": 22.05,
      "step": 4940,
      "token_acc": 0.6538461538461539,
      "train_speed(iter/s)": 0.191493
    },
    {
      "epoch": 0.618125,
      "grad_norm": 3.3524210453033447,
      "learning_rate": 2.5494345510745154e-05,
      "loss": 2.126527786254883,
      "memory(GiB)": 22.05,
      "step": 4945,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.191573
    },
    {
      "epoch": 0.61875,
      "grad_norm": 1.8058122396469116,
      "learning_rate": 2.5421180004834015e-05,
      "loss": 2.305426025390625,
      "memory(GiB)": 22.05,
      "step": 4950,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.191641
    },
    {
      "epoch": 0.619375,
      "grad_norm": 2.6728579998016357,
      "learning_rate": 2.534807070483685e-05,
      "loss": 1.8765068054199219,
      "memory(GiB)": 22.05,
      "step": 4955,
      "token_acc": 0.5921052631578947,
      "train_speed(iter/s)": 0.19172
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.912582516670227,
      "learning_rate": 2.5275017892612885e-05,
      "loss": 1.8034311294555665,
      "memory(GiB)": 22.05,
      "step": 4960,
      "token_acc": 0.5317460317460317,
      "train_speed(iter/s)": 0.191797
    },
    {
      "epoch": 0.620625,
      "grad_norm": 1.3044708967208862,
      "learning_rate": 2.5202021849803576e-05,
      "loss": 2.3315940856933595,
      "memory(GiB)": 22.05,
      "step": 4965,
      "token_acc": 0.463768115942029,
      "train_speed(iter/s)": 0.191872
    },
    {
      "epoch": 0.62125,
      "grad_norm": 1.2439281940460205,
      "learning_rate": 2.5129082857831523e-05,
      "loss": 1.9593940734863282,
      "memory(GiB)": 22.05,
      "step": 4970,
      "token_acc": 0.549618320610687,
      "train_speed(iter/s)": 0.191948
    },
    {
      "epoch": 0.621875,
      "grad_norm": 1.4819221496582031,
      "learning_rate": 2.505620119789935e-05,
      "loss": 2.1908876419067385,
      "memory(GiB)": 22.05,
      "step": 4975,
      "token_acc": 0.5174825174825175,
      "train_speed(iter/s)": 0.192027
    },
    {
      "epoch": 0.6225,
      "grad_norm": 1.7999210357666016,
      "learning_rate": 2.4983377150988674e-05,
      "loss": 2.2139596939086914,
      "memory(GiB)": 22.05,
      "step": 4980,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.192103
    },
    {
      "epoch": 0.623125,
      "grad_norm": 1.4316176176071167,
      "learning_rate": 2.4910610997859e-05,
      "loss": 1.5207680702209472,
      "memory(GiB)": 22.05,
      "step": 4985,
      "token_acc": 0.6260162601626016,
      "train_speed(iter/s)": 0.192182
    },
    {
      "epoch": 0.62375,
      "grad_norm": 1.6896355152130127,
      "learning_rate": 2.4837903019046623e-05,
      "loss": 2.1822284698486327,
      "memory(GiB)": 22.05,
      "step": 4990,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.192265
    },
    {
      "epoch": 0.624375,
      "grad_norm": 1.7636154890060425,
      "learning_rate": 2.4765253494863536e-05,
      "loss": 1.6369134902954101,
      "memory(GiB)": 22.05,
      "step": 4995,
      "token_acc": 0.6126760563380281,
      "train_speed(iter/s)": 0.192339
    },
    {
      "epoch": 0.625,
      "grad_norm": 3.440204381942749,
      "learning_rate": 2.4692662705396412e-05,
      "loss": 2.2554500579833983,
      "memory(GiB)": 22.05,
      "step": 5000,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.19241
    },
    {
      "epoch": 0.625625,
      "grad_norm": 4.350735664367676,
      "learning_rate": 2.462013093050546e-05,
      "loss": 2.5195098876953126,
      "memory(GiB)": 22.05,
      "step": 5005,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.192495
    },
    {
      "epoch": 0.62625,
      "grad_norm": 1.1253869533538818,
      "learning_rate": 2.454765844982337e-05,
      "loss": 1.7717218399047852,
      "memory(GiB)": 22.05,
      "step": 5010,
      "token_acc": 0.6101694915254238,
      "train_speed(iter/s)": 0.192579
    },
    {
      "epoch": 0.626875,
      "grad_norm": 2.5842103958129883,
      "learning_rate": 2.4475245542754236e-05,
      "loss": 2.192234230041504,
      "memory(GiB)": 22.05,
      "step": 5015,
      "token_acc": 0.5634920634920635,
      "train_speed(iter/s)": 0.192664
    },
    {
      "epoch": 0.6275,
      "grad_norm": 1.564245581626892,
      "learning_rate": 2.4402892488472484e-05,
      "loss": 1.642405891418457,
      "memory(GiB)": 22.05,
      "step": 5020,
      "token_acc": 0.6377952755905512,
      "train_speed(iter/s)": 0.192752
    },
    {
      "epoch": 0.628125,
      "grad_norm": 3.2839195728302,
      "learning_rate": 2.4330599565921765e-05,
      "loss": 2.587068557739258,
      "memory(GiB)": 22.05,
      "step": 5025,
      "token_acc": 0.4755244755244755,
      "train_speed(iter/s)": 0.19284
    },
    {
      "epoch": 0.62875,
      "grad_norm": 1.6279348134994507,
      "learning_rate": 2.4258367053813942e-05,
      "loss": 2.005470848083496,
      "memory(GiB)": 22.05,
      "step": 5030,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.192926
    },
    {
      "epoch": 0.629375,
      "grad_norm": 1.5376346111297607,
      "learning_rate": 2.4186195230627964e-05,
      "loss": 1.3403411865234376,
      "memory(GiB)": 22.05,
      "step": 5035,
      "token_acc": 0.6341463414634146,
      "train_speed(iter/s)": 0.193014
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7528616189956665,
      "learning_rate": 2.411408437460878e-05,
      "loss": 2.0069169998168945,
      "memory(GiB)": 22.05,
      "step": 5040,
      "token_acc": 0.5725190839694656,
      "train_speed(iter/s)": 0.193102
    },
    {
      "epoch": 0.630625,
      "grad_norm": 5.652793884277344,
      "learning_rate": 2.4042034763766316e-05,
      "loss": 2.3254899978637695,
      "memory(GiB)": 22.05,
      "step": 5045,
      "token_acc": 0.5128205128205128,
      "train_speed(iter/s)": 0.193191
    },
    {
      "epoch": 0.63125,
      "grad_norm": 1.086720585823059,
      "learning_rate": 2.397004667587437e-05,
      "loss": 1.7458414077758788,
      "memory(GiB)": 22.05,
      "step": 5050,
      "token_acc": 0.5673758865248227,
      "train_speed(iter/s)": 0.193278
    },
    {
      "epoch": 0.631875,
      "grad_norm": 4.610947608947754,
      "learning_rate": 2.389812038846955e-05,
      "loss": 2.1690311431884766,
      "memory(GiB)": 22.05,
      "step": 5055,
      "token_acc": 0.5401459854014599,
      "train_speed(iter/s)": 0.193367
    },
    {
      "epoch": 0.6325,
      "grad_norm": 4.379487037658691,
      "learning_rate": 2.3826256178850206e-05,
      "loss": 1.7628448486328125,
      "memory(GiB)": 22.05,
      "step": 5060,
      "token_acc": 0.6046511627906976,
      "train_speed(iter/s)": 0.193454
    },
    {
      "epoch": 0.633125,
      "grad_norm": 1.8196852207183838,
      "learning_rate": 2.3754454324075353e-05,
      "loss": 2.2696218490600586,
      "memory(GiB)": 22.05,
      "step": 5065,
      "token_acc": 0.4962962962962963,
      "train_speed(iter/s)": 0.19354
    },
    {
      "epoch": 0.63375,
      "grad_norm": 2.328690528869629,
      "learning_rate": 2.3682715100963634e-05,
      "loss": 2.230829620361328,
      "memory(GiB)": 22.05,
      "step": 5070,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.193626
    },
    {
      "epoch": 0.634375,
      "grad_norm": 4.752225875854492,
      "learning_rate": 2.3611038786092185e-05,
      "loss": 2.0086803436279297,
      "memory(GiB)": 22.05,
      "step": 5075,
      "token_acc": 0.5811965811965812,
      "train_speed(iter/s)": 0.193703
    },
    {
      "epoch": 0.635,
      "grad_norm": 4.4766364097595215,
      "learning_rate": 2.353942565579565e-05,
      "loss": 2.5605344772338867,
      "memory(GiB)": 22.05,
      "step": 5080,
      "token_acc": 0.5096774193548387,
      "train_speed(iter/s)": 0.193789
    },
    {
      "epoch": 0.635625,
      "grad_norm": 1.671715259552002,
      "learning_rate": 2.3467875986165056e-05,
      "loss": 2.5266857147216797,
      "memory(GiB)": 22.05,
      "step": 5085,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.193873
    },
    {
      "epoch": 0.63625,
      "grad_norm": 3.573561906814575,
      "learning_rate": 2.3396390053046757e-05,
      "loss": 2.3108985900878904,
      "memory(GiB)": 22.05,
      "step": 5090,
      "token_acc": 0.44360902255639095,
      "train_speed(iter/s)": 0.193959
    },
    {
      "epoch": 0.636875,
      "grad_norm": 1.506113886833191,
      "learning_rate": 2.3324968132041405e-05,
      "loss": 2.1985685348510744,
      "memory(GiB)": 22.05,
      "step": 5095,
      "token_acc": 0.5190839694656488,
      "train_speed(iter/s)": 0.194041
    },
    {
      "epoch": 0.6375,
      "grad_norm": 1.9075177907943726,
      "learning_rate": 2.325361049850289e-05,
      "loss": 1.5945564270019532,
      "memory(GiB)": 22.05,
      "step": 5100,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.194128
    },
    {
      "epoch": 0.638125,
      "grad_norm": 6.272060394287109,
      "learning_rate": 2.318231742753716e-05,
      "loss": 2.3679121017456053,
      "memory(GiB)": 22.05,
      "step": 5105,
      "token_acc": 0.5039370078740157,
      "train_speed(iter/s)": 0.194216
    },
    {
      "epoch": 0.63875,
      "grad_norm": 1.537017822265625,
      "learning_rate": 2.3111089194001387e-05,
      "loss": 2.2155454635620115,
      "memory(GiB)": 22.05,
      "step": 5110,
      "token_acc": 0.504,
      "train_speed(iter/s)": 0.194304
    },
    {
      "epoch": 0.639375,
      "grad_norm": 1.4718014001846313,
      "learning_rate": 2.303992607250266e-05,
      "loss": 2.4414968490600586,
      "memory(GiB)": 22.05,
      "step": 5115,
      "token_acc": 0.5390625,
      "train_speed(iter/s)": 0.194388
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3653101921081543,
      "learning_rate": 2.2968828337397095e-05,
      "loss": 2.285797882080078,
      "memory(GiB)": 22.05,
      "step": 5120,
      "token_acc": 0.5193798449612403,
      "train_speed(iter/s)": 0.194472
    },
    {
      "epoch": 0.640625,
      "grad_norm": 3.1347720623016357,
      "learning_rate": 2.2897796262788728e-05,
      "loss": 2.736235809326172,
      "memory(GiB)": 22.05,
      "step": 5125,
      "token_acc": 0.3660130718954248,
      "train_speed(iter/s)": 0.194555
    },
    {
      "epoch": 0.64125,
      "grad_norm": 4.073421955108643,
      "learning_rate": 2.282683012252841e-05,
      "loss": 3.1743757247924806,
      "memory(GiB)": 22.05,
      "step": 5130,
      "token_acc": 0.36764705882352944,
      "train_speed(iter/s)": 0.194637
    },
    {
      "epoch": 0.641875,
      "grad_norm": 1.8330624103546143,
      "learning_rate": 2.275593019021284e-05,
      "loss": 1.8462953567504883,
      "memory(GiB)": 22.05,
      "step": 5135,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.194721
    },
    {
      "epoch": 0.6425,
      "grad_norm": 1.579421043395996,
      "learning_rate": 2.268509673918346e-05,
      "loss": 1.800603485107422,
      "memory(GiB)": 22.05,
      "step": 5140,
      "token_acc": 0.512,
      "train_speed(iter/s)": 0.194809
    },
    {
      "epoch": 0.643125,
      "grad_norm": 1.5228554010391235,
      "learning_rate": 2.261433004252536e-05,
      "loss": 1.512078857421875,
      "memory(GiB)": 22.05,
      "step": 5145,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.194898
    },
    {
      "epoch": 0.64375,
      "grad_norm": 1.1589442491531372,
      "learning_rate": 2.254363037306631e-05,
      "loss": 1.8974925994873046,
      "memory(GiB)": 22.05,
      "step": 5150,
      "token_acc": 0.5725806451612904,
      "train_speed(iter/s)": 0.194985
    },
    {
      "epoch": 0.644375,
      "grad_norm": 3.9373958110809326,
      "learning_rate": 2.2472998003375705e-05,
      "loss": 2.194015884399414,
      "memory(GiB)": 22.05,
      "step": 5155,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.195075
    },
    {
      "epoch": 0.645,
      "grad_norm": 1.6263712644577026,
      "learning_rate": 2.2402433205763393e-05,
      "loss": 2.1750360488891602,
      "memory(GiB)": 22.05,
      "step": 5160,
      "token_acc": 0.5042016806722689,
      "train_speed(iter/s)": 0.195158
    },
    {
      "epoch": 0.645625,
      "grad_norm": 1.3014689683914185,
      "learning_rate": 2.2331936252278772e-05,
      "loss": 1.6073831558227538,
      "memory(GiB)": 22.05,
      "step": 5165,
      "token_acc": 0.5985915492957746,
      "train_speed(iter/s)": 0.195247
    },
    {
      "epoch": 0.64625,
      "grad_norm": 1.7238430976867676,
      "learning_rate": 2.226150741470967e-05,
      "loss": 1.721792221069336,
      "memory(GiB)": 22.05,
      "step": 5170,
      "token_acc": 0.5793650793650794,
      "train_speed(iter/s)": 0.195338
    },
    {
      "epoch": 0.646875,
      "grad_norm": 1.610864281654358,
      "learning_rate": 2.219114696458128e-05,
      "loss": 2.0106801986694336,
      "memory(GiB)": 22.05,
      "step": 5175,
      "token_acc": 0.5478260869565217,
      "train_speed(iter/s)": 0.195425
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.440152645111084,
      "learning_rate": 2.212085517315516e-05,
      "loss": 2.1312427520751953,
      "memory(GiB)": 22.05,
      "step": 5180,
      "token_acc": 0.5234375,
      "train_speed(iter/s)": 0.19551
    },
    {
      "epoch": 0.648125,
      "grad_norm": 1.2162158489227295,
      "learning_rate": 2.205063231142819e-05,
      "loss": 2.0354000091552735,
      "memory(GiB)": 22.05,
      "step": 5185,
      "token_acc": 0.6062992125984252,
      "train_speed(iter/s)": 0.195593
    },
    {
      "epoch": 0.64875,
      "grad_norm": 1.819762945175171,
      "learning_rate": 2.198047865013143e-05,
      "loss": 1.7717378616333008,
      "memory(GiB)": 22.05,
      "step": 5190,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.195675
    },
    {
      "epoch": 0.649375,
      "grad_norm": 1.4572125673294067,
      "learning_rate": 2.1910394459729263e-05,
      "loss": 1.5021587371826173,
      "memory(GiB)": 22.05,
      "step": 5195,
      "token_acc": 0.628099173553719,
      "train_speed(iter/s)": 0.195758
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6546612977981567,
      "learning_rate": 2.1840380010418133e-05,
      "loss": 2.104200744628906,
      "memory(GiB)": 22.05,
      "step": 5200,
      "token_acc": 0.5793103448275863,
      "train_speed(iter/s)": 0.195842
    },
    {
      "epoch": 0.650625,
      "grad_norm": 1.9270577430725098,
      "learning_rate": 2.1770435572125673e-05,
      "loss": 1.8249431610107423,
      "memory(GiB)": 22.05,
      "step": 5205,
      "token_acc": 0.6148148148148148,
      "train_speed(iter/s)": 0.195927
    },
    {
      "epoch": 0.65125,
      "grad_norm": 4.02349853515625,
      "learning_rate": 2.170056141450958e-05,
      "loss": 2.5376930236816406,
      "memory(GiB)": 22.05,
      "step": 5210,
      "token_acc": 0.4496124031007752,
      "train_speed(iter/s)": 0.196013
    },
    {
      "epoch": 0.651875,
      "grad_norm": 0.8401995301246643,
      "learning_rate": 2.1630757806956622e-05,
      "loss": 1.8561120986938477,
      "memory(GiB)": 22.05,
      "step": 5215,
      "token_acc": 0.5923076923076923,
      "train_speed(iter/s)": 0.196094
    },
    {
      "epoch": 0.6525,
      "grad_norm": 4.5359039306640625,
      "learning_rate": 2.1561025018581515e-05,
      "loss": 1.9922466278076172,
      "memory(GiB)": 22.05,
      "step": 5220,
      "token_acc": 0.5042735042735043,
      "train_speed(iter/s)": 0.196178
    },
    {
      "epoch": 0.653125,
      "grad_norm": 1.3033411502838135,
      "learning_rate": 2.1491363318226e-05,
      "loss": 1.8459117889404297,
      "memory(GiB)": 22.05,
      "step": 5225,
      "token_acc": 0.5563380281690141,
      "train_speed(iter/s)": 0.196258
    },
    {
      "epoch": 0.65375,
      "grad_norm": 1.5203301906585693,
      "learning_rate": 2.1421772974457737e-05,
      "loss": 1.9795551300048828,
      "memory(GiB)": 22.05,
      "step": 5230,
      "token_acc": 0.4928571428571429,
      "train_speed(iter/s)": 0.196344
    },
    {
      "epoch": 0.654375,
      "grad_norm": 2.6640331745147705,
      "learning_rate": 2.1352254255569288e-05,
      "loss": 2.0393278121948244,
      "memory(GiB)": 22.05,
      "step": 5235,
      "token_acc": 0.488,
      "train_speed(iter/s)": 0.196426
    },
    {
      "epoch": 0.655,
      "grad_norm": 1.722782015800476,
      "learning_rate": 2.1282807429577074e-05,
      "loss": 2.3245828628540037,
      "memory(GiB)": 22.05,
      "step": 5240,
      "token_acc": 0.48872180451127817,
      "train_speed(iter/s)": 0.196507
    },
    {
      "epoch": 0.655625,
      "grad_norm": 3.9303109645843506,
      "learning_rate": 2.121343276422032e-05,
      "loss": 1.906226921081543,
      "memory(GiB)": 22.05,
      "step": 5245,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.196592
    },
    {
      "epoch": 0.65625,
      "grad_norm": 2.9597396850585938,
      "learning_rate": 2.1144130526960093e-05,
      "loss": 2.192997360229492,
      "memory(GiB)": 22.05,
      "step": 5250,
      "token_acc": 0.5639097744360902,
      "train_speed(iter/s)": 0.196676
    },
    {
      "epoch": 0.656875,
      "grad_norm": 2.9416682720184326,
      "learning_rate": 2.107490098497822e-05,
      "loss": 2.1404815673828126,
      "memory(GiB)": 22.05,
      "step": 5255,
      "token_acc": 0.5736434108527132,
      "train_speed(iter/s)": 0.196758
    },
    {
      "epoch": 0.6575,
      "grad_norm": 2.443376302719116,
      "learning_rate": 2.1005744405176226e-05,
      "loss": 1.7824886322021485,
      "memory(GiB)": 22.05,
      "step": 5260,
      "token_acc": 0.5630252100840336,
      "train_speed(iter/s)": 0.196842
    },
    {
      "epoch": 0.658125,
      "grad_norm": 1.5537890195846558,
      "learning_rate": 2.093666105417438e-05,
      "loss": 2.2507448196411133,
      "memory(GiB)": 22.05,
      "step": 5265,
      "token_acc": 0.5075757575757576,
      "train_speed(iter/s)": 0.196929
    },
    {
      "epoch": 0.65875,
      "grad_norm": 1.1487101316452026,
      "learning_rate": 2.086765119831064e-05,
      "loss": 1.3207083702087403,
      "memory(GiB)": 22.05,
      "step": 5270,
      "token_acc": 0.6386554621848739,
      "train_speed(iter/s)": 0.197013
    },
    {
      "epoch": 0.659375,
      "grad_norm": 1.4399656057357788,
      "learning_rate": 2.0798715103639555e-05,
      "loss": 1.4338695526123046,
      "memory(GiB)": 22.05,
      "step": 5275,
      "token_acc": 0.6774193548387096,
      "train_speed(iter/s)": 0.197097
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1117459535598755,
      "learning_rate": 2.0729853035931386e-05,
      "loss": 1.8327220916748046,
      "memory(GiB)": 22.05,
      "step": 5280,
      "token_acc": 0.5798319327731093,
      "train_speed(iter/s)": 0.197182
    },
    {
      "epoch": 0.660625,
      "grad_norm": 1.6316473484039307,
      "learning_rate": 2.0661065260670963e-05,
      "loss": 2.317948913574219,
      "memory(GiB)": 22.05,
      "step": 5285,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.197266
    },
    {
      "epoch": 0.66125,
      "grad_norm": 1.0866568088531494,
      "learning_rate": 2.059235204305665e-05,
      "loss": 1.9422548294067383,
      "memory(GiB)": 22.05,
      "step": 5290,
      "token_acc": 0.5528455284552846,
      "train_speed(iter/s)": 0.197345
    },
    {
      "epoch": 0.661875,
      "grad_norm": 1.1189398765563965,
      "learning_rate": 2.0523713647999433e-05,
      "loss": 1.8019094467163086,
      "memory(GiB)": 22.05,
      "step": 5295,
      "token_acc": 0.5746268656716418,
      "train_speed(iter/s)": 0.197441
    },
    {
      "epoch": 0.6625,
      "grad_norm": 2.2866270542144775,
      "learning_rate": 2.0455150340121818e-05,
      "loss": 2.1118711471557616,
      "memory(GiB)": 22.05,
      "step": 5300,
      "token_acc": 0.5118110236220472,
      "train_speed(iter/s)": 0.197535
    },
    {
      "epoch": 0.663125,
      "grad_norm": 1.097043752670288,
      "learning_rate": 2.0386662383756776e-05,
      "loss": 3.063735580444336,
      "memory(GiB)": 22.05,
      "step": 5305,
      "token_acc": 0.5147058823529411,
      "train_speed(iter/s)": 0.197631
    },
    {
      "epoch": 0.66375,
      "grad_norm": 1.742618441581726,
      "learning_rate": 2.0318250042946842e-05,
      "loss": 2.052766036987305,
      "memory(GiB)": 22.05,
      "step": 5310,
      "token_acc": 0.5401459854014599,
      "train_speed(iter/s)": 0.197727
    },
    {
      "epoch": 0.664375,
      "grad_norm": 1.1276395320892334,
      "learning_rate": 2.0249913581443e-05,
      "loss": 1.4527484893798828,
      "memory(GiB)": 22.05,
      "step": 5315,
      "token_acc": 0.6287878787878788,
      "train_speed(iter/s)": 0.19782
    },
    {
      "epoch": 0.665,
      "grad_norm": 1.5223623514175415,
      "learning_rate": 2.01816532627037e-05,
      "loss": 1.8905988693237306,
      "memory(GiB)": 22.05,
      "step": 5320,
      "token_acc": 0.5966386554621849,
      "train_speed(iter/s)": 0.197916
    },
    {
      "epoch": 0.665625,
      "grad_norm": 2.14182186126709,
      "learning_rate": 2.0113469349893818e-05,
      "loss": 2.237017059326172,
      "memory(GiB)": 22.05,
      "step": 5325,
      "token_acc": 0.5210084033613446,
      "train_speed(iter/s)": 0.19801
    },
    {
      "epoch": 0.66625,
      "grad_norm": 1.200850248336792,
      "learning_rate": 2.004536210588371e-05,
      "loss": 1.611367416381836,
      "memory(GiB)": 22.05,
      "step": 5330,
      "token_acc": 0.5853658536585366,
      "train_speed(iter/s)": 0.198104
    },
    {
      "epoch": 0.666875,
      "grad_norm": 1.4034370183944702,
      "learning_rate": 1.9977331793248084e-05,
      "loss": 1.4672616958618163,
      "memory(GiB)": 22.05,
      "step": 5335,
      "token_acc": 0.616,
      "train_speed(iter/s)": 0.198191
    },
    {
      "epoch": 0.6675,
      "grad_norm": 1.2202478647232056,
      "learning_rate": 1.99093786742651e-05,
      "loss": 2.271006774902344,
      "memory(GiB)": 22.05,
      "step": 5340,
      "token_acc": 0.4461538461538462,
      "train_speed(iter/s)": 0.19827
    },
    {
      "epoch": 0.668125,
      "grad_norm": 4.130249500274658,
      "learning_rate": 1.9841503010915315e-05,
      "loss": 2.2332347869873046,
      "memory(GiB)": 22.05,
      "step": 5345,
      "token_acc": 0.48854961832061067,
      "train_speed(iter/s)": 0.198356
    },
    {
      "epoch": 0.66875,
      "grad_norm": 3.0765459537506104,
      "learning_rate": 1.9773705064880624e-05,
      "loss": 1.9384330749511718,
      "memory(GiB)": 22.05,
      "step": 5350,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.198439
    },
    {
      "epoch": 0.669375,
      "grad_norm": 1.2065341472625732,
      "learning_rate": 1.9705985097543348e-05,
      "loss": 1.6356290817260741,
      "memory(GiB)": 22.05,
      "step": 5355,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.19852
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.490739107131958,
      "learning_rate": 1.963834336998515e-05,
      "loss": 2.1931718826293944,
      "memory(GiB)": 22.05,
      "step": 5360,
      "token_acc": 0.5378787878787878,
      "train_speed(iter/s)": 0.198604
    },
    {
      "epoch": 0.670625,
      "grad_norm": 1.307372808456421,
      "learning_rate": 1.9570780142986064e-05,
      "loss": 2.052845764160156,
      "memory(GiB)": 22.05,
      "step": 5365,
      "token_acc": 0.5338345864661654,
      "train_speed(iter/s)": 0.198684
    },
    {
      "epoch": 0.67125,
      "grad_norm": 2.2415127754211426,
      "learning_rate": 1.9503295677023494e-05,
      "loss": 2.001054382324219,
      "memory(GiB)": 22.05,
      "step": 5370,
      "token_acc": 0.5616438356164384,
      "train_speed(iter/s)": 0.198766
    },
    {
      "epoch": 0.671875,
      "grad_norm": 5.181946277618408,
      "learning_rate": 1.9435890232271136e-05,
      "loss": 2.230368804931641,
      "memory(GiB)": 22.05,
      "step": 5375,
      "token_acc": 0.5259259259259259,
      "train_speed(iter/s)": 0.198847
    },
    {
      "epoch": 0.6725,
      "grad_norm": 1.85470449924469,
      "learning_rate": 1.9368564068598106e-05,
      "loss": 1.4795488357543944,
      "memory(GiB)": 22.05,
      "step": 5380,
      "token_acc": 0.6544117647058824,
      "train_speed(iter/s)": 0.198928
    },
    {
      "epoch": 0.673125,
      "grad_norm": 1.628752589225769,
      "learning_rate": 1.9301317445567842e-05,
      "loss": 2.1168119430541994,
      "memory(GiB)": 22.05,
      "step": 5385,
      "token_acc": 0.5950413223140496,
      "train_speed(iter/s)": 0.19901
    },
    {
      "epoch": 0.67375,
      "grad_norm": 1.2916282415390015,
      "learning_rate": 1.92341506224371e-05,
      "loss": 1.7275928497314452,
      "memory(GiB)": 22.05,
      "step": 5390,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.199089
    },
    {
      "epoch": 0.674375,
      "grad_norm": 2.934847593307495,
      "learning_rate": 1.9167063858155005e-05,
      "loss": 2.903516387939453,
      "memory(GiB)": 22.05,
      "step": 5395,
      "token_acc": 0.4067796610169492,
      "train_speed(iter/s)": 0.199169
    },
    {
      "epoch": 0.675,
      "grad_norm": 2.228316307067871,
      "learning_rate": 1.9100057411362048e-05,
      "loss": 2.0569995880126952,
      "memory(GiB)": 22.05,
      "step": 5400,
      "token_acc": 0.5488721804511278,
      "train_speed(iter/s)": 0.199244
    },
    {
      "epoch": 0.675625,
      "grad_norm": 1.7744959592819214,
      "learning_rate": 1.9033131540389047e-05,
      "loss": 1.5014753341674805,
      "memory(GiB)": 22.05,
      "step": 5405,
      "token_acc": 0.6694214876033058,
      "train_speed(iter/s)": 0.199326
    },
    {
      "epoch": 0.67625,
      "grad_norm": 1.527185082435608,
      "learning_rate": 1.8966286503256176e-05,
      "loss": 1.7163427352905274,
      "memory(GiB)": 22.05,
      "step": 5410,
      "token_acc": 0.6014492753623188,
      "train_speed(iter/s)": 0.199409
    },
    {
      "epoch": 0.676875,
      "grad_norm": 1.4123142957687378,
      "learning_rate": 1.8899522557671996e-05,
      "loss": 1.1700825691223145,
      "memory(GiB)": 22.05,
      "step": 5415,
      "token_acc": 0.652542372881356,
      "train_speed(iter/s)": 0.199494
    },
    {
      "epoch": 0.6775,
      "grad_norm": 1.7489513158798218,
      "learning_rate": 1.8832839961032385e-05,
      "loss": 2.522290802001953,
      "memory(GiB)": 22.05,
      "step": 5420,
      "token_acc": 0.4621212121212121,
      "train_speed(iter/s)": 0.199574
    },
    {
      "epoch": 0.678125,
      "grad_norm": 3.267880439758301,
      "learning_rate": 1.8766238970419624e-05,
      "loss": 2.280315399169922,
      "memory(GiB)": 22.05,
      "step": 5425,
      "token_acc": 0.4689655172413793,
      "train_speed(iter/s)": 0.19965
    },
    {
      "epoch": 0.67875,
      "grad_norm": 1.380112648010254,
      "learning_rate": 1.8699719842601408e-05,
      "loss": 2.0183279037475588,
      "memory(GiB)": 22.05,
      "step": 5430,
      "token_acc": 0.6106870229007634,
      "train_speed(iter/s)": 0.199732
    },
    {
      "epoch": 0.679375,
      "grad_norm": 1.757131814956665,
      "learning_rate": 1.8633282834029756e-05,
      "loss": 1.9360641479492187,
      "memory(GiB)": 22.05,
      "step": 5435,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.199811
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1951593160629272,
      "learning_rate": 1.8566928200840128e-05,
      "loss": 2.2599872589111327,
      "memory(GiB)": 22.05,
      "step": 5440,
      "token_acc": 0.4647887323943662,
      "train_speed(iter/s)": 0.199886
    },
    {
      "epoch": 0.680625,
      "grad_norm": 5.603946208953857,
      "learning_rate": 1.850065619885045e-05,
      "loss": 1.9804492950439454,
      "memory(GiB)": 22.05,
      "step": 5445,
      "token_acc": 0.6422764227642277,
      "train_speed(iter/s)": 0.199968
    },
    {
      "epoch": 0.68125,
      "grad_norm": 1.796549677848816,
      "learning_rate": 1.843446708355999e-05,
      "loss": 2.552280044555664,
      "memory(GiB)": 22.05,
      "step": 5450,
      "token_acc": 0.4274193548387097,
      "train_speed(iter/s)": 0.200043
    },
    {
      "epoch": 0.681875,
      "grad_norm": 1.6811681985855103,
      "learning_rate": 1.8368361110148515e-05,
      "loss": 2.5489635467529297,
      "memory(GiB)": 22.05,
      "step": 5455,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.200123
    },
    {
      "epoch": 0.6825,
      "grad_norm": 3.528012752532959,
      "learning_rate": 1.830233853347526e-05,
      "loss": 2.382342529296875,
      "memory(GiB)": 22.05,
      "step": 5460,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.200202
    },
    {
      "epoch": 0.683125,
      "grad_norm": 3.5476062297821045,
      "learning_rate": 1.8236399608077886e-05,
      "loss": 1.8785659790039062,
      "memory(GiB)": 22.05,
      "step": 5465,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.20028
    },
    {
      "epoch": 0.68375,
      "grad_norm": 1.3497649431228638,
      "learning_rate": 1.8170544588171607e-05,
      "loss": 1.9947402954101563,
      "memory(GiB)": 22.05,
      "step": 5470,
      "token_acc": 0.4881889763779528,
      "train_speed(iter/s)": 0.200377
    },
    {
      "epoch": 0.684375,
      "grad_norm": 4.545778751373291,
      "learning_rate": 1.8104773727648152e-05,
      "loss": 2.2643198013305663,
      "memory(GiB)": 22.05,
      "step": 5475,
      "token_acc": 0.556390977443609,
      "train_speed(iter/s)": 0.200457
    },
    {
      "epoch": 0.685,
      "grad_norm": 3.9657177925109863,
      "learning_rate": 1.8039087280074726e-05,
      "loss": 1.8294242858886718,
      "memory(GiB)": 22.05,
      "step": 5480,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.200538
    },
    {
      "epoch": 0.685625,
      "grad_norm": 1.4123817682266235,
      "learning_rate": 1.7973485498693205e-05,
      "loss": 2.0554718017578124,
      "memory(GiB)": 22.05,
      "step": 5485,
      "token_acc": 0.5639097744360902,
      "train_speed(iter/s)": 0.200618
    },
    {
      "epoch": 0.68625,
      "grad_norm": 2.1575396060943604,
      "learning_rate": 1.790796863641894e-05,
      "loss": 1.3975269317626953,
      "memory(GiB)": 22.05,
      "step": 5490,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.200697
    },
    {
      "epoch": 0.686875,
      "grad_norm": 5.0818610191345215,
      "learning_rate": 1.784253694583996e-05,
      "loss": 3.128497505187988,
      "memory(GiB)": 22.05,
      "step": 5495,
      "token_acc": 0.4251968503937008,
      "train_speed(iter/s)": 0.200775
    },
    {
      "epoch": 0.6875,
      "grad_norm": 4.411250114440918,
      "learning_rate": 1.7777190679215923e-05,
      "loss": 2.600341033935547,
      "memory(GiB)": 22.05,
      "step": 5500,
      "token_acc": 0.3897058823529412,
      "train_speed(iter/s)": 0.200851
    },
    {
      "epoch": 0.688125,
      "grad_norm": 4.830103397369385,
      "learning_rate": 1.771193008847711e-05,
      "loss": 2.9207324981689453,
      "memory(GiB)": 22.05,
      "step": 5505,
      "token_acc": 0.41843971631205673,
      "train_speed(iter/s)": 0.200926
    },
    {
      "epoch": 0.68875,
      "grad_norm": 3.3509674072265625,
      "learning_rate": 1.764675542522354e-05,
      "loss": 2.116287612915039,
      "memory(GiB)": 22.05,
      "step": 5510,
      "token_acc": 0.5492957746478874,
      "train_speed(iter/s)": 0.201005
    },
    {
      "epoch": 0.689375,
      "grad_norm": 4.0353779792785645,
      "learning_rate": 1.758166694072393e-05,
      "loss": 2.085260581970215,
      "memory(GiB)": 22.05,
      "step": 5515,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.201083
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3948686122894287,
      "learning_rate": 1.7516664885914788e-05,
      "loss": 1.4136690139770507,
      "memory(GiB)": 22.05,
      "step": 5520,
      "token_acc": 0.6461538461538462,
      "train_speed(iter/s)": 0.20116
    },
    {
      "epoch": 0.690625,
      "grad_norm": 1.2960959672927856,
      "learning_rate": 1.745174951139933e-05,
      "loss": 1.8673233032226562,
      "memory(GiB)": 22.05,
      "step": 5525,
      "token_acc": 0.616,
      "train_speed(iter/s)": 0.201238
    },
    {
      "epoch": 0.69125,
      "grad_norm": 1.5376447439193726,
      "learning_rate": 1.738692106744669e-05,
      "loss": 2.276660919189453,
      "memory(GiB)": 22.05,
      "step": 5530,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.201319
    },
    {
      "epoch": 0.691875,
      "grad_norm": 1.6496416330337524,
      "learning_rate": 1.732217980399078e-05,
      "loss": 1.3345353126525878,
      "memory(GiB)": 22.05,
      "step": 5535,
      "token_acc": 0.6495726495726496,
      "train_speed(iter/s)": 0.2014
    },
    {
      "epoch": 0.6925,
      "grad_norm": 1.877198338508606,
      "learning_rate": 1.725752597062944e-05,
      "loss": 2.0244094848632814,
      "memory(GiB)": 22.05,
      "step": 5540,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.201478
    },
    {
      "epoch": 0.693125,
      "grad_norm": 1.7567708492279053,
      "learning_rate": 1.7192959816623452e-05,
      "loss": 1.3470577239990233,
      "memory(GiB)": 22.05,
      "step": 5545,
      "token_acc": 0.672,
      "train_speed(iter/s)": 0.201559
    },
    {
      "epoch": 0.69375,
      "grad_norm": 1.7559374570846558,
      "learning_rate": 1.7128481590895515e-05,
      "loss": 1.607315444946289,
      "memory(GiB)": 22.05,
      "step": 5550,
      "token_acc": 0.6129032258064516,
      "train_speed(iter/s)": 0.20164
    },
    {
      "epoch": 0.694375,
      "grad_norm": 1.7372955083847046,
      "learning_rate": 1.7064091542029387e-05,
      "loss": 1.5323661804199218,
      "memory(GiB)": 22.05,
      "step": 5555,
      "token_acc": 0.5954198473282443,
      "train_speed(iter/s)": 0.201715
    },
    {
      "epoch": 0.695,
      "grad_norm": 1.3438010215759277,
      "learning_rate": 1.699978991826887e-05,
      "loss": 1.9509944915771484,
      "memory(GiB)": 22.05,
      "step": 5560,
      "token_acc": 0.5488721804511278,
      "train_speed(iter/s)": 0.20179
    },
    {
      "epoch": 0.695625,
      "grad_norm": 1.5001565217971802,
      "learning_rate": 1.6935576967516813e-05,
      "loss": 2.3597021102905273,
      "memory(GiB)": 22.05,
      "step": 5565,
      "token_acc": 0.5433070866141733,
      "train_speed(iter/s)": 0.201869
    },
    {
      "epoch": 0.69625,
      "grad_norm": 2.750336170196533,
      "learning_rate": 1.687145293733427e-05,
      "loss": 1.9423830032348632,
      "memory(GiB)": 22.05,
      "step": 5570,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.20195
    },
    {
      "epoch": 0.696875,
      "grad_norm": 3.9897260665893555,
      "learning_rate": 1.6807418074939458e-05,
      "loss": 2.0284910202026367,
      "memory(GiB)": 22.05,
      "step": 5575,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.202027
    },
    {
      "epoch": 0.6975,
      "grad_norm": 1.2730591297149658,
      "learning_rate": 1.674347262720678e-05,
      "loss": 2.3004098892211915,
      "memory(GiB)": 22.05,
      "step": 5580,
      "token_acc": 0.5153846153846153,
      "train_speed(iter/s)": 0.202104
    },
    {
      "epoch": 0.698125,
      "grad_norm": 1.4302102327346802,
      "learning_rate": 1.6679616840665966e-05,
      "loss": 1.5871657371520995,
      "memory(GiB)": 22.05,
      "step": 5585,
      "token_acc": 0.6412213740458015,
      "train_speed(iter/s)": 0.202183
    },
    {
      "epoch": 0.69875,
      "grad_norm": 1.4048292636871338,
      "learning_rate": 1.661585096150107e-05,
      "loss": 2.4708393096923826,
      "memory(GiB)": 22.05,
      "step": 5590,
      "token_acc": 0.49624060150375937,
      "train_speed(iter/s)": 0.202256
    },
    {
      "epoch": 0.699375,
      "grad_norm": 4.681246280670166,
      "learning_rate": 1.6552175235549484e-05,
      "loss": 1.6311641693115235,
      "memory(GiB)": 22.05,
      "step": 5595,
      "token_acc": 0.6461538461538462,
      "train_speed(iter/s)": 0.202335
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5195261240005493,
      "learning_rate": 1.648858990830108e-05,
      "loss": 1.958013916015625,
      "memory(GiB)": 22.05,
      "step": 5600,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.202413
    },
    {
      "epoch": 0.700625,
      "grad_norm": 1.2784968614578247,
      "learning_rate": 1.642509522489719e-05,
      "loss": 2.3861648559570314,
      "memory(GiB)": 22.05,
      "step": 5605,
      "token_acc": 0.4863013698630137,
      "train_speed(iter/s)": 0.202491
    },
    {
      "epoch": 0.70125,
      "grad_norm": 1.8259912729263306,
      "learning_rate": 1.6361691430129702e-05,
      "loss": 2.980569076538086,
      "memory(GiB)": 22.05,
      "step": 5610,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.202563
    },
    {
      "epoch": 0.701875,
      "grad_norm": 1.5588361024856567,
      "learning_rate": 1.629837876844008e-05,
      "loss": 2.16141357421875,
      "memory(GiB)": 22.05,
      "step": 5615,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.202641
    },
    {
      "epoch": 0.7025,
      "grad_norm": 2.8096213340759277,
      "learning_rate": 1.6235157483918463e-05,
      "loss": 1.509973907470703,
      "memory(GiB)": 22.05,
      "step": 5620,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.202717
    },
    {
      "epoch": 0.703125,
      "grad_norm": 3.1193974018096924,
      "learning_rate": 1.617202782030267e-05,
      "loss": 2.6069610595703123,
      "memory(GiB)": 22.05,
      "step": 5625,
      "token_acc": 0.4015748031496063,
      "train_speed(iter/s)": 0.202787
    },
    {
      "epoch": 0.70375,
      "grad_norm": 1.2679967880249023,
      "learning_rate": 1.6108990020977317e-05,
      "loss": 1.469367218017578,
      "memory(GiB)": 22.05,
      "step": 5630,
      "token_acc": 0.632,
      "train_speed(iter/s)": 0.202866
    },
    {
      "epoch": 0.704375,
      "grad_norm": 1.1051857471466064,
      "learning_rate": 1.604604432897287e-05,
      "loss": 2.066769027709961,
      "memory(GiB)": 22.05,
      "step": 5635,
      "token_acc": 0.5658914728682171,
      "train_speed(iter/s)": 0.202941
    },
    {
      "epoch": 0.705,
      "grad_norm": 3.5380561351776123,
      "learning_rate": 1.5983190986964646e-05,
      "loss": 1.6238239288330079,
      "memory(GiB)": 22.05,
      "step": 5640,
      "token_acc": 0.6330935251798561,
      "train_speed(iter/s)": 0.20302
    },
    {
      "epoch": 0.705625,
      "grad_norm": 2.3010807037353516,
      "learning_rate": 1.5920430237271956e-05,
      "loss": 2.4668258666992187,
      "memory(GiB)": 22.05,
      "step": 5645,
      "token_acc": 0.44715447154471544,
      "train_speed(iter/s)": 0.203097
    },
    {
      "epoch": 0.70625,
      "grad_norm": 1.3800610303878784,
      "learning_rate": 1.5857762321857143e-05,
      "loss": 1.9891740798950195,
      "memory(GiB)": 22.05,
      "step": 5650,
      "token_acc": 0.5578231292517006,
      "train_speed(iter/s)": 0.203174
    },
    {
      "epoch": 0.706875,
      "grad_norm": 1.308677077293396,
      "learning_rate": 1.579518748232463e-05,
      "loss": 1.8013996124267577,
      "memory(GiB)": 22.05,
      "step": 5655,
      "token_acc": 0.627906976744186,
      "train_speed(iter/s)": 0.203249
    },
    {
      "epoch": 0.7075,
      "grad_norm": 1.5478328466415405,
      "learning_rate": 1.573270595992002e-05,
      "loss": 2.5498619079589844,
      "memory(GiB)": 22.05,
      "step": 5660,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.203319
    },
    {
      "epoch": 0.708125,
      "grad_norm": 1.3203810453414917,
      "learning_rate": 1.5670317995529113e-05,
      "loss": 2.1912208557128907,
      "memory(GiB)": 22.05,
      "step": 5665,
      "token_acc": 0.47794117647058826,
      "train_speed(iter/s)": 0.203396
    },
    {
      "epoch": 0.70875,
      "grad_norm": 1.1480982303619385,
      "learning_rate": 1.560802382967705e-05,
      "loss": 2.4933399200439452,
      "memory(GiB)": 22.05,
      "step": 5670,
      "token_acc": 0.48091603053435117,
      "train_speed(iter/s)": 0.203471
    },
    {
      "epoch": 0.709375,
      "grad_norm": 1.784155011177063,
      "learning_rate": 1.554582370252735e-05,
      "loss": 2.1366920471191406,
      "memory(GiB)": 22.05,
      "step": 5675,
      "token_acc": 0.5190839694656488,
      "train_speed(iter/s)": 0.203549
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4882168769836426,
      "learning_rate": 1.548371785388095e-05,
      "loss": 1.7913820266723632,
      "memory(GiB)": 22.05,
      "step": 5680,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.20363
    },
    {
      "epoch": 0.710625,
      "grad_norm": 1.8744583129882812,
      "learning_rate": 1.542170652317534e-05,
      "loss": 1.260321807861328,
      "memory(GiB)": 22.05,
      "step": 5685,
      "token_acc": 0.6583333333333333,
      "train_speed(iter/s)": 0.203704
    },
    {
      "epoch": 0.71125,
      "grad_norm": 4.428460597991943,
      "learning_rate": 1.5359789949483613e-05,
      "loss": 2.2747098922729494,
      "memory(GiB)": 22.05,
      "step": 5690,
      "token_acc": 0.49606299212598426,
      "train_speed(iter/s)": 0.203781
    },
    {
      "epoch": 0.711875,
      "grad_norm": 1.38154137134552,
      "learning_rate": 1.5297968371513534e-05,
      "loss": 2.013472557067871,
      "memory(GiB)": 22.05,
      "step": 5695,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.203856
    },
    {
      "epoch": 0.7125,
      "grad_norm": 3.915585517883301,
      "learning_rate": 1.5236242027606638e-05,
      "loss": 2.37567253112793,
      "memory(GiB)": 22.05,
      "step": 5700,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.203933
    },
    {
      "epoch": 0.713125,
      "grad_norm": 4.3940110206604,
      "learning_rate": 1.5174611155737316e-05,
      "loss": 2.868480682373047,
      "memory(GiB)": 22.05,
      "step": 5705,
      "token_acc": 0.4676258992805755,
      "train_speed(iter/s)": 0.204009
    },
    {
      "epoch": 0.71375,
      "grad_norm": 1.352835774421692,
      "learning_rate": 1.5113075993511838e-05,
      "loss": 1.8510766983032227,
      "memory(GiB)": 22.05,
      "step": 5710,
      "token_acc": 0.5648854961832062,
      "train_speed(iter/s)": 0.204085
    },
    {
      "epoch": 0.714375,
      "grad_norm": 3.3943145275115967,
      "learning_rate": 1.5051636778167527e-05,
      "loss": 2.692440414428711,
      "memory(GiB)": 22.05,
      "step": 5715,
      "token_acc": 0.4393939393939394,
      "train_speed(iter/s)": 0.204156
    },
    {
      "epoch": 0.715,
      "grad_norm": 1.4400434494018555,
      "learning_rate": 1.4990293746571808e-05,
      "loss": 2.42694149017334,
      "memory(GiB)": 22.05,
      "step": 5720,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.204224
    },
    {
      "epoch": 0.715625,
      "grad_norm": 2.3691823482513428,
      "learning_rate": 1.4929047135221226e-05,
      "loss": 2.4554386138916016,
      "memory(GiB)": 22.05,
      "step": 5725,
      "token_acc": 0.5169491525423728,
      "train_speed(iter/s)": 0.204297
    },
    {
      "epoch": 0.71625,
      "grad_norm": 1.705531120300293,
      "learning_rate": 1.4867897180240651e-05,
      "loss": 2.250478744506836,
      "memory(GiB)": 22.05,
      "step": 5730,
      "token_acc": 0.5169491525423728,
      "train_speed(iter/s)": 0.20437
    },
    {
      "epoch": 0.716875,
      "grad_norm": 2.2353692054748535,
      "learning_rate": 1.4806844117382331e-05,
      "loss": 1.6444114685058593,
      "memory(GiB)": 22.05,
      "step": 5735,
      "token_acc": 0.5983606557377049,
      "train_speed(iter/s)": 0.204447
    },
    {
      "epoch": 0.7175,
      "grad_norm": 4.741176605224609,
      "learning_rate": 1.4745888182024893e-05,
      "loss": 2.659572982788086,
      "memory(GiB)": 22.05,
      "step": 5740,
      "token_acc": 0.44537815126050423,
      "train_speed(iter/s)": 0.204522
    },
    {
      "epoch": 0.718125,
      "grad_norm": 3.3432047367095947,
      "learning_rate": 1.4685029609172557e-05,
      "loss": 1.9349704742431642,
      "memory(GiB)": 22.05,
      "step": 5745,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.204597
    },
    {
      "epoch": 0.71875,
      "grad_norm": 1.627546787261963,
      "learning_rate": 1.4624268633454187e-05,
      "loss": 1.5774983406066894,
      "memory(GiB)": 22.05,
      "step": 5750,
      "token_acc": 0.5426356589147286,
      "train_speed(iter/s)": 0.204673
    },
    {
      "epoch": 0.719375,
      "grad_norm": 1.7565624713897705,
      "learning_rate": 1.4563605489122332e-05,
      "loss": 2.820928382873535,
      "memory(GiB)": 22.05,
      "step": 5755,
      "token_acc": 0.45925925925925926,
      "train_speed(iter/s)": 0.204747
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0406464338302612,
      "learning_rate": 1.4503040410052412e-05,
      "loss": 1.6002910614013672,
      "memory(GiB)": 22.05,
      "step": 5760,
      "token_acc": 0.6050420168067226,
      "train_speed(iter/s)": 0.204822
    },
    {
      "epoch": 0.720625,
      "grad_norm": 1.4772621393203735,
      "learning_rate": 1.4442573629741778e-05,
      "loss": 1.7708063125610352,
      "memory(GiB)": 22.05,
      "step": 5765,
      "token_acc": 0.6231884057971014,
      "train_speed(iter/s)": 0.204897
    },
    {
      "epoch": 0.72125,
      "grad_norm": 1.463902235031128,
      "learning_rate": 1.4382205381308767e-05,
      "loss": 1.9128162384033203,
      "memory(GiB)": 22.05,
      "step": 5770,
      "token_acc": 0.5859375,
      "train_speed(iter/s)": 0.204972
    },
    {
      "epoch": 0.721875,
      "grad_norm": 3.618865728378296,
      "learning_rate": 1.432193589749188e-05,
      "loss": 3.3777206420898436,
      "memory(GiB)": 22.05,
      "step": 5775,
      "token_acc": 0.453125,
      "train_speed(iter/s)": 0.205046
    },
    {
      "epoch": 0.7225,
      "grad_norm": 1.249064326286316,
      "learning_rate": 1.4261765410648844e-05,
      "loss": 2.1475725173950195,
      "memory(GiB)": 22.05,
      "step": 5780,
      "token_acc": 0.49645390070921985,
      "train_speed(iter/s)": 0.205123
    },
    {
      "epoch": 0.723125,
      "grad_norm": 5.9929518699646,
      "learning_rate": 1.4201694152755718e-05,
      "loss": 1.8191646575927733,
      "memory(GiB)": 22.05,
      "step": 5785,
      "token_acc": 0.5752212389380531,
      "train_speed(iter/s)": 0.205197
    },
    {
      "epoch": 0.72375,
      "grad_norm": 2.1835811138153076,
      "learning_rate": 1.4141722355406011e-05,
      "loss": 1.9717430114746093,
      "memory(GiB)": 22.05,
      "step": 5790,
      "token_acc": 0.5615384615384615,
      "train_speed(iter/s)": 0.205271
    },
    {
      "epoch": 0.724375,
      "grad_norm": 1.5202016830444336,
      "learning_rate": 1.4081850249809752e-05,
      "loss": 1.9508281707763673,
      "memory(GiB)": 22.05,
      "step": 5795,
      "token_acc": 0.527027027027027,
      "train_speed(iter/s)": 0.205348
    },
    {
      "epoch": 0.725,
      "grad_norm": 2.686697006225586,
      "learning_rate": 1.402207806679266e-05,
      "loss": 1.9739391326904296,
      "memory(GiB)": 22.05,
      "step": 5800,
      "token_acc": 0.5537190082644629,
      "train_speed(iter/s)": 0.205424
    },
    {
      "epoch": 0.725625,
      "grad_norm": 1.661710500717163,
      "learning_rate": 1.39624060367952e-05,
      "loss": 1.9152101516723632,
      "memory(GiB)": 22.05,
      "step": 5805,
      "token_acc": 0.5488721804511278,
      "train_speed(iter/s)": 0.2055
    },
    {
      "epoch": 0.72625,
      "grad_norm": 2.1420788764953613,
      "learning_rate": 1.390283438987174e-05,
      "loss": 1.8154563903808594,
      "memory(GiB)": 22.05,
      "step": 5810,
      "token_acc": 0.5859375,
      "train_speed(iter/s)": 0.205574
    },
    {
      "epoch": 0.726875,
      "grad_norm": 4.997673988342285,
      "learning_rate": 1.3843363355689591e-05,
      "loss": 1.9662689208984374,
      "memory(GiB)": 22.05,
      "step": 5815,
      "token_acc": 0.5546875,
      "train_speed(iter/s)": 0.20565
    },
    {
      "epoch": 0.7275,
      "grad_norm": 2.1112794876098633,
      "learning_rate": 1.3783993163528248e-05,
      "loss": 1.6993133544921875,
      "memory(GiB)": 22.05,
      "step": 5820,
      "token_acc": 0.6344827586206897,
      "train_speed(iter/s)": 0.205723
    },
    {
      "epoch": 0.728125,
      "grad_norm": 4.7244157791137695,
      "learning_rate": 1.372472404227835e-05,
      "loss": 1.6785472869873046,
      "memory(GiB)": 22.05,
      "step": 5825,
      "token_acc": 0.5725190839694656,
      "train_speed(iter/s)": 0.205792
    },
    {
      "epoch": 0.72875,
      "grad_norm": 4.499751091003418,
      "learning_rate": 1.3665556220440914e-05,
      "loss": 2.3216022491455077,
      "memory(GiB)": 22.05,
      "step": 5830,
      "token_acc": 0.5158730158730159,
      "train_speed(iter/s)": 0.205862
    },
    {
      "epoch": 0.729375,
      "grad_norm": 4.973579406738281,
      "learning_rate": 1.3606489926126437e-05,
      "loss": 2.0821422576904296,
      "memory(GiB)": 22.05,
      "step": 5835,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.205937
    },
    {
      "epoch": 0.73,
      "grad_norm": 9.968071937561035,
      "learning_rate": 1.3547525387053933e-05,
      "loss": 3.569590377807617,
      "memory(GiB)": 22.05,
      "step": 5840,
      "token_acc": 0.43902439024390244,
      "train_speed(iter/s)": 0.20601
    },
    {
      "epoch": 0.730625,
      "grad_norm": 1.7751528024673462,
      "learning_rate": 1.348866283055017e-05,
      "loss": 1.6114604949951172,
      "memory(GiB)": 22.05,
      "step": 5845,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.206085
    },
    {
      "epoch": 0.73125,
      "grad_norm": 1.5307657718658447,
      "learning_rate": 1.3429902483548745e-05,
      "loss": 2.5617170333862305,
      "memory(GiB)": 22.05,
      "step": 5850,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.206154
    },
    {
      "epoch": 0.731875,
      "grad_norm": 1.730362892150879,
      "learning_rate": 1.3371244572589141e-05,
      "loss": 2.2747100830078124,
      "memory(GiB)": 22.05,
      "step": 5855,
      "token_acc": 0.5114503816793893,
      "train_speed(iter/s)": 0.206226
    },
    {
      "epoch": 0.7325,
      "grad_norm": 5.042920112609863,
      "learning_rate": 1.3312689323816005e-05,
      "loss": 1.7792694091796875,
      "memory(GiB)": 22.05,
      "step": 5860,
      "token_acc": 0.5746268656716418,
      "train_speed(iter/s)": 0.206297
    },
    {
      "epoch": 0.733125,
      "grad_norm": 1.5382933616638184,
      "learning_rate": 1.3254236962978154e-05,
      "loss": 1.5159878730773926,
      "memory(GiB)": 22.05,
      "step": 5865,
      "token_acc": 0.6090225563909775,
      "train_speed(iter/s)": 0.206368
    },
    {
      "epoch": 0.73375,
      "grad_norm": 1.0053356885910034,
      "learning_rate": 1.3195887715427698e-05,
      "loss": 1.671766471862793,
      "memory(GiB)": 22.05,
      "step": 5870,
      "token_acc": 0.5677966101694916,
      "train_speed(iter/s)": 0.206444
    },
    {
      "epoch": 0.734375,
      "grad_norm": 1.824853539466858,
      "learning_rate": 1.3137641806119264e-05,
      "loss": 2.0153728485107423,
      "memory(GiB)": 22.05,
      "step": 5875,
      "token_acc": 0.549618320610687,
      "train_speed(iter/s)": 0.206519
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.7203445434570312,
      "learning_rate": 1.3079499459609077e-05,
      "loss": 1.9832077026367188,
      "memory(GiB)": 22.05,
      "step": 5880,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.206593
    },
    {
      "epoch": 0.735625,
      "grad_norm": 1.8875442743301392,
      "learning_rate": 1.302146090005405e-05,
      "loss": 2.0026973724365233,
      "memory(GiB)": 22.05,
      "step": 5885,
      "token_acc": 0.5040650406504065,
      "train_speed(iter/s)": 0.206662
    },
    {
      "epoch": 0.73625,
      "grad_norm": 1.3581173419952393,
      "learning_rate": 1.2963526351211017e-05,
      "loss": 2.0670097351074217,
      "memory(GiB)": 22.05,
      "step": 5890,
      "token_acc": 0.552,
      "train_speed(iter/s)": 0.206734
    },
    {
      "epoch": 0.736875,
      "grad_norm": 1.7158703804016113,
      "learning_rate": 1.2905696036435801e-05,
      "loss": 1.9889314651489258,
      "memory(GiB)": 22.05,
      "step": 5895,
      "token_acc": 0.5118110236220472,
      "train_speed(iter/s)": 0.206808
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.826833963394165,
      "learning_rate": 1.284797017868233e-05,
      "loss": 1.6477016448974608,
      "memory(GiB)": 22.05,
      "step": 5900,
      "token_acc": 0.5983606557377049,
      "train_speed(iter/s)": 0.206879
    },
    {
      "epoch": 0.738125,
      "grad_norm": 1.2259066104888916,
      "learning_rate": 1.2790349000501898e-05,
      "loss": 1.8579067230224608,
      "memory(GiB)": 22.05,
      "step": 5905,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.206955
    },
    {
      "epoch": 0.73875,
      "grad_norm": 3.2998337745666504,
      "learning_rate": 1.2732832724042154e-05,
      "loss": 2.149477005004883,
      "memory(GiB)": 22.05,
      "step": 5910,
      "token_acc": 0.5328467153284672,
      "train_speed(iter/s)": 0.207029
    },
    {
      "epoch": 0.739375,
      "grad_norm": 3.5310635566711426,
      "learning_rate": 1.267542157104635e-05,
      "loss": 2.2869613647460936,
      "memory(GiB)": 22.05,
      "step": 5915,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.207097
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.572324514389038,
      "learning_rate": 1.2618115762852451e-05,
      "loss": 1.686045265197754,
      "memory(GiB)": 22.05,
      "step": 5920,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.207169
    },
    {
      "epoch": 0.740625,
      "grad_norm": 2.1912522315979004,
      "learning_rate": 1.2560915520392296e-05,
      "loss": 2.0406978607177733,
      "memory(GiB)": 22.05,
      "step": 5925,
      "token_acc": 0.5378151260504201,
      "train_speed(iter/s)": 0.207241
    },
    {
      "epoch": 0.74125,
      "grad_norm": 1.9790096282958984,
      "learning_rate": 1.2503821064190697e-05,
      "loss": 2.4477121353149416,
      "memory(GiB)": 22.05,
      "step": 5930,
      "token_acc": 0.4645669291338583,
      "train_speed(iter/s)": 0.207308
    },
    {
      "epoch": 0.741875,
      "grad_norm": 2.950251579284668,
      "learning_rate": 1.2446832614364665e-05,
      "loss": 2.291324424743652,
      "memory(GiB)": 22.05,
      "step": 5935,
      "token_acc": 0.48120300751879697,
      "train_speed(iter/s)": 0.207377
    },
    {
      "epoch": 0.7425,
      "grad_norm": 1.675872564315796,
      "learning_rate": 1.2389950390622513e-05,
      "loss": 1.644556427001953,
      "memory(GiB)": 22.05,
      "step": 5940,
      "token_acc": 0.6349206349206349,
      "train_speed(iter/s)": 0.207451
    },
    {
      "epoch": 0.743125,
      "grad_norm": 1.93691086769104,
      "learning_rate": 1.2333174612263012e-05,
      "loss": 1.70833740234375,
      "memory(GiB)": 22.05,
      "step": 5945,
      "token_acc": 0.6496350364963503,
      "train_speed(iter/s)": 0.207528
    },
    {
      "epoch": 0.74375,
      "grad_norm": 2.372194290161133,
      "learning_rate": 1.2276505498174571e-05,
      "loss": 1.94794921875,
      "memory(GiB)": 22.05,
      "step": 5950,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.207597
    },
    {
      "epoch": 0.744375,
      "grad_norm": 3.3306267261505127,
      "learning_rate": 1.2219943266834337e-05,
      "loss": 2.7655918121337892,
      "memory(GiB)": 22.05,
      "step": 5955,
      "token_acc": 0.4380165289256198,
      "train_speed(iter/s)": 0.207668
    },
    {
      "epoch": 0.745,
      "grad_norm": 1.8176937103271484,
      "learning_rate": 1.2163488136307429e-05,
      "loss": 2.1437021255493165,
      "memory(GiB)": 22.05,
      "step": 5960,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.207743
    },
    {
      "epoch": 0.745625,
      "grad_norm": 2.0283939838409424,
      "learning_rate": 1.2107140324246051e-05,
      "loss": 2.1933956146240234,
      "memory(GiB)": 22.05,
      "step": 5965,
      "token_acc": 0.549618320610687,
      "train_speed(iter/s)": 0.207815
    },
    {
      "epoch": 0.74625,
      "grad_norm": 3.8950212001800537,
      "learning_rate": 1.205090004788864e-05,
      "loss": 2.2394172668457033,
      "memory(GiB)": 22.05,
      "step": 5970,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.207891
    },
    {
      "epoch": 0.746875,
      "grad_norm": 1.470211148262024,
      "learning_rate": 1.199476752405906e-05,
      "loss": 1.7179777145385742,
      "memory(GiB)": 22.05,
      "step": 5975,
      "token_acc": 0.5874125874125874,
      "train_speed(iter/s)": 0.207963
    },
    {
      "epoch": 0.7475,
      "grad_norm": 4.548595905303955,
      "learning_rate": 1.1938742969165774e-05,
      "loss": 2.185068893432617,
      "memory(GiB)": 22.05,
      "step": 5980,
      "token_acc": 0.49640287769784175,
      "train_speed(iter/s)": 0.208028
    },
    {
      "epoch": 0.748125,
      "grad_norm": 4.253203868865967,
      "learning_rate": 1.1882826599200965e-05,
      "loss": 2.1399776458740236,
      "memory(GiB)": 22.05,
      "step": 5985,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.208094
    },
    {
      "epoch": 0.74875,
      "grad_norm": 1.2248022556304932,
      "learning_rate": 1.1827018629739748e-05,
      "loss": 1.6363147735595702,
      "memory(GiB)": 22.05,
      "step": 5990,
      "token_acc": 0.6030534351145038,
      "train_speed(iter/s)": 0.208163
    },
    {
      "epoch": 0.749375,
      "grad_norm": 4.435097694396973,
      "learning_rate": 1.1771319275939321e-05,
      "loss": 2.0308746337890624,
      "memory(GiB)": 22.05,
      "step": 5995,
      "token_acc": 0.6071428571428571,
      "train_speed(iter/s)": 0.208234
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.3147943019866943,
      "learning_rate": 1.1715728752538103e-05,
      "loss": 2.2068496704101563,
      "memory(GiB)": 22.05,
      "step": 6000,
      "token_acc": 0.4915254237288136,
      "train_speed(iter/s)": 0.208307
    },
    {
      "epoch": 0.75,
      "eval_loss": 1.6107215881347656,
      "eval_runtime": 5573.1927,
      "eval_samples_per_second": 1.435,
      "eval_steps_per_second": 1.435,
      "eval_token_acc": 0.6089607917041161,
      "step": 6000
    }
  ],
  "logging_steps": 5,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4209536185270272e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
